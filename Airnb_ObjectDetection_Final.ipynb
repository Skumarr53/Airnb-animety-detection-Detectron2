{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airnb Amenity Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:50.886926Z",
     "start_time": "2020-08-23T14:21:50.875349Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:51.754892Z",
     "start_time": "2020-08-23T14:21:50.887872Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import detectron2\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger() # this logs Detectron2 information such as what the model is doing when it's training\n",
    "\n",
    "# import some common libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "import wandb\n",
    "\n",
    "\n",
    "# import custom libraries\n",
    "#from modules.preprocessing import *\n",
    "from modules.train import *\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2 import model_zoo # a series of pre-trained Detectron2 models: https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md\n",
    "from detectron2.engine import DefaultPredictor # a default predictor class to make predictions on an image using a trained model\n",
    "from detectron2.config import get_cfg # a config of \"cfg\" in Detectron2 is a series of instructions for building a model\n",
    "from detectron2.utils.visualizer import Visualizer # a class to help visualize Detectron2 predictions on an image\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog # stores information about the model such as what the training/test data is, what the class names are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try Detecron 2 on Custom Dataset\n",
    "\n",
    "Before jumping onto model building, try it on small dataset (probaly on single) and make sure it is working as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:51.767935Z",
     "start_time": "2020-08-23T14:21:51.755969Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/santhosh/HardDisk/skumar/DataScience/Projects_Section/Projects_Working/Airbnb_Amenity_Detection/DataSets'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change Dirrectory to DataSets directory\n",
    "\n",
    "if 'DataSets' not in os.getcwd():\n",
    "    os.chdir('DataSets')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define list of classes selected for amenity detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:51.864846Z",
     "start_time": "2020-08-23T14:21:51.768763Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Target classes\n",
    "target_classes = [\n",
    "    \"Toilet\", \"Swimming_pool\", \"Bed\", \"Billiard_table\", \"Sink\", \"Fountain\",\n",
    "    \"Oven\", \"Ceiling_fan\", \"Television\", \"Microwave_oven\", \"Gas_stove\",\n",
    "    \"Refrigerator\", \"Kitchen_&_dining_room_table\", \"Washing_machine\",\n",
    "    \"Bathtub\", \"Stairs\", \"Fireplace\", \"Pillow\", \"Mirror\", \"Shower\", \"Couch\",\n",
    "    \"Countertop\", \"Coffeemaker\", \"Dishwasher\", \"Sofa_bed\", \"Tree_house\",\n",
    "    \"Towel\", \"Porch\", \"Wine_rack\", \"Jacuzzi\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:02:20.666424Z",
     "start_time": "2020-08-19T07:02:20.652993Z"
    }
   },
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "def annote_image(annotations, resize=False):\n",
    "    file_name = annotations.file_name.to_numpy()[0]\n",
    "    \n",
    "    img = cv2.cvtColor(cv2.imread(f'{file_name}'), \n",
    "                       cv2.COLOR_BGR2RGB)\n",
    "    for a in annotations.annotations[0]:\n",
    "        xxyy = [int(i) for i in a['bbox']]\n",
    "        cv2.rectangle(img, (xxyy[0],xxyy[1]),(xxyy[2],xxyy[3]), (0,255,0), 2)\n",
    "    \n",
    "    if not resize:\n",
    "        return img\n",
    "    \n",
    "    return cv2.resize(img, (384,384), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T05:38:39.747940Z",
     "start_time": "2020-08-19T05:38:39.624677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/santhosh/HardDisk/skumar/DataScience/Projects_Section/Projects_Working/Airbnb_Amenity_Detection/DataSets\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**prepare the Dataset**\n",
    "\n",
    "Register our dataset to detectron2, following the detectron2 custom dataset tutorial.\n",
    "\n",
    "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. See the tutorial for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:51.945046Z",
     "start_time": "2020-08-23T14:21:51.866229Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_image_ids(image_folder=None):\n",
    "    \"\"\"\n",
    "    Explores a folder of images and gets their ID from their file name.\n",
    "    Returns a list of all image ID's in image_folder.\n",
    "    E.g. image_folder/608fda8c976e0ac.jpg -> [\"608fda8c976e0ac\"]\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): path to folder of images, e.g. \"../validation/\"\n",
    "    \"\"\"\n",
    "    return [os.path.splitext(img_name)[0] for img_name in os.listdir(image_folder) if img_name.endswith(\".jpg\")]\n",
    "\n",
    "# Make a function which formats a specific annotations csv based on what we're dealing with\n",
    "def format_annotations(image_folder, annotation_file, target_classes=None):\n",
    "    \"\"\"\n",
    "    TODO - NOTE: This function could (definitely can) be faster.\n",
    "    TODO - Some ideas: skip the use of pandas entirely and use CSV's\n",
    "    \n",
    "    Formats annotation_file based on images contained in image_folder.\n",
    "    Will get all unique image IDs and make sure annotation_file\n",
    "    only contains those (the target images).\n",
    "    Adds meta-data to annotation_file such as class names and categories.\n",
    "    If target_classes isn't None, the returned annotations will be filtered by this list.\n",
    "    Note: image_folder and annotation_file should both be validation if working on\n",
    "    validation set or both be training if working on training set.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): path to folder of target images.\n",
    "    annotation_file (str): path to annotation file of target images.\n",
    "    target_classes (list), optional: a list of target classes you'd like to filter labels.\n",
    "    \"\"\"\n",
    "    # Get all image ids from target directory\n",
    "    image_ids = get_image_ids(image_folder)\n",
    "    \n",
    "    # Setup annotation file and classnames\n",
    "    # TODO - improve this, is pandas required? \n",
    "    annot_file = pd.read_csv(annotation_file)\n",
    "    classes = pd.read_csv(\"class-descriptions-boxable.csv\",\n",
    "                          names=[\"LabelName\", \"ClassName\"])\n",
    "    \n",
    "    # Create classname column on annotations which converts label codes to string labels\n",
    "    annot_file[\"ClassName\"] = annot_file[\"LabelName\"].map(classes.set_index(\"LabelName\")[\"ClassName\"])\n",
    "\n",
    "    # Sort annot_file by \"ClassName\" for alphabetical labels (used with target_classes)\n",
    "    annot_file.sort_values(by=[\"ClassName\"], inplace=True)\n",
    "    \n",
    "    # TODO - fix this, Make sure we only get the images we're concerned about\n",
    "    if target_classes:\n",
    "        annot_file = annot_file[annot_file[\"ImageID\"].isin(image_ids) & annot_file[\"ClassName\"].isin(target_classes)]\n",
    "    else:\n",
    "        annot_file = annot_file[annot_file[\"ImageID\"].isin(image_ids)]\n",
    "   \n",
    "    # Add ClassID column, e.g. \"Bathtub, Toilet\" -> 1, 2\n",
    "    annot_file[\"ClassName\"] = pd.Categorical(annot_file[\"ClassName\"])\n",
    "    annot_file[\"ClassID\"] = annot_file[\"ClassName\"].cat.codes\n",
    "    \n",
    "    return annot_file\n",
    "\n",
    "def rel_to_absolute(bbox, height, width):\n",
    "    \"\"\"\n",
    "    Converts bounding box dimensions from relative to absolute pixel values (Detectron2 style).\n",
    "    See: https://detectron2.readthedocs.io/modules/structures.html#detectron2.structures.BoxMode\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    bbox (array): relative dimensions of bounding box in format (x0, y0, x1, y1 or Xmin, Ymin, Xmax, Ymax)\n",
    "    height (int): height of image\n",
    "    width (int): width of image\n",
    "    \"\"\"\n",
    "    bbox[0] = np.round(np.multiply(bbox[0], width)) # x0\n",
    "    bbox[1] = np.round(np.multiply(bbox[1], height)) # y0\n",
    "    bbox[2] = np.round(np.multiply(bbox[2], width)) # x1\n",
    "    bbox[3] = np.round(np.multiply(bbox[3], height)) # y1\n",
    "    return [i.astype(\"object\") for i in bbox] # convert all to objects for JSON saving\n",
    "\n",
    "def get_image_dicts(image_folder, annotation_file, target_classes=None):\n",
    "    \"\"\"\n",
    "    Create JSON of dectectron2 style labels to be reused later.\n",
    "\n",
    "    TODO -- Maybe create some verbosity here? In other words, what are the outputs?\n",
    "    TODO -- what if annotations = None? Can we create a call to create an annotations CSV in 1 hit?\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): target folder containing images\n",
    "    annotations (DataFrame): DataFrame of image label data\n",
    "    \"\"\"\n",
    "    dataset_name = \"validation\" if \"valid\" in image_folder else \"train\"\n",
    "\n",
    "    print(f\"Using {annotation_file} for annotations...\")\n",
    "    # TODO: there should be some kind of asssertions here making sure the image folder and annotation files match\n",
    "    # E.g. train w/ train and valid w/ valid\n",
    "    annotations = format_annotations(image_folder=image_folder, \n",
    "                                     annotation_file=annotation_file,\n",
    "                                     target_classes=target_classes)\n",
    "\n",
    "    print(f\"On dataset: {dataset_name}\")\n",
    "    print(\"Classes we're using:\\n {}\".format(annotations[\"ClassName\"].value_counts()))\n",
    "\n",
    "    # Get all unique image ids from target folder\n",
    "    img_ids = get_image_ids(image_folder)\n",
    "    print(f\"Total number of images: {len(img_ids)}\")\n",
    "\n",
    "    # TODO: move img_data creation out of for loop and only work with subset of img_ids?\n",
    "    #img_data = annotations[annotations[\"ImageID\"] == img].reset_index() # reset index important for images with multiple objects\n",
    "    #change to something like \"img_data = annotations is in img_ids...\"\n",
    "\n",
    "    # Start creating image dictionaries (Detectron2 style labelling)\n",
    "    img_dicts = []\n",
    "    for idx, img in tqdm(enumerate(img_ids)):\n",
    "        record = {}\n",
    "\n",
    "        # Get image metadata\n",
    "        file_name = image_folder + \"/\" + img + \".jpg\"\n",
    "        height, width = cv2.imread(file_name).shape[:2]\n",
    "        img_data = annotations[annotations[\"ImageID\"] == img].reset_index() # reset index important for images\n",
    "                                                                            # with multiple objects\n",
    "        # Verbosity for image label troubleshooting\n",
    "        # print(f\"On image: {img}\")\n",
    "        # print(f\"Image category: {img_data.ClassID.values}\")\n",
    "        # print(f\"Image label: {img_data.ClassName.values}\")\n",
    "\n",
    "        # Update record dictionary\n",
    "        record[\"file_name\"] = file_name\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        # Create list of image annotations (labels)\n",
    "        img_annotations = []\n",
    "        for i in range(len(img_data)): # this is where we loop through examples with multiple objects in an image\n",
    "            category_id = img_data.loc[i][\"ClassID\"].astype(\"object\") # JSON (for evalution) can't take int8 (NumPy type) must be native Python type\n",
    "            # print(f\"Image category 2: {category_id}\")\n",
    "            # Get bounding box coordinates in Detectron2 style (x0, y0, x1, y1)\n",
    "            bbox = np.float32(img_data.loc[i][[\"XMin\", \"YMin\", \"XMax\", \"YMax\"]].values) # needs to be float/int # TODO: change for JSON\n",
    "            # Convert bbox from relative to absolute pixel dimensions\n",
    "            bbox = rel_to_absolute(bbox=bbox, height=height, width=width)\n",
    "            # Setup annot (1 annot = 1 label, there might be more) dictionary\n",
    "            annot = {\n",
    "                \"bbox\": bbox, \n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS, # See: https://detectron2.readthedocs.io/modules/structures.html#detectron2.structures.BoxMode.XYXY_ABS\n",
    "                \"category_id\": category_id\n",
    "            }\n",
    "            img_annotations.append(annot)\n",
    "\n",
    "        # Update record dictionary with annotations\n",
    "        record[\"annotations\"] = img_annotations\n",
    "\n",
    "        # Add record dictionary with image annotations to img_dicts list\n",
    "        img_dicts.append(record)\n",
    "\n",
    "    # TODO: Change this into it's own function??\n",
    "    # Save img_dicts to JSON for use later\n",
    "    json_file = os.path.join(image_folder, dataset_name+\"_labels.json\")\n",
    "    print(f\"Saving labels to: {json_file}...\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(img_dicts, f)\n",
    "\n",
    "    # return img labels dictionary\n",
    "    return img_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:52.023352Z",
     "start_time": "2020-08-23T14:21:51.946153Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def load_json_labels(image_folder):\n",
    "    \"\"\"\n",
    "    Returns Detectron2 style labels of images in image_folder based on JSON label file in image_folder.\n",
    "\n",
    "    TODO -- Maybe create some verbosity here? AKA, what are the outputs?\n",
    "    TODO -- what if annotations = None? Can we create a call to create an annotations CSV in 1 hit?\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    image_folder (str): target folder containing images\n",
    "    \"\"\"\n",
    "    # Get absolute path of JSON label file\n",
    "    for file in os.listdir(image_folder):\n",
    "        if file.endswith(\".json\"):\n",
    "            json_file = os.path.join(image_folder, file)\n",
    "\n",
    "    # TODO: Fix this assertion\n",
    "    assert json_file, \"No .json label file found, please make one with annots_to_json()\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        img_dicts = json.load(f)\n",
    "\n",
    "    # Convert bbox_mode to Enum of BoxMode.XYXY_ABS (doesn't work loading normal from JSON)\n",
    "    for img_dict in img_dicts:\n",
    "        for annot in img_dict[\"annotations\"]:\n",
    "            annot[\"bbox_mode\"] = BoxMode.XYXY_ABS\n",
    "\n",
    "    return img_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:02:26.170673Z",
     "start_time": "2020-08-19T07:02:26.158531Z"
    }
   },
   "outputs": [],
   "source": [
    "#Coffee maker class as example \n",
    "\n",
    "train_path, valid_path = 'train/Coffeemaker', 'validation/Coffeemaker'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:52.102734Z",
     "start_time": "2020-08-23T14:21:52.024685Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def register_datasets(train_path, valid_path=None, target_cls=None):\n",
    "    \"\"\"\n",
    "    Registers a Detectron2 style dataset from training paths.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    train_path (str) : pathname to training data containing training images\n",
    "    valid_path (str) : pathname to validation data containing validation images\n",
    "    \"\"\"\n",
    "    # TODO - update to accept any kind of path, e.g. not only coffeemaker, maybe could take a dict as input?\n",
    "    # E.g. {\"training\": \"path/to/training\",\n",
    "    #          \"valid\": \"path/to/valid\"}\n",
    "    for d in [train_path, valid_path]:\n",
    "        print(\"Registering: {}\".format(d.split(\"/\")[-1]))\n",
    "        if d not in DatasetCatalog._REGISTERED.keys():\n",
    "            DatasetCatalog.register(d, lambda d=d: load_json_labels(d))\n",
    "        MetadataCatalog.get(d).set(thing_classes=target_cls)\n",
    "    return MetadataCatalog.get(valid_path) # TODO - make this better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:02:41.445670Z",
     "start_time": "2020-08-19T07:02:41.431990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering: Coffeemaker\n",
      "Registering: Coffeemaker\n"
     ]
    }
   ],
   "source": [
    "coffee_metadata = register_datasets(train_path=train_path,\n",
    "                                    valid_path=valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:15:05.007150Z",
     "start_time": "2020-08-19T07:15:01.558459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using validation for annotations...\n",
      "On dataset: validation\n",
      "Classes we're using: Coffeemaker    18\n",
      "Name: ClassName, dtype: int64\n",
      "{'file_name': 'validation/Coffeemaker/9c56d526fd608f18.jpg', 'image_id': 16, 'height': 1024, 'width': 680, 'annotations': [{'bbox': [0.0, 87.35437, 440.5557, 954.0106], 'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'category_id': 0}]}\n",
      "> \u001b[0;32m/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/utils/visualizer.py\u001b[0m(532)\u001b[0;36mdraw_dataset_dict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    530 \u001b[0;31m            \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"thing_classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    531 \u001b[0;31m            \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 532 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    533 \u001b[0;31m                \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    534 \u001b[0;31m            labels = [\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 983.04x652.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_img_dicts = get_image_dicts(valid_path)\n",
    "\n",
    "for d in random.sample(val_img_dicts, 1):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    \n",
    "    img_shape = img.shape[:2]\n",
    "    \n",
    "    plt.figure(figsize=(img_shape[0]/75,img_shape[1]/75))\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=coffee_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(vis.get_image())#[:, :, ::-1])\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:19:00.279068Z",
     "start_time": "2020-08-19T07:18:36.607505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 12:48:46 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train for annotations...\n",
      "On dataset: train\n",
      "Classes we're using: Coffeemaker    51\n",
      "Name: ClassName, dtype: int64\n",
      "\u001b[32m[08/19 12:48:58 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 35 images left.\n",
      "\u001b[32m[08/19 12:48:58 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category   | #instances   |\n",
      "|:-----------:|:-------------|\n",
      "| Coffeemaker | 51           |\n",
      "|             |              |\u001b[0m\n",
      "\u001b[32m[08/19 12:48:58 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/19 12:48:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/19 12:48:58 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/19 12:48:58 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = ('train/Coffeemaker',)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 500    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (coffeemaker)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:23:19.884037Z",
     "start_time": "2020-08-19T07:19:10.557652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 12:49:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/19 12:49:21 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 19  total_loss: 1.096  loss_cls: 0.660  loss_box_reg: 0.403  loss_rpn_cls: 0.029  loss_rpn_loc: 0.016  time: 0.5022  data_time: 0.0291  lr: 0.000050  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:49:31 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 39  total_loss: 0.913  loss_cls: 0.416  loss_box_reg: 0.452  loss_rpn_cls: 0.026  loss_rpn_loc: 0.022  time: 0.4942  data_time: 0.0033  lr: 0.000100  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:49:41 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 59  total_loss: 0.764  loss_cls: 0.302  loss_box_reg: 0.442  loss_rpn_cls: 0.016  loss_rpn_loc: 0.013  time: 0.4938  data_time: 0.0031  lr: 0.000150  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:49:50 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 79  total_loss: 0.731  loss_cls: 0.247  loss_box_reg: 0.490  loss_rpn_cls: 0.022  loss_rpn_loc: 0.017  time: 0.4860  data_time: 0.0031  lr: 0.000200  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:00 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 99  total_loss: 0.702  loss_cls: 0.211  loss_box_reg: 0.459  loss_rpn_cls: 0.017  loss_rpn_loc: 0.011  time: 0.4829  data_time: 0.0033  lr: 0.000250  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:10 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 119  total_loss: 0.584  loss_cls: 0.153  loss_box_reg: 0.416  loss_rpn_cls: 0.014  loss_rpn_loc: 0.018  time: 0.4840  data_time: 0.0032  lr: 0.000300  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:19 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 139  total_loss: 0.546  loss_cls: 0.138  loss_box_reg: 0.372  loss_rpn_cls: 0.008  loss_rpn_loc: 0.010  time: 0.4818  data_time: 0.0031  lr: 0.000350  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:29 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 159  total_loss: 0.469  loss_cls: 0.113  loss_box_reg: 0.339  loss_rpn_cls: 0.009  loss_rpn_loc: 0.016  time: 0.4807  data_time: 0.0030  lr: 0.000400  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:38 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 179  total_loss: 0.371  loss_cls: 0.097  loss_box_reg: 0.274  loss_rpn_cls: 0.007  loss_rpn_loc: 0.013  time: 0.4807  data_time: 0.0031  lr: 0.000450  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:48 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 199  total_loss: 0.348  loss_cls: 0.085  loss_box_reg: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 0.4807  data_time: 0.0031  lr: 0.000500  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:50:58 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 219  total_loss: 0.350  loss_cls: 0.081  loss_box_reg: 0.245  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 0.4803  data_time: 0.0034  lr: 0.000549  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:51:07 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 239  total_loss: 0.257  loss_cls: 0.079  loss_box_reg: 0.161  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 0.4802  data_time: 0.0029  lr: 0.000599  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:51:17 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 259  total_loss: 0.242  loss_cls: 0.059  loss_box_reg: 0.155  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 0.4797  data_time: 0.0033  lr: 0.000649  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:51:27 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 279  total_loss: 0.263  loss_cls: 0.056  loss_box_reg: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 0.4802  data_time: 0.0031  lr: 0.000699  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:51:37 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 299  total_loss: 0.220  loss_cls: 0.047  loss_box_reg: 0.140  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.4815  data_time: 0.0032  lr: 0.000749  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:51:47 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 319  total_loss: 0.216  loss_cls: 0.057  loss_box_reg: 0.142  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 0.4813  data_time: 0.0034  lr: 0.000799  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:51:56 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 339  total_loss: 0.252  loss_cls: 0.042  loss_box_reg: 0.184  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 0.4814  data_time: 0.0031  lr: 0.000849  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:52:06 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 359  total_loss: 0.225  loss_cls: 0.052  loss_box_reg: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 0.4821  data_time: 0.0030  lr: 0.000899  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:52:16 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 379  total_loss: 0.239  loss_cls: 0.045  loss_box_reg: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.4827  data_time: 0.0033  lr: 0.000949  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:52:26 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 399  total_loss: 0.180  loss_cls: 0.041  loss_box_reg: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 0.4819  data_time: 0.0031  lr: 0.000999  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:52:36 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 419  total_loss: 0.212  loss_cls: 0.043  loss_box_reg: 0.140  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 0.4819  data_time: 0.0028  lr: 0.001049  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:52:46 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 439  total_loss: 0.217  loss_cls: 0.040  loss_box_reg: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 0.4815  data_time: 0.0030  lr: 0.001099  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:52:55 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 459  total_loss: 0.165  loss_cls: 0.030  loss_box_reg: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 0.4811  data_time: 0.0031  lr: 0.001149  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:53:05 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 479  total_loss: 0.165  loss_cls: 0.039  loss_box_reg: 0.122  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 0.4819  data_time: 0.0029  lr: 0.001199  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:53:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.153  loss_cls: 0.034  loss_box_reg: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 0.4809  data_time: 0.0030  lr: 0.001249  max_mem: 2734M\n",
      "\u001b[32m[08/19 12:53:19 d2.engine.hooks]: \u001b[0mOverall training speed: 497 iterations in 0:03:59 (0.4819 s / it)\n",
      "\u001b[32m[08/19 12:53:19 d2.engine.hooks]: \u001b[0mTotal training time: 0:04:07 (0:00:07 on hooks)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference & evaluation using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run inference with the trained model on the validation dataset. First, let's create a predictor using the model we just trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:25:19.104945Z",
     "start_time": "2020-08-19T07:25:18.538503Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"validation/Coffeemaker\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:25:19.533305Z",
     "start_time": "2020-08-19T07:25:19.152554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': Instances(num_instances=1, image_height=683, image_width=1024, fields=[pred_boxes: Boxes(tensor([[106.3987,   0.0000, 998.7112, 680.1294]], device='cuda:0')), scores: tensor([0.9898], device='cuda:0'), pred_classes: tensor([0], device='cuda:0')])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "\n",
    "#val_img_dicts = get_image_dicts(valid_path)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for d in random.sample(val_img_dicts, 1):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    print(outputs)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=coffee_metadata, \n",
    "                   scale=0.5 \n",
    "                   #instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:25:59.543435Z",
     "start_time": "2020-08-19T07:25:56.582700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 12:55:56 d2.evaluation.coco_evaluation]: \u001b[0m'validation/Coffeemaker' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/19 12:55:56 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './output/validation/Coffeemaker_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "Using validation for annotations...\n",
      "On dataset: validation\n",
      "Classes we're using: Coffeemaker    18\n",
      "Name: ClassName, dtype: int64\n",
      "\u001b[32m[08/19 12:55:57 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category   | #instances   |\n",
      "|:-----------:|:-------------|\n",
      "| Coffeemaker | 18           |\n",
      "|             |              |\u001b[0m\n",
      "\u001b[32m[08/19 12:55:57 d2.data.common]: \u001b[0mSerializing 17 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/19 12:55:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/19 12:55:57 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/19 12:55:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 17 images\n",
      "\u001b[32m[08/19 12:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/17. 0.1276 s / img. ETA=0:00:00\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.506824 (0.125569 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.122563 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.28 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.602\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.882\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.762\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.602\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 60.152 | 88.228 | 76.152 |  nan  |  nan  | 60.152 |\n",
      "\u001b[32m[08/19 12:55:59 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 60.151786157304976,\n",
       "               'AP50': 88.2275756038602,\n",
       "               'AP75': 76.15181927622044,\n",
       "               'APs': nan,\n",
       "               'APm': nan,\n",
       "               'APl': 60.151786157304976})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "\n",
    "# We use COCOEvaluator which has simiar config style\n",
    "evaluator = COCOEvaluator(\"validation/Coffeemaker\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"validation/Coffeemaker\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T07:26:53.717638Z",
     "start_time": "2020-08-19T07:26:53.702249Z"
    }
   },
   "source": [
    "Wow!! AP(Avg Precision) of 60 is pretty amazing compared to what airnb has achieved (around 50) .offcourse we only considered single class here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plain_train_net.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to write out the plain_train_net.py script verbatim to see what it's doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/detectron2/blob/master/tools/plain_train_net.py\n",
    "\n",
    "I'll leave notes and change it where I need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:52.166206Z",
     "start_time": "2020-08-23T14:21:52.104750Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"R50-FPN-1x\": \"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"R50-FPN-3x\": \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"R101-FPN-3x\": \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"X101-FPN-3x\": \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "    \"RN-R50-1x\": \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"RN-R50-3x\": \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"RN-R101-3x\": \"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:57.722985Z",
     "start_time": "2020-08-23T14:21:52.167930Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2kewddba\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2kewddba</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2kewddba"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"airbnb-object-detection\", \n",
    "           sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:42:19.661948Z",
     "start_time": "2020-08-21T07:42:19.627355Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f264ee04d0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m coffee_metadata = register_datasets(train_path=train_path,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mvalid_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     target_cls=['Bathtub', 'Coffeemaker', 'Tree house'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_path' is not defined"
     ]
    }
   ],
   "source": [
    "coffee_metadata = register_datasets(train_path=train_path,\n",
    "                                    valid_path=valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T07:45:03.645936Z",
     "start_time": "2020-08-21T07:45:03.608658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'train/cmaker-bathtub-treehouse-train' in DatasetCatalog._REGISTERED.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:11:20.220432Z",
     "start_time": "2020-08-19T08:11:20.204828Z"
    }
   },
   "source": [
    "### Train with Detectron's custom training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:11:46.585429Z",
     "start_time": "2020-08-19T08:11:46.566593Z"
    }
   },
   "source": [
    "The following code is original training code from the Detectron2 example notebook but I think we can make it better/suit our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:12:06.953902Z",
     "start_time": "2020-08-19T08:12:06.936142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example use case of model_zoo\n",
    "model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T08:30:44.262563Z",
     "start_time": "2020-08-19T08:30:44.244592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T09:04:04.577659Z",
     "start_time": "2020-08-19T09:04:04.561404Z"
    }
   },
   "outputs": [],
   "source": [
    "config_path = '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection'\n",
    "train_path, valid_path = 'train/Coffeemaker', 'validation/Coffeemaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T09:04:05.483333Z",
     "start_time": "2020-08-19T09:04:05.465312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl', 'DATASETS.TRAIN', \"('train/Coffeemaker',)\", 'DATASETS.TEST', \"('validation/Coffeemaker',)\", 'DATALOADER.NUM_WORKERS', '1', 'SOLVER.IMS_PER_BATCH', '2', 'SOLVER.MAX_ITER', '500', 'MODEL.ROI_HEADS.NUM_CLASSES', '1'], resume=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup arg parser\n",
    "parser = default_argument_parser() # default in Detectron2\n",
    "args = parser.parse_args(f\"--config-file {config_path}/faster_rcnn_R_50_FPN_1x.yaml \\\n",
    "                          MODEL.WEIGHTS https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl \\\n",
    "                          DATASETS.TRAIN ('{train_path}',) \\\n",
    "                          DATASETS.TEST ('{valid_path}',) \\\n",
    "                          DATALOADER.NUM_WORKERS 1 \\\n",
    "                          SOLVER.IMS_PER_BATCH 2 \\\n",
    "                          SOLVER.MAX_ITER 500 \\\n",
    "                          MODEL.ROI_HEADS.NUM_CLASSES 1\".split())\n",
    "# TODO: Add args to Weights & Biases\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T16:56:39.415972Z",
     "start_time": "2020-08-19T16:51:12.911345Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl', 'DATASETS.TRAIN', \"('train/Coffeemaker',)\", 'DATASETS.TEST', \"('validation/Coffeemaker',)\", 'DATALOADER.NUM_WORKERS', '1', 'SOLVER.IMS_PER_BATCH', '2', 'SOLVER.MAX_ITER', '500', 'MODEL.ROI_HEADS.NUM_CLASSES', '1'], resume=False)\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl', 'DATASETS.TRAIN', \"('train/Coffeemaker',)\", 'DATASETS.TEST', \"('validation/Coffeemaker',)\", 'DATALOADER.NUM_WORKERS', '1', 'SOLVER.IMS_PER_BATCH', '2', 'SOLVER.MAX_ITER', '500', 'MODEL.ROI_HEADS.NUM_CLASSES', '1'], resume=False)\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 1\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/Coffeemaker',)\n",
      "  TRAIN: ('train/Coffeemaker',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 1\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  BASE_LR: 0.02\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 500\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 1\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/Coffeemaker',)\n",
      "  TRAIN: ('train/Coffeemaker',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 1\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  BASE_LR: 0.02\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 500\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/19 22:21:13 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/19 22:21:13 d2.utils.env]: \u001b[0mUsing a generated random seed 13921852\n",
      "\u001b[32m[08/19 22:21:13 d2.utils.env]: \u001b[0mUsing a generated random seed 13921852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2a06loj7\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2a06loj7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-135:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/watchdog/observers/api.py\", line 203, in run\n",
      "    self.dispatch_events(self.event_queue, self.timeout)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/watchdog/observers/api.py\", line 376, in dispatch_events\n",
      "    handler.dispatch(event)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/watchdog/events.py\", line 452, in dispatch\n",
      "    super(PatternMatchingEventHandler, self).dispatch(event)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/watchdog/events.py\", line 331, in dispatch\n",
      "    {\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/wandb/run_manager.py\", line 697, in _on_file_modified\n",
      "    self._get_file_event_handler(event.src_path, save_name).on_modified()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/wandb/run_manager.py\", line 245, in on_modified\n",
      "    self._eventually_update()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/wandb/run_manager.py\", line 253, in _eventually_update\n",
      "    self._update()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/wandb/run_manager.py\", line 268, in _update\n",
      "    config_dict = util.load_yaml(f)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/wandb/util.py\", line 775, in load_yaml\n",
      "    return yaml.full_load(file)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/__init__.py\", line 142, in full_load\n",
      "    return load(stream, FullLoader)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/__init__.py\", line 114, in load\n",
      "    return loader.get_single_data()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/constructor.py\", line 49, in get_single_data\n",
      "    node = self.get_single_node()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/composer.py\", line 36, in get_single_node\n",
      "    document = self.compose_document()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/composer.py\", line 55, in compose_document\n",
      "    node = self.compose_node(None, None)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/composer.py\", line 127, in compose_mapping_node\n",
      "    while not self.check_event(MappingEndEvent):\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/parser.py\", line 98, in check_event\n",
      "    self.current_event = self.state()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/parser.py\", line 428, in parse_block_mapping_key\n",
      "    if self.check_token(KeyToken):\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/scanner.py\", line 116, in check_token\n",
      "    self.fetch_more_tokens()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/scanner.py\", line 223, in fetch_more_tokens\n",
      "    return self.fetch_value()\n",
      "  File \"/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/yaml/scanner.py\", line 577, in fetch_value\n",
      "    raise ScannerError(None, None,\n",
      "yaml.scanner.ScannerError: mapping values are not allowed here\n",
      "  in \"/home/santhosh/HardDisk/skumar/DataScience/Projects_Section/Projects_Working/Airbnb_Amenity_Detection/DataSets/wandb/run-20200819_222114-2a06loj7/config.yaml\", line 12, column 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Printing config_yaml file to go into Weights & Biases\n",
      "{'CUDNN_BENCHMARK': False, 'DATALOADER': {'ASPECT_RATIO_GROUPING': True, 'FILTER_EMPTY_ANNOTATIONS': True, 'NUM_WORKERS': 1, 'REPEAT_THRESHOLD': 0.0, 'SAMPLER_TRAIN': 'TrainingSampler'}, 'DATASETS': {'PRECOMPUTED_PROPOSAL_TOPK_TEST': 1000, 'PRECOMPUTED_PROPOSAL_TOPK_TRAIN': 2000, 'PROPOSAL_FILES_TEST': [], 'PROPOSAL_FILES_TRAIN': [], 'TEST': ['validation/Coffeemaker'], 'TRAIN': ['train/Coffeemaker']}, 'GLOBAL': {'HACK': 1.0}, 'INPUT': {'CROP': {'ENABLED': False, 'SIZE': [0.9, 0.9], 'TYPE': 'relative_range'}, 'FORMAT': 'BGR', 'MASK_FORMAT': 'polygon', 'MAX_SIZE_TEST': 1333, 'MAX_SIZE_TRAIN': 1333, 'MIN_SIZE_TEST': 800, 'MIN_SIZE_TRAIN': [640, 672, 704, 736, 768, 800], 'MIN_SIZE_TRAIN_SAMPLING': 'choice'}, 'MODEL': {'ANCHOR_GENERATOR': {'ANGLES': [[-90, 0, 90]], 'ASPECT_RATIOS': [[0.5, 1.0, 2.0]], 'NAME': 'DefaultAnchorGenerator', 'OFFSET': 0.0, 'SIZES': [[32], [64], [128], [256], [512]]}, 'BACKBONE': {'FREEZE_AT': 2, 'NAME': 'build_resnet_fpn_backbone'}, 'DEVICE': 'cuda', 'FPN': {'FUSE_TYPE': 'sum', 'IN_FEATURES': ['res2', 'res3', 'res4', 'res5'], 'NORM': '', 'OUT_CHANNELS': 256}, 'KEYPOINT_ON': False, 'LOAD_PROPOSALS': False, 'MASK_ON': False, 'META_ARCHITECTURE': 'GeneralizedRCNN', 'PANOPTIC_FPN': {'COMBINE': {'ENABLED': True, 'INSTANCES_CONFIDENCE_THRESH': 0.5, 'OVERLAP_THRESH': 0.5, 'STUFF_AREA_LIMIT': 4096}, 'INSTANCE_LOSS_WEIGHT': 1.0}, 'PIXEL_MEAN': [103.53, 116.28, 123.675], 'PIXEL_STD': [1.0, 1.0, 1.0], 'PROPOSAL_GENERATOR': {'MIN_SIZE': 0, 'NAME': 'RPN'}, 'RESNETS': {'DEFORM_MODULATED': False, 'DEFORM_NUM_GROUPS': 1, 'DEFORM_ON_PER_STAGE': [False, False, False, False], 'DEPTH': 50, 'NORM': 'FrozenBN', 'NUM_GROUPS': 1, 'OUT_FEATURES': ['res2', 'res3', 'res4', 'res5'], 'RES2_OUT_CHANNELS': 256, 'RES5_DILATION': 1, 'STEM_OUT_CHANNELS': 64, 'STRIDE_IN_1X1': True, 'WIDTH_PER_GROUP': 64}, 'RETINANET': {'BBOX_REG_WEIGHTS': [1.0, 1.0, 1.0, 1.0], 'FOCAL_LOSS_ALPHA': 0.25, 'FOCAL_LOSS_GAMMA': 2.0, 'IN_FEATURES': ['p3', 'p4', 'p5', 'p6', 'p7'], 'IOU_LABELS': [0, -1, 1], 'IOU_THRESHOLDS': [0.4, 0.5], 'NMS_THRESH_TEST': 0.5, 'NUM_CLASSES': 80, 'NUM_CONVS': 4, 'PRIOR_PROB': 0.01, 'SCORE_THRESH_TEST': 0.05, 'SMOOTH_L1_LOSS_BETA': 0.1, 'TOPK_CANDIDATES_TEST': 1000}, 'ROI_BOX_CASCADE_HEAD': {'BBOX_REG_WEIGHTS': [[10.0, 10.0, 5.0, 5.0], [20.0, 20.0, 10.0, 10.0], [30.0, 30.0, 15.0, 15.0]], 'IOUS': [0.5, 0.6, 0.7]}, 'ROI_BOX_HEAD': {'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': [10.0, 10.0, 5.0, 5.0], 'CLS_AGNOSTIC_BBOX_REG': False, 'CONV_DIM': 256, 'FC_DIM': 1024, 'NAME': 'FastRCNNConvFCHead', 'NORM': '', 'NUM_CONV': 0, 'NUM_FC': 2, 'POOLER_RESOLUTION': 7, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2', 'SMOOTH_L1_BETA': 0.0, 'TRAIN_ON_PRED_BOXES': False}, 'ROI_HEADS': {'BATCH_SIZE_PER_IMAGE': 512, 'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'], 'IOU_LABELS': [0, 1], 'IOU_THRESHOLDS': [0.5], 'NAME': 'StandardROIHeads', 'NMS_THRESH_TEST': 0.5, 'NUM_CLASSES': 1, 'POSITIVE_FRACTION': 0.25, 'PROPOSAL_APPEND_GT': True, 'SCORE_THRESH_TEST': 0.05}, 'ROI_KEYPOINT_HEAD': {'CONV_DIMS': [512, 512, 512, 512, 512, 512, 512, 512], 'LOSS_WEIGHT': 1.0, 'MIN_KEYPOINTS_PER_IMAGE': 1, 'NAME': 'KRCNNConvDeconvUpsampleHead', 'NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS': True, 'NUM_KEYPOINTS': 17, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2'}, 'ROI_MASK_HEAD': {'CLS_AGNOSTIC_MASK': False, 'CONV_DIM': 256, 'NAME': 'MaskRCNNConvUpsampleHead', 'NORM': '', 'NUM_CONV': 4, 'POOLER_RESOLUTION': 14, 'POOLER_SAMPLING_RATIO': 0, 'POOLER_TYPE': 'ROIAlignV2'}, 'RPN': {'BATCH_SIZE_PER_IMAGE': 256, 'BBOX_REG_LOSS_TYPE': 'smooth_l1', 'BBOX_REG_LOSS_WEIGHT': 1.0, 'BBOX_REG_WEIGHTS': [1.0, 1.0, 1.0, 1.0], 'BOUNDARY_THRESH': -1, 'HEAD_NAME': 'StandardRPNHead', 'IN_FEATURES': ['p2', 'p3', 'p4', 'p5', 'p6'], 'IOU_LABELS': [0, -1, 1], 'IOU_THRESHOLDS': [0.3, 0.7], 'LOSS_WEIGHT': 1.0, 'NMS_THRESH': 0.7, 'POSITIVE_FRACTION': 0.5, 'POST_NMS_TOPK_TEST': 1000, 'POST_NMS_TOPK_TRAIN': 1000, 'PRE_NMS_TOPK_TEST': 1000, 'PRE_NMS_TOPK_TRAIN': 2000, 'SMOOTH_L1_BETA': 0.0}, 'SEM_SEG_HEAD': {'COMMON_STRIDE': 4, 'CONVS_DIM': 128, 'IGNORE_VALUE': 255, 'IN_FEATURES': ['p2', 'p3', 'p4', 'p5'], 'LOSS_WEIGHT': 1.0, 'NAME': 'SemSegFPNHead', 'NORM': 'GN', 'NUM_CLASSES': 54}, 'WEIGHTS': 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl'}, 'OUTPUT_DIR': './output', 'SEED': -1, 'SOLVER': {'BASE_LR': 0.02, 'BIAS_LR_FACTOR': 1.0, 'CHECKPOINT_PERIOD': 5000, 'CLIP_GRADIENTS': {'CLIP_TYPE': 'value', 'CLIP_VALUE': 1.0, 'ENABLED': False, 'NORM_TYPE': 2.0}, 'GAMMA': 0.1, 'IMS_PER_BATCH': 2, 'LR_SCHEDULER_NAME': 'WarmupMultiStepLR', 'MAX_ITER': 500, 'MOMENTUM': 0.9, 'NESTEROV': False, 'REFERENCE_WORLD_SIZE': 0, 'STEPS': [60000, 80000], 'WARMUP_FACTOR': 0.001, 'WARMUP_ITERS': 1000, 'WARMUP_METHOD': 'linear', 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0.0001, 'WEIGHT_DECAY_NORM': 0.0}, 'TEST': {'AUG': {'ENABLED': False, 'FLIP': True, 'MAX_SIZE': 4000, 'MIN_SIZES': [400, 500, 600, 700, 800, 900, 1000, 1100, 1200]}, 'DETECTIONS_PER_IMAGE': 100, 'EVAL_PERIOD': 0, 'EXPECTED_RESULTS': [], 'KEYPOINT_OKS_SIGMAS': [], 'PRECISE_BN': {'ENABLED': False, 'NUM_ITER': 200}}, 'VERSION': 2, 'VIS_PERIOD': 0}\n",
      "\u001b[32m[08/19 22:21:17 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:21:17 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:21:17 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "\u001b[32m[08/19 22:21:18 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/19 22:21:18 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/19 22:21:18 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/19 22:21:18 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/19 22:21:18 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "\u001b[32m[08/19 22:21:18 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{weight, bias}\u001b[0m\n",
      "Using train for annotations...\n",
      "On dataset: train\n",
      "Classes we're using: Coffeemaker    51\n",
      "Name: ClassName, dtype: int64\n",
      "\u001b[32m[08/19 22:21:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 35 images left.\n",
      "\u001b[32m[08/19 22:21:41 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 35 images left.\n",
      "\u001b[32m[08/19 22:21:41 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/19 22:21:41 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/19 22:21:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/19 22:21:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/19 22:21:41 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/19 22:21:41 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/19 22:21:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/19 22:21:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/19 22:21:41 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/19 22:21:41 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/19 22:21:54 d2.utils.events]: \u001b[0m iter: 20  total_loss: 0.987  loss_cls: 0.856  loss_box_reg: 0.109  loss_rpn_cls: 0.022  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3796M\n",
      "\u001b[32m[08/19 22:21:54 d2.utils.events]: \u001b[0m iter: 20  total_loss: 0.987  loss_cls: 0.856  loss_box_reg: 0.109  loss_rpn_cls: 0.022  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3796M\n",
      "\u001b[32m[08/19 22:22:05 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 40  total_loss: 0.763  loss_cls: 0.568  loss_box_reg: 0.110  loss_rpn_cls: 0.022  loss_rpn_loc: 0.019  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:05 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 40  total_loss: 0.763  loss_cls: 0.568  loss_box_reg: 0.110  loss_rpn_cls: 0.022  loss_rpn_loc: 0.019  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:15 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 60  total_loss: 0.568  loss_cls: 0.383  loss_box_reg: 0.124  loss_rpn_cls: 0.022  loss_rpn_loc: 0.020  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:15 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 60  total_loss: 0.568  loss_cls: 0.383  loss_box_reg: 0.124  loss_rpn_cls: 0.022  loss_rpn_loc: 0.020  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:26 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 80  total_loss: 0.473  loss_cls: 0.301  loss_box_reg: 0.115  loss_rpn_cls: 0.019  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:26 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 80  total_loss: 0.473  loss_cls: 0.301  loss_box_reg: 0.115  loss_rpn_cls: 0.019  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:36 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 100  total_loss: 0.408  loss_cls: 0.241  loss_box_reg: 0.116  loss_rpn_cls: 0.021  loss_rpn_loc: 0.014  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:36 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 100  total_loss: 0.408  loss_cls: 0.241  loss_box_reg: 0.116  loss_rpn_cls: 0.021  loss_rpn_loc: 0.014  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:46 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 120  total_loss: 0.355  loss_cls: 0.217  loss_box_reg: 0.109  loss_rpn_cls: 0.020  loss_rpn_loc: 0.009  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:46 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 120  total_loss: 0.355  loss_cls: 0.217  loss_box_reg: 0.109  loss_rpn_cls: 0.020  loss_rpn_loc: 0.009  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:57 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 140  total_loss: 0.358  loss_cls: 0.193  loss_box_reg: 0.117  loss_rpn_cls: 0.020  loss_rpn_loc: 0.015  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:22:57 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 140  total_loss: 0.358  loss_cls: 0.193  loss_box_reg: 0.117  loss_rpn_cls: 0.020  loss_rpn_loc: 0.015  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:23:08 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 160  total_loss: 0.329  loss_cls: 0.174  loss_box_reg: 0.115  loss_rpn_cls: 0.021  loss_rpn_loc: 0.017  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:23:08 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 160  total_loss: 0.329  loss_cls: 0.174  loss_box_reg: 0.115  loss_rpn_cls: 0.021  loss_rpn_loc: 0.017  lr: 0.000020  max_mem: 3797M\n",
      "\u001b[32m[08/19 22:23:20 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 180  total_loss: 0.318  loss_cls: 0.153  loss_box_reg: 0.105  loss_rpn_cls: 0.023  loss_rpn_loc: 0.012  lr: 0.000020  max_mem: 3798M\n",
      "\u001b[32m[08/19 22:23:20 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 180  total_loss: 0.318  loss_cls: 0.153  loss_box_reg: 0.105  loss_rpn_cls: 0.023  loss_rpn_loc: 0.012  lr: 0.000020  max_mem: 3798M\n",
      "\u001b[32m[08/19 22:23:30 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 200  total_loss: 0.296  loss_cls: 0.145  loss_box_reg: 0.098  loss_rpn_cls: 0.018  loss_rpn_loc: 0.018  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:23:30 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 200  total_loss: 0.296  loss_cls: 0.145  loss_box_reg: 0.098  loss_rpn_cls: 0.018  loss_rpn_loc: 0.018  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:23:42 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 220  total_loss: 0.312  loss_cls: 0.151  loss_box_reg: 0.119  loss_rpn_cls: 0.019  loss_rpn_loc: 0.008  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:23:42 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 220  total_loss: 0.312  loss_cls: 0.151  loss_box_reg: 0.119  loss_rpn_cls: 0.019  loss_rpn_loc: 0.008  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:23:53 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 240  total_loss: 0.306  loss_cls: 0.139  loss_box_reg: 0.120  loss_rpn_cls: 0.022  loss_rpn_loc: 0.018  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:23:53 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 240  total_loss: 0.306  loss_cls: 0.139  loss_box_reg: 0.120  loss_rpn_cls: 0.022  loss_rpn_loc: 0.018  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:04 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 260  total_loss: 0.302  loss_cls: 0.142  loss_box_reg: 0.123  loss_rpn_cls: 0.019  loss_rpn_loc: 0.018  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:04 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 260  total_loss: 0.302  loss_cls: 0.142  loss_box_reg: 0.123  loss_rpn_cls: 0.019  loss_rpn_loc: 0.018  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:15 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 280  total_loss: 0.310  loss_cls: 0.135  loss_box_reg: 0.118  loss_rpn_cls: 0.021  loss_rpn_loc: 0.014  lr: 0.000020  max_mem: 3870M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:24:15 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 280  total_loss: 0.310  loss_cls: 0.135  loss_box_reg: 0.118  loss_rpn_cls: 0.021  loss_rpn_loc: 0.014  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:26 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 300  total_loss: 0.285  loss_cls: 0.134  loss_box_reg: 0.118  loss_rpn_cls: 0.020  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:26 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 300  total_loss: 0.285  loss_cls: 0.134  loss_box_reg: 0.118  loss_rpn_cls: 0.020  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:38 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 320  total_loss: 0.292  loss_cls: 0.139  loss_box_reg: 0.128  loss_rpn_cls: 0.012  loss_rpn_loc: 0.015  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:38 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 320  total_loss: 0.292  loss_cls: 0.139  loss_box_reg: 0.128  loss_rpn_cls: 0.012  loss_rpn_loc: 0.015  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:48 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 340  total_loss: 0.273  loss_cls: 0.122  loss_box_reg: 0.109  loss_rpn_cls: 0.019  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:48 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 340  total_loss: 0.273  loss_cls: 0.122  loss_box_reg: 0.109  loss_rpn_cls: 0.019  loss_rpn_loc: 0.011  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:59 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 360  total_loss: 0.297  loss_cls: 0.134  loss_box_reg: 0.117  loss_rpn_cls: 0.028  loss_rpn_loc: 0.012  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:24:59 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 360  total_loss: 0.297  loss_cls: 0.134  loss_box_reg: 0.117  loss_rpn_cls: 0.028  loss_rpn_loc: 0.012  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:10 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 380  total_loss: 0.289  loss_cls: 0.126  loss_box_reg: 0.124  loss_rpn_cls: 0.016  loss_rpn_loc: 0.010  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:10 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 380  total_loss: 0.289  loss_cls: 0.126  loss_box_reg: 0.124  loss_rpn_cls: 0.016  loss_rpn_loc: 0.010  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:21 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 400  total_loss: 0.255  loss_cls: 0.112  loss_box_reg: 0.105  loss_rpn_cls: 0.016  loss_rpn_loc: 0.009  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:21 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 400  total_loss: 0.255  loss_cls: 0.112  loss_box_reg: 0.105  loss_rpn_cls: 0.016  loss_rpn_loc: 0.009  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:33 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 420  total_loss: 0.303  loss_cls: 0.114  loss_box_reg: 0.110  loss_rpn_cls: 0.013  loss_rpn_loc: 0.013  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:33 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 420  total_loss: 0.303  loss_cls: 0.114  loss_box_reg: 0.110  loss_rpn_cls: 0.013  loss_rpn_loc: 0.013  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:45 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 440  total_loss: 0.258  loss_cls: 0.119  loss_box_reg: 0.113  loss_rpn_cls: 0.020  loss_rpn_loc: 0.013  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:45 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 440  total_loss: 0.258  loss_cls: 0.119  loss_box_reg: 0.113  loss_rpn_cls: 0.020  loss_rpn_loc: 0.013  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:57 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 460  total_loss: 0.289  loss_cls: 0.120  loss_box_reg: 0.125  loss_rpn_cls: 0.017  loss_rpn_loc: 0.015  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:25:57 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 460  total_loss: 0.289  loss_cls: 0.120  loss_box_reg: 0.125  loss_rpn_cls: 0.017  loss_rpn_loc: 0.015  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:26:09 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 480  total_loss: 0.249  loss_cls: 0.105  loss_box_reg: 0.098  loss_rpn_cls: 0.014  loss_rpn_loc: 0.010  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:26:09 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 480  total_loss: 0.249  loss_cls: 0.105  loss_box_reg: 0.098  loss_rpn_cls: 0.014  loss_rpn_loc: 0.010  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:26:20 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/19 22:26:26 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 500  total_loss: 0.269  loss_cls: 0.113  loss_box_reg: 0.123  loss_rpn_cls: 0.015  loss_rpn_loc: 0.010  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:26:26 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 500  total_loss: 0.269  loss_cls: 0.113  loss_box_reg: 0.123  loss_rpn_cls: 0.015  loss_rpn_loc: 0.010  lr: 0.000020  max_mem: 3870M\n",
      "\u001b[32m[08/19 22:26:26 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "Using validation for annotations...\n",
      "On dataset: validation\n",
      "Classes we're using: Coffeemaker    18\n",
      "Name: ClassName, dtype: int64\n",
      "\u001b[32m[08/19 22:26:32 d2.data.common]: \u001b[0mSerializing 17 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/19 22:26:32 d2.data.common]: \u001b[0mSerializing 17 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/19 22:26:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/19 22:26:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/19 22:26:32 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/19 22:26:32 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/19 22:26:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 17 images\n",
      "\u001b[32m[08/19 22:26:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 17 images\n",
      "\u001b[32m[08/19 22:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/17. 0.1398 s / img. ETA=0:00:00\n",
      "\u001b[32m[08/19 22:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/17. 0.1398 s / img. ETA=0:00:00\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.650151 (0.137513 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:01.650151 (0.137513 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.134154 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:01 (0.134154 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/Coffeemaker/coco_instances_results.json\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/Coffeemaker/coco_instances_results.json\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.489\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.494\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.053 | 30.935 | 2.952  |  nan  |  nan  | 13.527 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.053 | 30.935 | 2.952  |  nan  |  nan  | 13.527 |\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "### Returning results_i...\n",
      "OrderedDict([('bbox', {'AP': 11.05339551469239, 'AP50': 30.93535494399573, 'AP75': 2.9524258093825573, 'APs': nan, 'APm': nan, 'APl': 13.527326828326483})])\n",
      "\u001b[32m[08/19 22:26:35 detectron2]: \u001b[0mEvaluation results for validation/Coffeemaker in csv format:\n",
      "\u001b[32m[08/19 22:26:35 detectron2]: \u001b[0mEvaluation results for validation/Coffeemaker in csv format:\n",
      "### Calculating results...\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.testing]: \u001b[0mcopypaste: 11.0534,30.9354,2.9524,nan,nan,13.5273\n",
      "\u001b[32m[08/19 22:26:35 d2.evaluation.testing]: \u001b[0mcopypaste: 11.0534,30.9354,2.9524,nan,nan,13.5273\n",
      "### Returning results...\n",
      "OrderedDict([('bbox', {'AP': 11.05339551469239, 'AP50': 30.93535494399573, 'AP75': 2.9524258093825573, 'APs': nan, 'APm': nan, 'APl': 13.527326828326483})])\n",
      "### Saving results to Weights & Biases...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 11.05339551469239,\n",
       "               'AP50': 30.93535494399573,\n",
       "               'AP75': 2.9524258093825573,\n",
       "               'APs': nan,\n",
       "               'APm': nan,\n",
       "               'APl': 13.527326828326483})])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderedDict([('bbox',\n",
    "              {'AP': 11.05339551469239,\n",
    "               'AP50': 30.93535494399573,\n",
    "               'AP75': 2.9524258093825573,\n",
    "               'APs': nan,\n",
    "               'APm': nan,\n",
    "               'APl': 13.527326828326483})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:57.757318Z",
     "start_time": "2020-08-23T14:21:57.724755Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Changed from original: Create evaluator for COCOEvaluator only\n",
    "# Since we are only using bounding boxes to begin with, our evaluator can be simple COCO style\n",
    "def get_evaluator(cfg, dataset_name, output_folder=None):\n",
    "    \"\"\"\n",
    "    Create a COCOEvaluator\n",
    "    \"\"\"\n",
    "    if output_folder is None:\n",
    "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "    evaluator = COCOEvaluator(dataset_name=dataset_name,\n",
    "                              cfg=cfg,\n",
    "                              distributed=False,\n",
    "                              output_dir=output_folder)\n",
    "    return evaluator\n",
    "\n",
    "\n",
    "# Create testing function\n",
    "def do_test(cfg, model):\n",
    "    results = OrderedDict()\n",
    "    for dataset_name in cfg.DATASETS.TEST:\n",
    "        data_loader = build_detection_test_loader(cfg, dataset_name)\n",
    "        # Create the evaluator\n",
    "        evaluator = get_evaluator(cfg,\n",
    "                                  dataset_name,\n",
    "                                  output_folder=os.path.join(\n",
    "                                      cfg.OUTPUT_DIR, \"inference\",\n",
    "                                      dataset_name))\n",
    "        # Make inference on dataset\n",
    "        results_i = inference_on_dataset(model, data_loader, evaluator)\n",
    "        # Update results dictionary\n",
    "        results[dataset_name] = results_i\n",
    "\n",
    "        print(\"### Returning results_i...\")\n",
    "        #print(results_i)\n",
    "        #print(f\"### Average Precision: {results_i['AP']}\")\n",
    "        # Let's get some communication happening\n",
    "        if comm.is_main_process():\n",
    "            logger.info(\"Evaluation results for {} in csv format:\".format(\n",
    "                dataset_name))\n",
    "            ## wandb.log()? TODO/NOTE: This may be something Weights & Biases can track\n",
    "            #print(\"### Calculating results...\")\n",
    "            print_csv_format(results_i)\n",
    "\n",
    "        # Check to see length of results\n",
    "        if len(results) == 1:\n",
    "            results = list(results.values())[0]\n",
    "        #print(\"### Returning results...\")\n",
    "        #print(results)\n",
    "\n",
    "        # TODO : log results_i dict with different parameters\n",
    "        print(\"### Saving results to Weights & Biases...\")\n",
    "        wandb.log(results_i)\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "# Create training function\n",
    "def do_train(cfg, model, resume=False):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    # Create optimizer from config file (returns torch.nn.optimizer.Optimizer)\n",
    "    optimizer = build_optimizer(cfg, model)\n",
    "    # Create scheduler for learning rate (returns torch.optim.lr._LR_scheduler)\n",
    "    scheduler = build_lr_scheduler(cfg, optimizer)\n",
    "    print(f\"Scheduler: {scheduler}\")\n",
    "\n",
    "    # Create checkpointer\n",
    "    checkpointer = DetectionCheckpointer(model,\n",
    "                                         save_dir=cfg.OUTPUT_DIR,\n",
    "                                         optimizer=optimizer,\n",
    "                                         scheduler=scheduler)\n",
    "\n",
    "    # Create start iteration (refernces checkpointer) - https://detectron2.readthedocs.io/modules/checkpoint.html#detectron2.checkpoint.Checkpointer.resume_or_load\n",
    "    start_iter = (\n",
    "        # This can be 0\n",
    "        checkpointer.resume_or_load(\n",
    "            cfg.MODEL.\n",
    "            WEIGHTS,  # Use predefined model weights (pretrained model)\n",
    "            resume=resume).get(\"iteration\", -1) + 1)\n",
    "    # Set max number of iterations\n",
    "    max_iter = cfg.SOLVER.MAX_ITER\n",
    "\n",
    "    # Create periodiccheckpoint\n",
    "    periodic_checkpointer = PeriodicCheckpointer(\n",
    "        checkpointer=checkpointer,\n",
    "        # How often to make checkpoints?\n",
    "        period=cfg.SOLVER.CHECKPOINT_PERIOD,\n",
    "        max_iter=max_iter)\n",
    "\n",
    "    # Create writers (for saving checkpoints?)\n",
    "    writers = ([\n",
    "        # Print out common metrics such as iteration time, ETA, memory, all losses, learning rate\n",
    "        CommonMetricPrinter(max_iter=max_iter),\n",
    "        # Write scalars to a JSON file such as loss values, time and more\n",
    "        JSONWriter(os.path.join(cfg.OUTPUT_DIR, \"metrics.json\")),\n",
    "        # Write all scalars such as loss values to a TensorBoard file for easy visualization\n",
    "        TensorboardXWriter(cfg.OUTPUT_DIR),\n",
    "    ] if comm.is_main_process() else [])\n",
    "\n",
    "    ### Original note from script: ###\n",
    "    # compared to \"train_net.py\", we do not support accurate timing and precise BN\n",
    "    # here, because they are not trivial to implement\n",
    "\n",
    "    # Build a training data loader based off the training dataset name in the config\n",
    "    data_loader = build_detection_train_loader(cfg)\n",
    "\n",
    "    # Start logging\n",
    "    logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
    "\n",
    "    # Store events\n",
    "    with EventStorage(start_iter) as storage:\n",
    "        # Loop through zipped data loader and iteration\n",
    "        for data, iteration in zip(data_loader, range(start_iter, max_iter)):\n",
    "            iteration = iteration + 1\n",
    "            storage.step(\n",
    "            )  # update stroage with step - https://detectron2.readthedocs.io/modules/utils.html#detectron2.utils.events.EventStorage.step\n",
    "\n",
    "            # Create loss dictionary by trying to model data\n",
    "            loss_dict = model(data)\n",
    "            losses = sum(loss_dict.values())\n",
    "            # Are losses infinite? If so, something is wrong\n",
    "            assert torch.isfinite(losses).all(), loss_dict\n",
    "\n",
    "            # TODO - Not quite sure what's happening here\n",
    "            loss_dict_reduced = {\n",
    "                k: v.item()\n",
    "                for k, v in comm.reduce_dict(loss_dict).items()\n",
    "            }\n",
    "            # Sum up losses\n",
    "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
    "\n",
    "            # # TODO: wandb.log()? log the losses\n",
    "            # wandb.log({\n",
    "            #         \"Total loss\": losses_reduced\n",
    "            # })\n",
    "\n",
    "            # Update storage\n",
    "            if comm.is_main_process():\n",
    "                # Store informate in storage - https://detectron2.readthedocs.io/modules/utils.html#detectron2.utils.events.EventStorage.put_scalars\n",
    "                storage.put_scalars(total_loss=losses_reduced,\n",
    "                                    **loss_dict_reduced)\n",
    "\n",
    "            # Start doing PyTorch things\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            # Add learning rate to storage information\n",
    "            storage.put_scalar(\"lr\",\n",
    "                               optimizer.param_groups[0][\"lr\"],\n",
    "                               smoothing_hint=False)\n",
    "            # This is required for your learning rate to change!!!! (not having this meant my learning rate was staying at 0)\n",
    "            scheduler.step()\n",
    "\n",
    "            # Perform evaluation?\n",
    "            if (cfg.TEST.EVAL_PERIOD > 0\n",
    "                    and iteration % cfg.TEST.EVAL_PERIOD == 0\n",
    "                    and iteration != max_iter):\n",
    "                do_test(cfg, model)\n",
    "                # TODO - compared to \"train_net.py\", the test results are not dumped to EventStorage\n",
    "                comm.synchronize()\n",
    "\n",
    "            # Log different metrics with writers\n",
    "            if iteration - start_iter > 5 and (iteration % 20 == 0\n",
    "                                               or iteration == max_iter):\n",
    "                for writer in writers:\n",
    "                    writer.write()\n",
    "\n",
    "            # Update the periodic_checkpointer\n",
    "            periodic_checkpointer.step(iteration)\n",
    "\n",
    "\n",
    "# Create setup function\n",
    "def setup(args):\n",
    "    \"\"\"\n",
    "    Create configs and perform basic setups.\n",
    "    \"\"\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(\n",
    "        args.config_file)  # This will take some kind of model.yaml file\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.freeze()\n",
    "    default_setup(\n",
    "        cfg, args\n",
    "    )  # this logs the config and arguments passed to the command line to the output file\n",
    "\n",
    "    # Load config YAML as dict\n",
    "    cfg_yaml = cfg.load_yaml_with_base(\n",
    "        os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"))\n",
    "\n",
    "    # default_config = get_cfg()\n",
    "    # default_config_loaded = default_config.load_yaml_with_base(\"output/config.yaml\")\n",
    "    # default_config_loaded\n",
    "\n",
    "    # TODO: turn config into YAML and save to weights & biases\n",
    "    # TODO: Init wandb and add configs\n",
    "    # Setup a new weights & biases run every time we run the setup() function\n",
    "    wandb.init(project=\"airbnb-object-detection\", sync_tensorboard=True)\n",
    "\n",
    "    #print(\"### Printing config_yaml file to go into Weights & Biases\")\n",
    "    #print(cfg_yaml)\n",
    "    wandb.config.update(cfg_yaml)\n",
    "\n",
    "    return cfg\n",
    "\n",
    "# Create main function\n",
    "def main(args):\n",
    "    \n",
    "    # Create the config file\n",
    "    cfg = setup(args)\n",
    "\n",
    "    # Build the model\n",
    "    model = build_model(cfg)\n",
    "    \n",
    "    # Log what's going on\n",
    "    logger.info(\"Model:\\n{}\".format(model))\n",
    "\n",
    "    # TODO: Fix this (if it doesn't work)\n",
    "    #wandb.watch(model, log=\"all\")\n",
    "\n",
    "    # Only do evaluation if the args say so\n",
    "    if args.eval_only:\n",
    "        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
    "                cfg.MODEL.WEIGHTS, resume=args.resume\n",
    "        )\n",
    "        return do_test(cfg, model)\n",
    "\n",
    "    # Do distributed training? (depends on number of GPUs available)\n",
    "    distributed = comm.get_world_size() > 1\n",
    "    if distributed:\n",
    "        # Put the model on multiple devices if available\n",
    "        model = DistributedDataParallel(\n",
    "                model, \n",
    "                device_ids=[comm.get_local_rank()], \n",
    "                broadcast_buffers=False\n",
    "        )\n",
    "\n",
    "    # Train the model\n",
    "    do_train(cfg, model)\n",
    "    # TODO - May want to evaluate in a different step?\n",
    "    return do_test(cfg, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the models we try on subset data to come up with the best architecture in terms of performance and time trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T16:40:48.262617Z",
     "start_time": "2020-08-22T16:40:28.008422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train-annotations-bbox.csv for annotations...\n",
      "On dataset: train\n",
      "Classes we're using:\n",
      " Bathtub        113\n",
      "Tree house     110\n",
      "Coffeemaker     51\n",
      "Name: ClassName, dtype: int64\n",
      "Total number of images: 252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f8a6cceb584508966b934fedaa8354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving labels to: train/cmaker-bathtub-treehouse-train/train_labels.json...\n"
     ]
    }
   ],
   "source": [
    "## Generate JSON label file\n",
    "\n",
    "_ = get_image_dicts('train/cmaker-bathtub-treehouse-train',\n",
    "                     'train-annotations-bbox.csv',['Bathtub', 'Coffeemaker', 'Tree house'])\n",
    "\n",
    "_ = get_image_dicts('validation/cmaker-bathtub-treehouse-validation',\n",
    "                    'validation-annotations-bbox.csv',['Bathtub', 'Coffeemaker', 'Tree house'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:57.868396Z",
     "start_time": "2020-08-23T14:21:57.758294Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"R50-FPN-1x\": \"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\",\n",
    "    \"R50-FPN-3x\": \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"R101-FPN-3x\": \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"X101-FPN-3x\": \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "    \"RN-R50-1x\": \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\",\n",
    "    \"RN-R50-3x\": \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\",\n",
    "    \"RN-R101-3x\": \"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing data subset from coffeemaker, bathtub, treehouse classes only are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:57.950908Z",
     "start_time": "2020-08-23T14:21:57.869187Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering: cmaker-bathtub-treehouse-train\n",
      "Registering: cmaker-bathtub-treehouse-validation\n"
     ]
    }
   ],
   "source": [
    "# Setup arg parser\n",
    "parser = default_argument_parser()\n",
    "\n",
    "# register new datasets\n",
    "cmaker_bathtub_metadata = register_datasets('train/cmaker-bathtub-treehouse-train',\n",
    "                  'validation/cmaker-bathtub-treehouse-validation',\n",
    "                  target_cls=[\"Bathtub\", \"Coffeemaker\", \"Tree house\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:58.044843Z",
     "start_time": "2020-08-23T14:21:57.952369Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml',\n",
       " 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',\n",
       " 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml',\n",
       " 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml',\n",
       " 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml',\n",
       " 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml',\n",
       " 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl': '/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup different weights and config files to try\n",
    "weights = []\n",
    "configs = []\n",
    "for k, v in models.items():\n",
    "    model = models[k]\n",
    "    model_weights = model_zoo.get_checkpoint_url(model)\n",
    "    weights.append(model_weights)\n",
    "    config_file = model_zoo.get_config_file(model)\n",
    "    configs.append(config_file)\n",
    "    weights_configs = dict(zip(weights, configs))\n",
    "weights_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:58.138650Z",
     "start_time": "2020-08-23T14:21:58.046139Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Setup different arg strings to pass to main() \n",
    "workers = 2\n",
    "ims_per_batch = 1                    # lower memory issues \n",
    "lr = 0.00025\n",
    "max_iter = 3000\n",
    "seed = 33                            # for reproducibility\n",
    "num_classes = 3\n",
    "\n",
    "arg_strings = []\n",
    "for weights, config in weights_configs.items(): # try out diff models\n",
    "    arg_string = f\"--config-file {config} \\\n",
    "                MODEL.WEIGHTS {weights} \\\n",
    "                DATASETS.TRAIN ('train/cmaker-bathtub-treehouse-train',) \\\n",
    "                DATASETS.TEST ('validation/cmaker-bathtub-treehouse-validation',) \\\n",
    "                DATALOADER.NUM_WORKERS {workers} \\\n",
    "                SOLVER.IMS_PER_BATCH {ims_per_batch} \\\n",
    "                SOLVER.BASE_LR {lr} \\\n",
    "                SOLVER.MAX_ITER {max_iter} \\\n",
    "                SEED {seed} \\\n",
    "                MODEL.ROI_HEADS.NUM_CLASSES {num_classes}\".split()\n",
    "    arg_strings.append(arg_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T14:29:43.916906Z",
     "start_time": "2020-08-21T14:29:43.899570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arg_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:58.298872Z",
     "start_time": "2020-08-23T14:21:58.139809Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Create different arg parsers\n",
    "arg_list = []\n",
    "for arg_string in arg_strings:\n",
    "    args = parser.parse_args(arg_string)\n",
    "    arg_list.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:21:58.479362Z",
     "start_time": "2020-08-23T14:21:58.300057Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T16:38:32.200943Z",
     "start_time": "2020-08-23T14:22:02.631619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>> Running experiment: 0\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 19:52:02 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/1mu8nnjl\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/1mu8nnjl</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:52:07 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:52:07 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd3802e070>\n",
      "\u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "\u001b[32m[08/23 19:52:07 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_1x/137257794/model_final_b275ba.pkl\n",
      "\u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "\u001b[32m[08/23 19:52:07 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{weight, bias}\u001b[0m\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[32m[08/23 19:52:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 19:52:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 19:52:07 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "|  Bathtub   | 113          | Coffeemaker | 51           | Tree house | 110          |\n",
      "|            |              |             |              |            |              |\n",
      "|   total    | 274          |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[08/23 19:52:07 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "|  Bathtub   | 113          | Coffeemaker | 51           | Tree house | 110          |\n",
      "|            |              |             |              |            |              |\n",
      "|   total    | 274          |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[08/23 19:52:07 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 19:52:07 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 19:52:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 19:52:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 19:52:07 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 19:52:07 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 19:52:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 19:52:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 19:52:07 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 19:52:07 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 19:52:12 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.634  loss_cls: 1.468  loss_box_reg: 0.096  loss_rpn_cls: 0.013  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 1508M\n",
      "\u001b[32m[08/23 19:52:12 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.634  loss_cls: 1.468  loss_box_reg: 0.096  loss_rpn_cls: 0.013  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 1508M\n",
      "\u001b[32m[08/23 19:52:18 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 40  total_loss: 1.530  loss_cls: 1.372  loss_box_reg: 0.086  loss_rpn_cls: 0.019  loss_rpn_loc: 0.008  lr: 0.000010  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:18 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 40  total_loss: 1.530  loss_cls: 1.372  loss_box_reg: 0.086  loss_rpn_cls: 0.019  loss_rpn_loc: 0.008  lr: 0.000010  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:25 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 60  total_loss: 1.314  loss_cls: 1.123  loss_box_reg: 0.106  loss_rpn_cls: 0.027  loss_rpn_loc: 0.009  lr: 0.000015  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:25 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 60  total_loss: 1.314  loss_cls: 1.123  loss_box_reg: 0.106  loss_rpn_cls: 0.027  loss_rpn_loc: 0.009  lr: 0.000015  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:31 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 80  total_loss: 1.041  loss_cls: 0.899  loss_box_reg: 0.081  loss_rpn_cls: 0.014  loss_rpn_loc: 0.008  lr: 0.000020  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:31 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 80  total_loss: 1.041  loss_cls: 0.899  loss_box_reg: 0.081  loss_rpn_cls: 0.014  loss_rpn_loc: 0.008  lr: 0.000020  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:36 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 100  total_loss: 0.764  loss_cls: 0.628  loss_box_reg: 0.080  loss_rpn_cls: 0.023  loss_rpn_loc: 0.005  lr: 0.000025  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:36 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 100  total_loss: 0.764  loss_cls: 0.628  loss_box_reg: 0.080  loss_rpn_cls: 0.023  loss_rpn_loc: 0.005  lr: 0.000025  max_mem: 1509M\n",
      "\u001b[32m[08/23 19:52:42 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 120  total_loss: 0.602  loss_cls: 0.422  loss_box_reg: 0.088  loss_rpn_cls: 0.010  loss_rpn_loc: 0.015  lr: 0.000030  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:42 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 120  total_loss: 0.602  loss_cls: 0.422  loss_box_reg: 0.088  loss_rpn_cls: 0.010  loss_rpn_loc: 0.015  lr: 0.000030  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:47 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 140  total_loss: 0.454  loss_cls: 0.308  loss_box_reg: 0.092  loss_rpn_cls: 0.012  loss_rpn_loc: 0.006  lr: 0.000035  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:47 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 140  total_loss: 0.454  loss_cls: 0.308  loss_box_reg: 0.092  loss_rpn_cls: 0.012  loss_rpn_loc: 0.006  lr: 0.000035  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:53 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 160  total_loss: 0.385  loss_cls: 0.216  loss_box_reg: 0.094  loss_rpn_cls: 0.012  loss_rpn_loc: 0.013  lr: 0.000040  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:53 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 160  total_loss: 0.385  loss_cls: 0.216  loss_box_reg: 0.094  loss_rpn_cls: 0.012  loss_rpn_loc: 0.013  lr: 0.000040  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:58 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 180  total_loss: 0.339  loss_cls: 0.196  loss_box_reg: 0.103  loss_rpn_cls: 0.014  loss_rpn_loc: 0.011  lr: 0.000045  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:52:58 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 180  total_loss: 0.339  loss_cls: 0.196  loss_box_reg: 0.103  loss_rpn_cls: 0.014  loss_rpn_loc: 0.011  lr: 0.000045  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:03 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 200  total_loss: 0.317  loss_cls: 0.153  loss_box_reg: 0.096  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  lr: 0.000050  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:03 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 200  total_loss: 0.317  loss_cls: 0.153  loss_box_reg: 0.096  loss_rpn_cls: 0.004  loss_rpn_loc: 0.016  lr: 0.000050  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:53:09 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 220  total_loss: 0.235  loss_cls: 0.121  loss_box_reg: 0.078  loss_rpn_cls: 0.011  loss_rpn_loc: 0.012  lr: 0.000055  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:09 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 220  total_loss: 0.235  loss_cls: 0.121  loss_box_reg: 0.078  loss_rpn_cls: 0.011  loss_rpn_loc: 0.012  lr: 0.000055  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:14 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 240  total_loss: 0.285  loss_cls: 0.143  loss_box_reg: 0.116  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000060  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:14 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 240  total_loss: 0.285  loss_cls: 0.143  loss_box_reg: 0.116  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000060  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:20 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 260  total_loss: 0.304  loss_cls: 0.152  loss_box_reg: 0.132  loss_rpn_cls: 0.008  loss_rpn_loc: 0.009  lr: 0.000065  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:20 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 260  total_loss: 0.304  loss_cls: 0.152  loss_box_reg: 0.132  loss_rpn_cls: 0.008  loss_rpn_loc: 0.009  lr: 0.000065  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:25 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 280  total_loss: 0.246  loss_cls: 0.115  loss_box_reg: 0.103  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000070  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:25 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 280  total_loss: 0.246  loss_cls: 0.115  loss_box_reg: 0.103  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000070  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:30 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 300  total_loss: 0.262  loss_cls: 0.116  loss_box_reg: 0.090  loss_rpn_cls: 0.019  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:30 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 300  total_loss: 0.262  loss_cls: 0.116  loss_box_reg: 0.090  loss_rpn_cls: 0.019  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:35 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 320  total_loss: 0.246  loss_cls: 0.130  loss_box_reg: 0.100  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000080  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:35 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 320  total_loss: 0.246  loss_cls: 0.130  loss_box_reg: 0.100  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000080  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:41 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 340  total_loss: 0.234  loss_cls: 0.105  loss_box_reg: 0.096  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  lr: 0.000085  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:41 d2.utils.events]: \u001b[0m eta: 0:11:41  iter: 340  total_loss: 0.234  loss_cls: 0.105  loss_box_reg: 0.096  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  lr: 0.000085  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:46 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 360  total_loss: 0.227  loss_cls: 0.103  loss_box_reg: 0.094  loss_rpn_cls: 0.009  loss_rpn_loc: 0.008  lr: 0.000090  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:46 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 360  total_loss: 0.227  loss_cls: 0.103  loss_box_reg: 0.094  loss_rpn_cls: 0.009  loss_rpn_loc: 0.008  lr: 0.000090  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:51 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 380  total_loss: 0.275  loss_cls: 0.107  loss_box_reg: 0.099  loss_rpn_cls: 0.007  loss_rpn_loc: 0.015  lr: 0.000095  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:51 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 380  total_loss: 0.275  loss_cls: 0.107  loss_box_reg: 0.099  loss_rpn_cls: 0.007  loss_rpn_loc: 0.015  lr: 0.000095  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:56 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 400  total_loss: 0.264  loss_cls: 0.106  loss_box_reg: 0.096  loss_rpn_cls: 0.007  loss_rpn_loc: 0.006  lr: 0.000100  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:53:56 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 400  total_loss: 0.264  loss_cls: 0.106  loss_box_reg: 0.096  loss_rpn_cls: 0.007  loss_rpn_loc: 0.006  lr: 0.000100  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:02 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 420  total_loss: 0.220  loss_cls: 0.097  loss_box_reg: 0.098  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  lr: 0.000105  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:02 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 420  total_loss: 0.220  loss_cls: 0.097  loss_box_reg: 0.098  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  lr: 0.000105  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:08 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 440  total_loss: 0.241  loss_cls: 0.099  loss_box_reg: 0.118  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000110  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:08 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 440  total_loss: 0.241  loss_cls: 0.099  loss_box_reg: 0.118  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000110  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:13 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 460  total_loss: 0.251  loss_cls: 0.105  loss_box_reg: 0.111  loss_rpn_cls: 0.007  loss_rpn_loc: 0.012  lr: 0.000115  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:13 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 460  total_loss: 0.251  loss_cls: 0.105  loss_box_reg: 0.111  loss_rpn_cls: 0.007  loss_rpn_loc: 0.012  lr: 0.000115  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:18 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 480  total_loss: 0.222  loss_cls: 0.087  loss_box_reg: 0.091  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000120  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:18 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 480  total_loss: 0.222  loss_cls: 0.087  loss_box_reg: 0.091  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000120  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:24 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 500  total_loss: 0.251  loss_cls: 0.122  loss_box_reg: 0.110  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  lr: 0.000125  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:24 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 500  total_loss: 0.251  loss_cls: 0.122  loss_box_reg: 0.110  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  lr: 0.000125  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:30 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 520  total_loss: 0.199  loss_cls: 0.080  loss_box_reg: 0.087  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000130  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:30 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 520  total_loss: 0.199  loss_cls: 0.080  loss_box_reg: 0.087  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000130  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:35 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 540  total_loss: 0.269  loss_cls: 0.111  loss_box_reg: 0.120  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  lr: 0.000135  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:35 d2.utils.events]: \u001b[0m eta: 0:11:03  iter: 540  total_loss: 0.269  loss_cls: 0.111  loss_box_reg: 0.120  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  lr: 0.000135  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:41 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 560  total_loss: 0.269  loss_cls: 0.098  loss_box_reg: 0.122  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  lr: 0.000140  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:41 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 560  total_loss: 0.269  loss_cls: 0.098  loss_box_reg: 0.122  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  lr: 0.000140  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:46 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 580  total_loss: 0.218  loss_cls: 0.089  loss_box_reg: 0.107  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  lr: 0.000145  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:46 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 580  total_loss: 0.218  loss_cls: 0.089  loss_box_reg: 0.107  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  lr: 0.000145  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:52 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 600  total_loss: 0.216  loss_cls: 0.079  loss_box_reg: 0.089  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  lr: 0.000150  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:52 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 600  total_loss: 0.216  loss_cls: 0.079  loss_box_reg: 0.089  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  lr: 0.000150  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:57 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 620  total_loss: 0.191  loss_cls: 0.073  loss_box_reg: 0.088  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  lr: 0.000155  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:54:57 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 620  total_loss: 0.191  loss_cls: 0.073  loss_box_reg: 0.088  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  lr: 0.000155  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:55:03 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 640  total_loss: 0.201  loss_cls: 0.082  loss_box_reg: 0.100  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  lr: 0.000160  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:03 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 640  total_loss: 0.201  loss_cls: 0.082  loss_box_reg: 0.100  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  lr: 0.000160  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:08 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 660  total_loss: 0.287  loss_cls: 0.116  loss_box_reg: 0.148  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  lr: 0.000165  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:08 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 660  total_loss: 0.287  loss_cls: 0.116  loss_box_reg: 0.148  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  lr: 0.000165  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:14 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 680  total_loss: 0.208  loss_cls: 0.098  loss_box_reg: 0.091  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000170  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:14 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 680  total_loss: 0.208  loss_cls: 0.098  loss_box_reg: 0.091  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000170  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:19 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 700  total_loss: 0.204  loss_cls: 0.072  loss_box_reg: 0.091  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  lr: 0.000175  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:19 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 700  total_loss: 0.204  loss_cls: 0.072  loss_box_reg: 0.091  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  lr: 0.000175  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:25 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 720  total_loss: 0.273  loss_cls: 0.107  loss_box_reg: 0.133  loss_rpn_cls: 0.009  loss_rpn_loc: 0.007  lr: 0.000180  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:25 d2.utils.events]: \u001b[0m eta: 0:11:36  iter: 720  total_loss: 0.273  loss_cls: 0.107  loss_box_reg: 0.133  loss_rpn_cls: 0.009  loss_rpn_loc: 0.007  lr: 0.000180  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:31 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 740  total_loss: 0.252  loss_cls: 0.079  loss_box_reg: 0.110  loss_rpn_cls: 0.007  loss_rpn_loc: 0.010  lr: 0.000185  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:31 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 740  total_loss: 0.252  loss_cls: 0.079  loss_box_reg: 0.110  loss_rpn_cls: 0.007  loss_rpn_loc: 0.010  lr: 0.000185  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:36 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 760  total_loss: 0.207  loss_cls: 0.075  loss_box_reg: 0.092  loss_rpn_cls: 0.005  loss_rpn_loc: 0.011  lr: 0.000190  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:36 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 760  total_loss: 0.207  loss_cls: 0.075  loss_box_reg: 0.092  loss_rpn_cls: 0.005  loss_rpn_loc: 0.011  lr: 0.000190  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:42 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 780  total_loss: 0.203  loss_cls: 0.076  loss_box_reg: 0.106  loss_rpn_cls: 0.004  loss_rpn_loc: 0.013  lr: 0.000195  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:42 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 780  total_loss: 0.203  loss_cls: 0.076  loss_box_reg: 0.106  loss_rpn_cls: 0.004  loss_rpn_loc: 0.013  lr: 0.000195  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:48 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 800  total_loss: 0.189  loss_cls: 0.069  loss_box_reg: 0.097  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000200  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:48 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 800  total_loss: 0.189  loss_cls: 0.069  loss_box_reg: 0.097  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000200  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:54 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 820  total_loss: 0.224  loss_cls: 0.080  loss_box_reg: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000205  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:54 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 820  total_loss: 0.224  loss_cls: 0.080  loss_box_reg: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000205  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:59 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 840  total_loss: 0.209  loss_cls: 0.065  loss_box_reg: 0.099  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000210  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:55:59 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 840  total_loss: 0.209  loss_cls: 0.065  loss_box_reg: 0.099  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000210  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:05 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 860  total_loss: 0.176  loss_cls: 0.058  loss_box_reg: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  lr: 0.000215  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:05 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 860  total_loss: 0.176  loss_cls: 0.058  loss_box_reg: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  lr: 0.000215  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:11 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 880  total_loss: 0.214  loss_cls: 0.085  loss_box_reg: 0.085  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  lr: 0.000220  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:11 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 880  total_loss: 0.214  loss_cls: 0.085  loss_box_reg: 0.085  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  lr: 0.000220  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:16 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 900  total_loss: 0.199  loss_cls: 0.065  loss_box_reg: 0.093  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  lr: 0.000225  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:16 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 900  total_loss: 0.199  loss_cls: 0.065  loss_box_reg: 0.093  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  lr: 0.000225  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:22 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 920  total_loss: 0.184  loss_cls: 0.065  loss_box_reg: 0.096  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  lr: 0.000230  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:22 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 920  total_loss: 0.184  loss_cls: 0.065  loss_box_reg: 0.096  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  lr: 0.000230  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:27 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 940  total_loss: 0.261  loss_cls: 0.094  loss_box_reg: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000235  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:27 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 940  total_loss: 0.261  loss_cls: 0.094  loss_box_reg: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000235  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:32 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 960  total_loss: 0.251  loss_cls: 0.102  loss_box_reg: 0.125  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000240  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:32 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 960  total_loss: 0.251  loss_cls: 0.102  loss_box_reg: 0.125  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000240  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:38 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 980  total_loss: 0.193  loss_cls: 0.072  loss_box_reg: 0.100  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  lr: 0.000245  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:38 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 980  total_loss: 0.193  loss_cls: 0.072  loss_box_reg: 0.100  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  lr: 0.000245  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:43 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1000  total_loss: 0.152  loss_cls: 0.045  loss_box_reg: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:43 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1000  total_loss: 0.152  loss_cls: 0.045  loss_box_reg: 0.074  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:50 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 1020  total_loss: 0.172  loss_cls: 0.054  loss_box_reg: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:50 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 1020  total_loss: 0.172  loss_cls: 0.054  loss_box_reg: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:55 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1040  total_loss: 0.150  loss_cls: 0.042  loss_box_reg: 0.076  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:56:55 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1040  total_loss: 0.150  loss_cls: 0.042  loss_box_reg: 0.076  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:57:02 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 1060  total_loss: 0.200  loss_cls: 0.059  loss_box_reg: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:02 d2.utils.events]: \u001b[0m eta: 0:10:33  iter: 1060  total_loss: 0.200  loss_cls: 0.059  loss_box_reg: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:07 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1080  total_loss: 0.190  loss_cls: 0.064  loss_box_reg: 0.099  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:07 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1080  total_loss: 0.190  loss_cls: 0.064  loss_box_reg: 0.099  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:13 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 1100  total_loss: 0.138  loss_cls: 0.044  loss_box_reg: 0.079  loss_rpn_cls: 0.005  loss_rpn_loc: 0.015  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:13 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 1100  total_loss: 0.138  loss_cls: 0.044  loss_box_reg: 0.079  loss_rpn_cls: 0.005  loss_rpn_loc: 0.015  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:18 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 1120  total_loss: 0.184  loss_cls: 0.062  loss_box_reg: 0.094  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:18 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 1120  total_loss: 0.184  loss_cls: 0.062  loss_box_reg: 0.094  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:24 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 1140  total_loss: 0.201  loss_cls: 0.067  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:24 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 1140  total_loss: 0.201  loss_cls: 0.067  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:29 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 1160  total_loss: 0.184  loss_cls: 0.057  loss_box_reg: 0.081  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:29 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 1160  total_loss: 0.184  loss_cls: 0.057  loss_box_reg: 0.081  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:35 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 1180  total_loss: 0.235  loss_cls: 0.074  loss_box_reg: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:35 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 1180  total_loss: 0.235  loss_cls: 0.074  loss_box_reg: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:40 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 1200  total_loss: 0.187  loss_cls: 0.065  loss_box_reg: 0.095  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:40 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 1200  total_loss: 0.187  loss_cls: 0.065  loss_box_reg: 0.095  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:45 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 1220  total_loss: 0.205  loss_cls: 0.064  loss_box_reg: 0.096  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:45 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 1220  total_loss: 0.205  loss_cls: 0.064  loss_box_reg: 0.096  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:51 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1240  total_loss: 0.167  loss_cls: 0.053  loss_box_reg: 0.085  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:51 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1240  total_loss: 0.167  loss_cls: 0.053  loss_box_reg: 0.085  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:56 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 1260  total_loss: 0.158  loss_cls: 0.049  loss_box_reg: 0.082  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:57:56 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 1260  total_loss: 0.158  loss_cls: 0.049  loss_box_reg: 0.082  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:02 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 1280  total_loss: 0.208  loss_cls: 0.059  loss_box_reg: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:02 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 1280  total_loss: 0.208  loss_cls: 0.059  loss_box_reg: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:08 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 1300  total_loss: 0.161  loss_cls: 0.051  loss_box_reg: 0.090  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:08 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 1300  total_loss: 0.161  loss_cls: 0.051  loss_box_reg: 0.090  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:13 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 1320  total_loss: 0.146  loss_cls: 0.048  loss_box_reg: 0.075  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:13 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 1320  total_loss: 0.146  loss_cls: 0.048  loss_box_reg: 0.075  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:19 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 1340  total_loss: 0.168  loss_cls: 0.060  loss_box_reg: 0.083  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:19 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 1340  total_loss: 0.168  loss_cls: 0.060  loss_box_reg: 0.083  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:25 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1360  total_loss: 0.150  loss_cls: 0.036  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:25 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1360  total_loss: 0.150  loss_cls: 0.036  loss_box_reg: 0.068  loss_rpn_cls: 0.002  loss_rpn_loc: 0.021  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:30 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1380  total_loss: 0.161  loss_cls: 0.053  loss_box_reg: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:30 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1380  total_loss: 0.161  loss_cls: 0.053  loss_box_reg: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:36 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 1400  total_loss: 0.168  loss_cls: 0.049  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:36 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 1400  total_loss: 0.168  loss_cls: 0.049  loss_box_reg: 0.055  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:41 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1420  total_loss: 0.138  loss_cls: 0.039  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:41 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 1420  total_loss: 0.138  loss_cls: 0.039  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:47 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 1440  total_loss: 0.147  loss_cls: 0.041  loss_box_reg: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:47 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 1440  total_loss: 0.147  loss_cls: 0.041  loss_box_reg: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:52 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1460  total_loss: 0.146  loss_cls: 0.051  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:52 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1460  total_loss: 0.146  loss_cls: 0.051  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 19:58:58 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1480  total_loss: 0.112  loss_cls: 0.033  loss_box_reg: 0.052  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:58:58 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1480  total_loss: 0.112  loss_cls: 0.033  loss_box_reg: 0.052  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:03 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1500  total_loss: 0.150  loss_cls: 0.054  loss_box_reg: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:03 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 1500  total_loss: 0.150  loss_cls: 0.054  loss_box_reg: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:09 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 1520  total_loss: 0.154  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:09 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 1520  total_loss: 0.154  loss_cls: 0.048  loss_box_reg: 0.062  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:15 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1540  total_loss: 0.169  loss_cls: 0.055  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:15 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1540  total_loss: 0.169  loss_cls: 0.055  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:20 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1560  total_loss: 0.153  loss_cls: 0.045  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:20 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1560  total_loss: 0.153  loss_cls: 0.045  loss_box_reg: 0.060  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:27 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 1580  total_loss: 0.158  loss_cls: 0.046  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:27 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 1580  total_loss: 0.158  loss_cls: 0.046  loss_box_reg: 0.061  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:32 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1600  total_loss: 0.144  loss_cls: 0.056  loss_box_reg: 0.074  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:32 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 1600  total_loss: 0.144  loss_cls: 0.056  loss_box_reg: 0.074  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:38 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 1620  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:38 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 1620  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:44 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1640  total_loss: 0.144  loss_cls: 0.052  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:44 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1640  total_loss: 0.144  loss_cls: 0.052  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:50 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1660  total_loss: 0.135  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:50 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1660  total_loss: 0.135  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:55 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1680  total_loss: 0.114  loss_cls: 0.037  loss_box_reg: 0.049  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 19:59:55 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1680  total_loss: 0.114  loss_cls: 0.037  loss_box_reg: 0.049  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:01 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 1700  total_loss: 0.127  loss_cls: 0.044  loss_box_reg: 0.070  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:01 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 1700  total_loss: 0.127  loss_cls: 0.044  loss_box_reg: 0.070  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:06 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1720  total_loss: 0.106  loss_cls: 0.037  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:06 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1720  total_loss: 0.106  loss_cls: 0.037  loss_box_reg: 0.062  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:11 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 1740  total_loss: 0.157  loss_cls: 0.050  loss_box_reg: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:11 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 1740  total_loss: 0.157  loss_cls: 0.050  loss_box_reg: 0.075  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:17 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 1760  total_loss: 0.148  loss_cls: 0.037  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:17 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 1760  total_loss: 0.148  loss_cls: 0.037  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:22 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 1780  total_loss: 0.127  loss_cls: 0.046  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:22 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 1780  total_loss: 0.127  loss_cls: 0.046  loss_box_reg: 0.056  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:28 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1800  total_loss: 0.115  loss_cls: 0.038  loss_box_reg: 0.051  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:28 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 1800  total_loss: 0.115  loss_cls: 0.038  loss_box_reg: 0.051  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:34 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1820  total_loss: 0.129  loss_cls: 0.038  loss_box_reg: 0.053  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:34 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 1820  total_loss: 0.129  loss_cls: 0.038  loss_box_reg: 0.053  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:40 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1840  total_loss: 0.143  loss_cls: 0.040  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:40 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 1840  total_loss: 0.143  loss_cls: 0.040  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:45 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1860  total_loss: 0.103  loss_cls: 0.032  loss_box_reg: 0.049  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:45 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 1860  total_loss: 0.103  loss_cls: 0.032  loss_box_reg: 0.049  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:51 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1880  total_loss: 0.127  loss_cls: 0.041  loss_box_reg: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:51 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1880  total_loss: 0.127  loss_cls: 0.041  loss_box_reg: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:00:58 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 1900  total_loss: 0.114  loss_cls: 0.040  loss_box_reg: 0.054  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:00:58 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 1900  total_loss: 0.114  loss_cls: 0.040  loss_box_reg: 0.054  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:03 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 1920  total_loss: 0.138  loss_cls: 0.036  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:03 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 1920  total_loss: 0.138  loss_cls: 0.036  loss_box_reg: 0.069  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:08 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 1940  total_loss: 0.131  loss_cls: 0.049  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:08 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 1940  total_loss: 0.131  loss_cls: 0.049  loss_box_reg: 0.064  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:14 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1960  total_loss: 0.129  loss_cls: 0.035  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:14 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1960  total_loss: 0.129  loss_cls: 0.035  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:20 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 1980  total_loss: 0.167  loss_cls: 0.050  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:20 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 1980  total_loss: 0.167  loss_cls: 0.050  loss_box_reg: 0.059  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:25 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 2000  total_loss: 0.127  loss_cls: 0.047  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:25 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 2000  total_loss: 0.127  loss_cls: 0.047  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:30 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2020  total_loss: 0.121  loss_cls: 0.037  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:30 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2020  total_loss: 0.121  loss_cls: 0.037  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:36 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 2040  total_loss: 0.136  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:36 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 2040  total_loss: 0.136  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:41 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 2060  total_loss: 0.116  loss_cls: 0.044  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:41 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 2060  total_loss: 0.116  loss_cls: 0.044  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:46 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 2080  total_loss: 0.133  loss_cls: 0.043  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:46 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 2080  total_loss: 0.133  loss_cls: 0.043  loss_box_reg: 0.054  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:52 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2100  total_loss: 0.105  loss_cls: 0.035  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:52 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2100  total_loss: 0.105  loss_cls: 0.035  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:57 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2120  total_loss: 0.123  loss_cls: 0.036  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:01:57 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2120  total_loss: 0.123  loss_cls: 0.036  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:03 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 2140  total_loss: 0.156  loss_cls: 0.046  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:03 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 2140  total_loss: 0.156  loss_cls: 0.046  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:09 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 2160  total_loss: 0.118  loss_cls: 0.026  loss_box_reg: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:09 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 2160  total_loss: 0.118  loss_cls: 0.026  loss_box_reg: 0.044  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:14 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 2180  total_loss: 0.103  loss_cls: 0.039  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:14 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 2180  total_loss: 0.103  loss_cls: 0.039  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:20 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 2200  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:20 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 2200  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:25 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 2220  total_loss: 0.134  loss_cls: 0.050  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:25 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 2220  total_loss: 0.134  loss_cls: 0.050  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:31 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 2240  total_loss: 0.099  loss_cls: 0.035  loss_box_reg: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:31 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 2240  total_loss: 0.099  loss_cls: 0.035  loss_box_reg: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:36 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2260  total_loss: 0.089  loss_cls: 0.029  loss_box_reg: 0.039  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:36 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2260  total_loss: 0.089  loss_cls: 0.029  loss_box_reg: 0.039  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:42 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 2280  total_loss: 0.118  loss_cls: 0.034  loss_box_reg: 0.048  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:42 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 2280  total_loss: 0.118  loss_cls: 0.034  loss_box_reg: 0.048  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:47 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 2300  total_loss: 0.106  loss_cls: 0.035  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:47 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 2300  total_loss: 0.106  loss_cls: 0.035  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:02:52 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2320  total_loss: 0.094  loss_cls: 0.029  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:52 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2320  total_loss: 0.094  loss_cls: 0.029  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:58 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 2340  total_loss: 0.117  loss_cls: 0.031  loss_box_reg: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:02:58 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 2340  total_loss: 0.117  loss_cls: 0.031  loss_box_reg: 0.061  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:03 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2360  total_loss: 0.117  loss_cls: 0.029  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:03 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2360  total_loss: 0.117  loss_cls: 0.029  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:10 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 2380  total_loss: 0.104  loss_cls: 0.034  loss_box_reg: 0.041  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:10 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 2380  total_loss: 0.104  loss_cls: 0.034  loss_box_reg: 0.041  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:15 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 2400  total_loss: 0.130  loss_cls: 0.052  loss_box_reg: 0.053  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:15 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 2400  total_loss: 0.130  loss_cls: 0.052  loss_box_reg: 0.053  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:21 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 2420  total_loss: 0.122  loss_cls: 0.037  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:21 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 2420  total_loss: 0.122  loss_cls: 0.037  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:26 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2440  total_loss: 0.102  loss_cls: 0.031  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:26 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2440  total_loss: 0.102  loss_cls: 0.031  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:32 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 2460  total_loss: 0.111  loss_cls: 0.029  loss_box_reg: 0.053  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:32 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 2460  total_loss: 0.111  loss_cls: 0.029  loss_box_reg: 0.053  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:38 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2480  total_loss: 0.093  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:38 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2480  total_loss: 0.093  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:44 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 2500  total_loss: 0.163  loss_cls: 0.048  loss_box_reg: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:44 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 2500  total_loss: 0.163  loss_cls: 0.048  loss_box_reg: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:51 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 2520  total_loss: 0.116  loss_cls: 0.041  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:51 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 2520  total_loss: 0.116  loss_cls: 0.041  loss_box_reg: 0.057  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:57 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2540  total_loss: 0.079  loss_cls: 0.027  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:03:57 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2540  total_loss: 0.079  loss_cls: 0.027  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:02 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2560  total_loss: 0.120  loss_cls: 0.026  loss_box_reg: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:02 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2560  total_loss: 0.120  loss_cls: 0.026  loss_box_reg: 0.037  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:07 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 2580  total_loss: 0.131  loss_cls: 0.045  loss_box_reg: 0.076  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:07 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 2580  total_loss: 0.131  loss_cls: 0.045  loss_box_reg: 0.076  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:13 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2600  total_loss: 0.094  loss_cls: 0.037  loss_box_reg: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:13 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2600  total_loss: 0.094  loss_cls: 0.037  loss_box_reg: 0.047  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:18 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2620  total_loss: 0.098  loss_cls: 0.037  loss_box_reg: 0.045  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:18 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2620  total_loss: 0.098  loss_cls: 0.037  loss_box_reg: 0.045  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:25 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 2640  total_loss: 0.116  loss_cls: 0.039  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:25 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 2640  total_loss: 0.116  loss_cls: 0.039  loss_box_reg: 0.057  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:30 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2660  total_loss: 0.093  loss_cls: 0.023  loss_box_reg: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:30 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2660  total_loss: 0.093  loss_cls: 0.023  loss_box_reg: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:35 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 2680  total_loss: 0.127  loss_cls: 0.039  loss_box_reg: 0.052  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:35 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 2680  total_loss: 0.127  loss_cls: 0.039  loss_box_reg: 0.052  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:41 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 2700  total_loss: 0.096  loss_cls: 0.033  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:41 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 2700  total_loss: 0.096  loss_cls: 0.033  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:46 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2720  total_loss: 0.106  loss_cls: 0.026  loss_box_reg: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:46 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2720  total_loss: 0.106  loss_cls: 0.026  loss_box_reg: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:04:52 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2740  total_loss: 0.125  loss_cls: 0.045  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:52 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2740  total_loss: 0.125  loss_cls: 0.045  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:58 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2760  total_loss: 0.108  loss_cls: 0.033  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:04:58 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2760  total_loss: 0.108  loss_cls: 0.033  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:03 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 2780  total_loss: 0.104  loss_cls: 0.037  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:03 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 2780  total_loss: 0.104  loss_cls: 0.037  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:10 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2800  total_loss: 0.080  loss_cls: 0.029  loss_box_reg: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:10 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2800  total_loss: 0.080  loss_cls: 0.029  loss_box_reg: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:16 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 2820  total_loss: 0.096  loss_cls: 0.027  loss_box_reg: 0.042  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:16 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 2820  total_loss: 0.096  loss_cls: 0.027  loss_box_reg: 0.042  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:21 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 2840  total_loss: 0.136  loss_cls: 0.037  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:21 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 2840  total_loss: 0.136  loss_cls: 0.037  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:27 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 2860  total_loss: 0.115  loss_cls: 0.047  loss_box_reg: 0.056  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:27 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 2860  total_loss: 0.115  loss_cls: 0.047  loss_box_reg: 0.056  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:33 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 2880  total_loss: 0.105  loss_cls: 0.033  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:33 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 2880  total_loss: 0.105  loss_cls: 0.033  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:38 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2900  total_loss: 0.122  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:38 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2900  total_loss: 0.122  loss_cls: 0.037  loss_box_reg: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:44 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 2920  total_loss: 0.117  loss_cls: 0.030  loss_box_reg: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:44 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 2920  total_loss: 0.117  loss_cls: 0.030  loss_box_reg: 0.041  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:49 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 2940  total_loss: 0.125  loss_cls: 0.043  loss_box_reg: 0.056  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:49 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 2940  total_loss: 0.125  loss_cls: 0.043  loss_box_reg: 0.056  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1619M\n",
      "\u001b[32m[08/23 20:05:55 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.108  loss_cls: 0.030  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:05:55 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.108  loss_cls: 0.030  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:01 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 2980  total_loss: 0.096  loss_cls: 0.030  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:01 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 2980  total_loss: 0.096  loss_cls: 0.030  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:07 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 20:06:13 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.096  loss_cls: 0.031  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:13 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.096  loss_cls: 0.031  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:14 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 20:06:16 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "|  Bathtub   | 15           | Coffeemaker | 18           | Tree house | 4            |\n",
      "|            |              |             |              |            |              |\n",
      "|   total    | 37           |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[08/23 20:06:16 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "|  Bathtub   | 15           | Coffeemaker | 18           | Tree house | 4            |\n",
      "|            |              |             |              |            |              |\n",
      "|   total    | 37           |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[08/23 20:06:16 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:06:16 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:06:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 20:06:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 20:06:16 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 20:06:16 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 20:06:16 d2.evaluation.coco_evaluation]: \u001b[0m'validation/cmaker-bathtub-treehouse-validation' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[32m[08/23 20:06:16 d2.evaluation.coco_evaluation]: \u001b[0m'validation/cmaker-bathtub-treehouse-validation' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:06:16 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './output/inference/validation/cmaker-bathtub-treehouse-validation/validation/cmaker-bathtub-treehouse-validation_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:06:16 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './output/inference/validation/cmaker-bathtub-treehouse-validation/validation/cmaker-bathtub-treehouse-validation_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[08/23 20:06:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 20:06:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 20:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1176 s / img. ETA=0:00:02\n",
      "\u001b[32m[08/23 20:06:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1176 s / img. ETA=0:00:02\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.732048 (0.124402 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.732048 (0.124402 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.121771 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.121771 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.508\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.907\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.508\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.651\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 50.834 | 90.728 | 56.112 |  nan  |  nan  | 50.835 |\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 50.834 | 90.728 | 56.112 |  nan  |  nan  | 50.835 |\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 56.323 | Coffeemaker | 47.664 | Tree house | 48.515 |\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 56.323 | Coffeemaker | 47.664 | Tree house | 48.515 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: 50.8338,90.7283,56.1120,nan,nan,50.8351\n",
      "\u001b[32m[08/23 20:06:21 d2.evaluation.testing]: \u001b[0mcopypaste: 50.8338,90.7283,56.1120,nan,nan,50.8351\n",
      "### Saving results to Weights & Biases...\n",
      ">>>>>>>>>>>>> Running experiment: 1\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 20:06:21 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/cyun4jyt\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/cyun4jyt</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:06:24 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:06:24 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd381509a0>\n",
      "\u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "\u001b[32m[08/23 20:06:24 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\n",
      "\u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "\u001b[32m[08/23 20:06:24 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{weight, bias}\u001b[0m\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[32m[08/23 20:06:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 20:06:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 20:06:24 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:06:24 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:06:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 20:06:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 20:06:24 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 20:06:24 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 20:06:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 20:06:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 20:06:24 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 20:06:24 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 20:06:29 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.629  loss_cls: 1.503  loss_box_reg: 0.090  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:29 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.629  loss_cls: 1.503  loss_box_reg: 0.090  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:35 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 40  total_loss: 1.492  loss_cls: 1.382  loss_box_reg: 0.083  loss_rpn_cls: 0.012  loss_rpn_loc: 0.006  lr: 0.000010  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:35 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 40  total_loss: 1.492  loss_cls: 1.382  loss_box_reg: 0.083  loss_rpn_cls: 0.012  loss_rpn_loc: 0.006  lr: 0.000010  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:41 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 60  total_loss: 1.288  loss_cls: 1.101  loss_box_reg: 0.094  loss_rpn_cls: 0.017  loss_rpn_loc: 0.008  lr: 0.000015  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:41 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 60  total_loss: 1.288  loss_cls: 1.101  loss_box_reg: 0.094  loss_rpn_cls: 0.017  loss_rpn_loc: 0.008  lr: 0.000015  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:46 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 80  total_loss: 0.921  loss_cls: 0.802  loss_box_reg: 0.084  loss_rpn_cls: 0.013  loss_rpn_loc: 0.008  lr: 0.000020  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:46 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 80  total_loss: 0.921  loss_cls: 0.802  loss_box_reg: 0.084  loss_rpn_cls: 0.013  loss_rpn_loc: 0.008  lr: 0.000020  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:51 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 100  total_loss: 0.663  loss_cls: 0.531  loss_box_reg: 0.096  loss_rpn_cls: 0.011  loss_rpn_loc: 0.005  lr: 0.000025  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:51 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 100  total_loss: 0.663  loss_cls: 0.531  loss_box_reg: 0.096  loss_rpn_cls: 0.011  loss_rpn_loc: 0.005  lr: 0.000025  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:56 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 120  total_loss: 0.513  loss_cls: 0.344  loss_box_reg: 0.104  loss_rpn_cls: 0.008  loss_rpn_loc: 0.016  lr: 0.000030  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:06:56 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 120  total_loss: 0.513  loss_cls: 0.344  loss_box_reg: 0.104  loss_rpn_cls: 0.008  loss_rpn_loc: 0.016  lr: 0.000030  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:01 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 140  total_loss: 0.369  loss_cls: 0.242  loss_box_reg: 0.095  loss_rpn_cls: 0.007  loss_rpn_loc: 0.006  lr: 0.000035  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:01 d2.utils.events]: \u001b[0m eta: 0:12:43  iter: 140  total_loss: 0.369  loss_cls: 0.242  loss_box_reg: 0.095  loss_rpn_cls: 0.007  loss_rpn_loc: 0.006  lr: 0.000035  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:07 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 160  total_loss: 0.330  loss_cls: 0.180  loss_box_reg: 0.083  loss_rpn_cls: 0.006  loss_rpn_loc: 0.012  lr: 0.000040  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:07 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 160  total_loss: 0.330  loss_cls: 0.180  loss_box_reg: 0.083  loss_rpn_cls: 0.006  loss_rpn_loc: 0.012  lr: 0.000040  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:12 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 180  total_loss: 0.318  loss_cls: 0.167  loss_box_reg: 0.102  loss_rpn_cls: 0.006  loss_rpn_loc: 0.011  lr: 0.000045  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:12 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 180  total_loss: 0.318  loss_cls: 0.167  loss_box_reg: 0.102  loss_rpn_cls: 0.006  loss_rpn_loc: 0.011  lr: 0.000045  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:17 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 200  total_loss: 0.293  loss_cls: 0.132  loss_box_reg: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  lr: 0.000050  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:17 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 200  total_loss: 0.293  loss_cls: 0.132  loss_box_reg: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  lr: 0.000050  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:23 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 220  total_loss: 0.248  loss_cls: 0.131  loss_box_reg: 0.080  loss_rpn_cls: 0.010  loss_rpn_loc: 0.011  lr: 0.000055  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:23 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 220  total_loss: 0.248  loss_cls: 0.131  loss_box_reg: 0.080  loss_rpn_cls: 0.010  loss_rpn_loc: 0.011  lr: 0.000055  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:28 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 240  total_loss: 0.242  loss_cls: 0.112  loss_box_reg: 0.097  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  lr: 0.000060  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:28 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 240  total_loss: 0.242  loss_cls: 0.112  loss_box_reg: 0.097  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  lr: 0.000060  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:33 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 260  total_loss: 0.312  loss_cls: 0.161  loss_box_reg: 0.133  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  lr: 0.000065  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:07:33 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 260  total_loss: 0.312  loss_cls: 0.161  loss_box_reg: 0.133  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  lr: 0.000065  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:38 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 280  total_loss: 0.217  loss_cls: 0.104  loss_box_reg: 0.105  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000070  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:38 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 280  total_loss: 0.217  loss_cls: 0.104  loss_box_reg: 0.105  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000070  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:43 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 300  total_loss: 0.250  loss_cls: 0.109  loss_box_reg: 0.081  loss_rpn_cls: 0.010  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:43 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 300  total_loss: 0.250  loss_cls: 0.109  loss_box_reg: 0.081  loss_rpn_cls: 0.010  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:48 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 320  total_loss: 0.259  loss_cls: 0.120  loss_box_reg: 0.104  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000080  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:48 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 320  total_loss: 0.259  loss_cls: 0.120  loss_box_reg: 0.104  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000080  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:54 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 340  total_loss: 0.225  loss_cls: 0.097  loss_box_reg: 0.092  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  lr: 0.000085  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:07:54 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 340  total_loss: 0.225  loss_cls: 0.097  loss_box_reg: 0.092  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  lr: 0.000085  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:00 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 360  total_loss: 0.238  loss_cls: 0.113  loss_box_reg: 0.094  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000090  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:00 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 360  total_loss: 0.238  loss_cls: 0.113  loss_box_reg: 0.094  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000090  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:06 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 380  total_loss: 0.247  loss_cls: 0.113  loss_box_reg: 0.102  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  lr: 0.000095  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:06 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 380  total_loss: 0.247  loss_cls: 0.113  loss_box_reg: 0.102  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  lr: 0.000095  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:12 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 400  total_loss: 0.247  loss_cls: 0.091  loss_box_reg: 0.103  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000100  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:12 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 400  total_loss: 0.247  loss_cls: 0.091  loss_box_reg: 0.103  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000100  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:17 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 420  total_loss: 0.209  loss_cls: 0.082  loss_box_reg: 0.092  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000105  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:17 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 420  total_loss: 0.209  loss_cls: 0.082  loss_box_reg: 0.092  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000105  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:22 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 440  total_loss: 0.236  loss_cls: 0.094  loss_box_reg: 0.110  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000110  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:22 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 440  total_loss: 0.236  loss_cls: 0.094  loss_box_reg: 0.110  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000110  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:28 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 460  total_loss: 0.236  loss_cls: 0.092  loss_box_reg: 0.114  loss_rpn_cls: 0.006  loss_rpn_loc: 0.012  lr: 0.000115  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:28 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 460  total_loss: 0.236  loss_cls: 0.092  loss_box_reg: 0.114  loss_rpn_cls: 0.006  loss_rpn_loc: 0.012  lr: 0.000115  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:33 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 480  total_loss: 0.232  loss_cls: 0.092  loss_box_reg: 0.098  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000120  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:33 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 480  total_loss: 0.232  loss_cls: 0.092  loss_box_reg: 0.098  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000120  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:39 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 500  total_loss: 0.226  loss_cls: 0.119  loss_box_reg: 0.098  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  lr: 0.000125  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:39 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 500  total_loss: 0.226  loss_cls: 0.119  loss_box_reg: 0.098  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  lr: 0.000125  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:44 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 520  total_loss: 0.178  loss_cls: 0.078  loss_box_reg: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  lr: 0.000130  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:44 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 520  total_loss: 0.178  loss_cls: 0.078  loss_box_reg: 0.095  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  lr: 0.000130  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:50 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 540  total_loss: 0.242  loss_cls: 0.109  loss_box_reg: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000135  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:50 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 540  total_loss: 0.242  loss_cls: 0.109  loss_box_reg: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000135  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:56 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 560  total_loss: 0.244  loss_cls: 0.089  loss_box_reg: 0.127  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000140  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:08:56 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 560  total_loss: 0.244  loss_cls: 0.089  loss_box_reg: 0.127  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000140  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:02 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 580  total_loss: 0.213  loss_cls: 0.080  loss_box_reg: 0.107  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  lr: 0.000145  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:02 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 580  total_loss: 0.213  loss_cls: 0.080  loss_box_reg: 0.107  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  lr: 0.000145  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:08 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 600  total_loss: 0.201  loss_cls: 0.074  loss_box_reg: 0.093  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000150  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:08 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 600  total_loss: 0.201  loss_cls: 0.074  loss_box_reg: 0.093  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000150  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:13 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 620  total_loss: 0.176  loss_cls: 0.063  loss_box_reg: 0.090  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000155  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:13 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 620  total_loss: 0.176  loss_cls: 0.063  loss_box_reg: 0.090  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000155  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:19 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 640  total_loss: 0.186  loss_cls: 0.076  loss_box_reg: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000160  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:19 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 640  total_loss: 0.186  loss_cls: 0.076  loss_box_reg: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000160  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:24 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 660  total_loss: 0.238  loss_cls: 0.094  loss_box_reg: 0.123  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000165  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:24 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 660  total_loss: 0.238  loss_cls: 0.094  loss_box_reg: 0.123  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000165  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:31 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 680  total_loss: 0.207  loss_cls: 0.091  loss_box_reg: 0.101  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000170  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:09:31 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 680  total_loss: 0.207  loss_cls: 0.091  loss_box_reg: 0.101  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  lr: 0.000170  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:37 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 700  total_loss: 0.198  loss_cls: 0.065  loss_box_reg: 0.092  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000175  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:37 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 700  total_loss: 0.198  loss_cls: 0.065  loss_box_reg: 0.092  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000175  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:43 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 720  total_loss: 0.227  loss_cls: 0.090  loss_box_reg: 0.108  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000180  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:43 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 720  total_loss: 0.227  loss_cls: 0.090  loss_box_reg: 0.108  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000180  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:48 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 740  total_loss: 0.221  loss_cls: 0.072  loss_box_reg: 0.080  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000185  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:48 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 740  total_loss: 0.221  loss_cls: 0.072  loss_box_reg: 0.080  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000185  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:54 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 760  total_loss: 0.181  loss_cls: 0.058  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000190  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:09:54 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 760  total_loss: 0.181  loss_cls: 0.058  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000190  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:00 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 780  total_loss: 0.178  loss_cls: 0.063  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000195  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:00 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 780  total_loss: 0.178  loss_cls: 0.063  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000195  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:06 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 800  total_loss: 0.204  loss_cls: 0.069  loss_box_reg: 0.091  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000200  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:06 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 800  total_loss: 0.204  loss_cls: 0.069  loss_box_reg: 0.091  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000200  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:11 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 820  total_loss: 0.198  loss_cls: 0.073  loss_box_reg: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000205  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:11 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 820  total_loss: 0.198  loss_cls: 0.073  loss_box_reg: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000205  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:16 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 840  total_loss: 0.213  loss_cls: 0.068  loss_box_reg: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000210  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:16 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 840  total_loss: 0.213  loss_cls: 0.068  loss_box_reg: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000210  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:22 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 860  total_loss: 0.183  loss_cls: 0.051  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000215  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:22 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 860  total_loss: 0.183  loss_cls: 0.051  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000215  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:28 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 880  total_loss: 0.216  loss_cls: 0.064  loss_box_reg: 0.098  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  lr: 0.000220  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:28 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 880  total_loss: 0.216  loss_cls: 0.064  loss_box_reg: 0.098  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  lr: 0.000220  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:34 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 900  total_loss: 0.201  loss_cls: 0.062  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000225  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:34 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 900  total_loss: 0.201  loss_cls: 0.062  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000225  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:39 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 920  total_loss: 0.182  loss_cls: 0.060  loss_box_reg: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000230  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:39 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 920  total_loss: 0.182  loss_cls: 0.060  loss_box_reg: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000230  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:45 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 940  total_loss: 0.227  loss_cls: 0.073  loss_box_reg: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000235  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:45 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 940  total_loss: 0.227  loss_cls: 0.073  loss_box_reg: 0.127  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000235  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:51 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 960  total_loss: 0.210  loss_cls: 0.081  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000240  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:51 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 960  total_loss: 0.210  loss_cls: 0.081  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000240  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:57 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 980  total_loss: 0.185  loss_cls: 0.060  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000245  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:10:57 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 980  total_loss: 0.185  loss_cls: 0.060  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000245  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:02 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1000  total_loss: 0.135  loss_cls: 0.035  loss_box_reg: 0.081  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:02 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1000  total_loss: 0.135  loss_cls: 0.035  loss_box_reg: 0.081  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:08 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 1020  total_loss: 0.160  loss_cls: 0.048  loss_box_reg: 0.087  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:08 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 1020  total_loss: 0.160  loss_cls: 0.048  loss_box_reg: 0.087  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:14 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1040  total_loss: 0.139  loss_cls: 0.034  loss_box_reg: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:14 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1040  total_loss: 0.139  loss_cls: 0.034  loss_box_reg: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:19 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1060  total_loss: 0.175  loss_cls: 0.043  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:19 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1060  total_loss: 0.175  loss_cls: 0.043  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:25 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 1080  total_loss: 0.173  loss_cls: 0.057  loss_box_reg: 0.094  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:25 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 1080  total_loss: 0.173  loss_cls: 0.057  loss_box_reg: 0.094  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:30 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 1100  total_loss: 0.125  loss_cls: 0.033  loss_box_reg: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:11:30 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 1100  total_loss: 0.125  loss_cls: 0.033  loss_box_reg: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:37 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1120  total_loss: 0.162  loss_cls: 0.046  loss_box_reg: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:37 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 1120  total_loss: 0.162  loss_cls: 0.046  loss_box_reg: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:42 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1140  total_loss: 0.182  loss_cls: 0.057  loss_box_reg: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:42 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1140  total_loss: 0.182  loss_cls: 0.057  loss_box_reg: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:48 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 1160  total_loss: 0.158  loss_cls: 0.048  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:48 d2.utils.events]: \u001b[0m eta: 0:08:47  iter: 1160  total_loss: 0.158  loss_cls: 0.048  loss_box_reg: 0.064  loss_rpn_cls: 0.004  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:53 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1180  total_loss: 0.177  loss_cls: 0.051  loss_box_reg: 0.084  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:11:53 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1180  total_loss: 0.177  loss_cls: 0.051  loss_box_reg: 0.084  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:00 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 1200  total_loss: 0.156  loss_cls: 0.053  loss_box_reg: 0.082  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:00 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 1200  total_loss: 0.156  loss_cls: 0.053  loss_box_reg: 0.082  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:05 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 1220  total_loss: 0.188  loss_cls: 0.065  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:05 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 1220  total_loss: 0.188  loss_cls: 0.065  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:10 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1240  total_loss: 0.145  loss_cls: 0.047  loss_box_reg: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:10 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1240  total_loss: 0.145  loss_cls: 0.047  loss_box_reg: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:16 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 1260  total_loss: 0.137  loss_cls: 0.039  loss_box_reg: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:16 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 1260  total_loss: 0.137  loss_cls: 0.039  loss_box_reg: 0.070  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:23 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 1280  total_loss: 0.183  loss_cls: 0.049  loss_box_reg: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:23 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 1280  total_loss: 0.183  loss_cls: 0.049  loss_box_reg: 0.073  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:28 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1300  total_loss: 0.161  loss_cls: 0.045  loss_box_reg: 0.076  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:28 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 1300  total_loss: 0.161  loss_cls: 0.045  loss_box_reg: 0.076  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:34 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 1320  total_loss: 0.110  loss_cls: 0.031  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:34 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 1320  total_loss: 0.110  loss_cls: 0.031  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:40 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 1340  total_loss: 0.138  loss_cls: 0.043  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:40 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 1340  total_loss: 0.138  loss_cls: 0.043  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:46 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 1360  total_loss: 0.156  loss_cls: 0.033  loss_box_reg: 0.076  loss_rpn_cls: 0.000  loss_rpn_loc: 0.016  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:46 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 1360  total_loss: 0.156  loss_cls: 0.033  loss_box_reg: 0.076  loss_rpn_cls: 0.000  loss_rpn_loc: 0.016  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:51 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 1380  total_loss: 0.151  loss_cls: 0.048  loss_box_reg: 0.080  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:51 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 1380  total_loss: 0.151  loss_cls: 0.048  loss_box_reg: 0.080  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:57 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 1400  total_loss: 0.155  loss_cls: 0.034  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:12:57 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 1400  total_loss: 0.155  loss_cls: 0.034  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:02 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1420  total_loss: 0.112  loss_cls: 0.030  loss_box_reg: 0.047  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:02 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1420  total_loss: 0.112  loss_cls: 0.030  loss_box_reg: 0.047  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:08 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1440  total_loss: 0.128  loss_cls: 0.040  loss_box_reg: 0.068  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:08 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1440  total_loss: 0.128  loss_cls: 0.040  loss_box_reg: 0.068  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:13 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1460  total_loss: 0.128  loss_cls: 0.041  loss_box_reg: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:13 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1460  total_loss: 0.128  loss_cls: 0.041  loss_box_reg: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:19 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1480  total_loss: 0.092  loss_cls: 0.026  loss_box_reg: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:19 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1480  total_loss: 0.092  loss_cls: 0.026  loss_box_reg: 0.044  loss_rpn_cls: 0.002  loss_rpn_loc: 0.019  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:24 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1500  total_loss: 0.124  loss_cls: 0.048  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:24 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1500  total_loss: 0.124  loss_cls: 0.048  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:30 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1520  total_loss: 0.133  loss_cls: 0.039  loss_box_reg: 0.052  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:13:30 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 1520  total_loss: 0.133  loss_cls: 0.039  loss_box_reg: 0.052  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:35 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1540  total_loss: 0.132  loss_cls: 0.043  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:35 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1540  total_loss: 0.132  loss_cls: 0.043  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:41 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1560  total_loss: 0.150  loss_cls: 0.037  loss_box_reg: 0.055  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:41 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1560  total_loss: 0.150  loss_cls: 0.037  loss_box_reg: 0.055  loss_rpn_cls: 0.001  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:47 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1580  total_loss: 0.131  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:47 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 1580  total_loss: 0.131  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:52 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1600  total_loss: 0.163  loss_cls: 0.046  loss_box_reg: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:52 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1600  total_loss: 0.163  loss_cls: 0.046  loss_box_reg: 0.080  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:58 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 1620  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:13:58 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 1620  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:03 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1640  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:03 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 1640  total_loss: 0.140  loss_cls: 0.051  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:09 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 1660  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.052  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:09 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 1660  total_loss: 0.128  loss_cls: 0.038  loss_box_reg: 0.052  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:15 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 1680  total_loss: 0.104  loss_cls: 0.032  loss_box_reg: 0.048  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:15 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 1680  total_loss: 0.104  loss_cls: 0.032  loss_box_reg: 0.048  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:21 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1700  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:21 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 1700  total_loss: 0.121  loss_cls: 0.038  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:26 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 1720  total_loss: 0.103  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:26 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 1720  total_loss: 0.103  loss_cls: 0.035  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:32 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1740  total_loss: 0.143  loss_cls: 0.041  loss_box_reg: 0.074  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:32 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1740  total_loss: 0.143  loss_cls: 0.041  loss_box_reg: 0.074  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:37 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 1760  total_loss: 0.132  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:37 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 1760  total_loss: 0.132  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:43 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 1780  total_loss: 0.117  loss_cls: 0.039  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:43 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 1780  total_loss: 0.117  loss_cls: 0.039  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:48 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1800  total_loss: 0.107  loss_cls: 0.039  loss_box_reg: 0.055  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:48 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 1800  total_loss: 0.107  loss_cls: 0.039  loss_box_reg: 0.055  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:53 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1820  total_loss: 0.096  loss_cls: 0.028  loss_box_reg: 0.044  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:14:53 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1820  total_loss: 0.096  loss_cls: 0.028  loss_box_reg: 0.044  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:00 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1840  total_loss: 0.117  loss_cls: 0.032  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:00 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1840  total_loss: 0.117  loss_cls: 0.032  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:05 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 1860  total_loss: 0.103  loss_cls: 0.032  loss_box_reg: 0.049  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:05 d2.utils.events]: \u001b[0m eta: 0:05:21  iter: 1860  total_loss: 0.103  loss_cls: 0.032  loss_box_reg: 0.049  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:11 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 1880  total_loss: 0.114  loss_cls: 0.039  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:11 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 1880  total_loss: 0.114  loss_cls: 0.039  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:16 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 1900  total_loss: 0.105  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:16 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 1900  total_loss: 0.105  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:22 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1920  total_loss: 0.111  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:22 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1920  total_loss: 0.111  loss_cls: 0.032  loss_box_reg: 0.059  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:27 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1940  total_loss: 0.121  loss_cls: 0.037  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:15:27 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1940  total_loss: 0.121  loss_cls: 0.037  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:33 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 1960  total_loss: 0.103  loss_cls: 0.028  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:33 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 1960  total_loss: 0.103  loss_cls: 0.028  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:38 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 1980  total_loss: 0.128  loss_cls: 0.036  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:38 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 1980  total_loss: 0.128  loss_cls: 0.036  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:44 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 2000  total_loss: 0.114  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:44 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 2000  total_loss: 0.114  loss_cls: 0.038  loss_box_reg: 0.059  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:49 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 2020  total_loss: 0.101  loss_cls: 0.028  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:49 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 2020  total_loss: 0.101  loss_cls: 0.028  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:55 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2040  total_loss: 0.119  loss_cls: 0.036  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:15:55 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2040  total_loss: 0.119  loss_cls: 0.036  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:00 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 2060  total_loss: 0.106  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:00 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 2060  total_loss: 0.106  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:06 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2080  total_loss: 0.097  loss_cls: 0.032  loss_box_reg: 0.042  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:06 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2080  total_loss: 0.097  loss_cls: 0.032  loss_box_reg: 0.042  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:12 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2100  total_loss: 0.081  loss_cls: 0.029  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:12 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2100  total_loss: 0.081  loss_cls: 0.029  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:18 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2120  total_loss: 0.097  loss_cls: 0.027  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:18 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2120  total_loss: 0.097  loss_cls: 0.027  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:23 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 2140  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.076  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:23 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 2140  total_loss: 0.115  loss_cls: 0.033  loss_box_reg: 0.076  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:29 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 2160  total_loss: 0.098  loss_cls: 0.025  loss_box_reg: 0.047  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:29 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 2160  total_loss: 0.098  loss_cls: 0.025  loss_box_reg: 0.047  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:34 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2180  total_loss: 0.097  loss_cls: 0.031  loss_box_reg: 0.044  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:34 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2180  total_loss: 0.097  loss_cls: 0.031  loss_box_reg: 0.044  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:41 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 2200  total_loss: 0.104  loss_cls: 0.035  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:41 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 2200  total_loss: 0.104  loss_cls: 0.035  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:46 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 2220  total_loss: 0.116  loss_cls: 0.042  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:46 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 2220  total_loss: 0.116  loss_cls: 0.042  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:52 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2240  total_loss: 0.080  loss_cls: 0.029  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:52 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2240  total_loss: 0.080  loss_cls: 0.029  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:57 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2260  total_loss: 0.071  loss_cls: 0.024  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:16:57 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2260  total_loss: 0.071  loss_cls: 0.024  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:03 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 2280  total_loss: 0.106  loss_cls: 0.031  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:03 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 2280  total_loss: 0.106  loss_cls: 0.031  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:09 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 2300  total_loss: 0.093  loss_cls: 0.032  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:09 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 2300  total_loss: 0.093  loss_cls: 0.032  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:14 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 2320  total_loss: 0.079  loss_cls: 0.025  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:14 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 2320  total_loss: 0.079  loss_cls: 0.025  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:20 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 2340  total_loss: 0.079  loss_cls: 0.022  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:20 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 2340  total_loss: 0.079  loss_cls: 0.022  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:26 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2360  total_loss: 0.100  loss_cls: 0.025  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:17:26 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2360  total_loss: 0.100  loss_cls: 0.025  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:32 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 2380  total_loss: 0.085  loss_cls: 0.024  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:32 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 2380  total_loss: 0.085  loss_cls: 0.024  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:37 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 2400  total_loss: 0.109  loss_cls: 0.036  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:37 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 2400  total_loss: 0.109  loss_cls: 0.036  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:43 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2420  total_loss: 0.099  loss_cls: 0.030  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:43 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2420  total_loss: 0.099  loss_cls: 0.030  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:48 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 2440  total_loss: 0.087  loss_cls: 0.023  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:48 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 2440  total_loss: 0.087  loss_cls: 0.023  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:54 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 2460  total_loss: 0.082  loss_cls: 0.025  loss_box_reg: 0.039  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:17:54 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 2460  total_loss: 0.082  loss_cls: 0.025  loss_box_reg: 0.039  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:01 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2480  total_loss: 0.077  loss_cls: 0.023  loss_box_reg: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:01 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 2480  total_loss: 0.077  loss_cls: 0.023  loss_box_reg: 0.042  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:07 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 2500  total_loss: 0.136  loss_cls: 0.037  loss_box_reg: 0.049  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:07 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 2500  total_loss: 0.136  loss_cls: 0.037  loss_box_reg: 0.049  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:12 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 2520  total_loss: 0.100  loss_cls: 0.031  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:12 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 2520  total_loss: 0.100  loss_cls: 0.031  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:18 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2540  total_loss: 0.071  loss_cls: 0.023  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:18 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2540  total_loss: 0.071  loss_cls: 0.023  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:23 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 2560  total_loss: 0.089  loss_cls: 0.021  loss_box_reg: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:23 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 2560  total_loss: 0.089  loss_cls: 0.021  loss_box_reg: 0.035  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:29 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 2580  total_loss: 0.096  loss_cls: 0.033  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:29 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 2580  total_loss: 0.096  loss_cls: 0.033  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:36 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 2600  total_loss: 0.084  loss_cls: 0.029  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:36 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 2600  total_loss: 0.084  loss_cls: 0.029  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:42 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2620  total_loss: 0.089  loss_cls: 0.032  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:42 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2620  total_loss: 0.089  loss_cls: 0.032  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:48 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2640  total_loss: 0.107  loss_cls: 0.028  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:48 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2640  total_loss: 0.107  loss_cls: 0.028  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:54 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2660  total_loss: 0.077  loss_cls: 0.016  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:18:54 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2660  total_loss: 0.077  loss_cls: 0.016  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.013  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:00 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 2680  total_loss: 0.123  loss_cls: 0.035  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:00 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 2680  total_loss: 0.123  loss_cls: 0.035  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:05 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 2700  total_loss: 0.089  loss_cls: 0.026  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:05 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 2700  total_loss: 0.089  loss_cls: 0.026  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:11 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2720  total_loss: 0.084  loss_cls: 0.023  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:11 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2720  total_loss: 0.084  loss_cls: 0.023  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:17 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 2740  total_loss: 0.097  loss_cls: 0.032  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:17 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 2740  total_loss: 0.097  loss_cls: 0.032  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:23 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 2760  total_loss: 0.088  loss_cls: 0.027  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:23 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 2760  total_loss: 0.088  loss_cls: 0.027  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:29 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2780  total_loss: 0.091  loss_cls: 0.031  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:19:29 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2780  total_loss: 0.091  loss_cls: 0.031  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:34 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 2800  total_loss: 0.076  loss_cls: 0.024  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:34 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 2800  total_loss: 0.076  loss_cls: 0.024  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:40 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 2820  total_loss: 0.075  loss_cls: 0.025  loss_box_reg: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:40 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 2820  total_loss: 0.075  loss_cls: 0.025  loss_box_reg: 0.033  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:46 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 2840  total_loss: 0.106  loss_cls: 0.025  loss_box_reg: 0.047  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:46 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 2840  total_loss: 0.106  loss_cls: 0.025  loss_box_reg: 0.047  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:52 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 2860  total_loss: 0.084  loss_cls: 0.029  loss_box_reg: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:52 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 2860  total_loss: 0.084  loss_cls: 0.029  loss_box_reg: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:58 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 2880  total_loss: 0.085  loss_cls: 0.026  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:19:58 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 2880  total_loss: 0.085  loss_cls: 0.026  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:03 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 2900  total_loss: 0.100  loss_cls: 0.027  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:03 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 2900  total_loss: 0.100  loss_cls: 0.027  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:09 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 2920  total_loss: 0.101  loss_cls: 0.031  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:09 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 2920  total_loss: 0.101  loss_cls: 0.031  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:15 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 2940  total_loss: 0.100  loss_cls: 0.029  loss_box_reg: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:15 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 2940  total_loss: 0.100  loss_cls: 0.029  loss_box_reg: 0.038  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:21 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.097  loss_cls: 0.029  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:21 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.097  loss_cls: 0.029  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:26 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2980  total_loss: 0.079  loss_cls: 0.026  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:26 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2980  total_loss: 0.079  loss_cls: 0.026  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:31 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 20:20:34 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.103  loss_cls: 0.031  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:34 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.103  loss_cls: 0.031  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 1620M\n",
      "\u001b[32m[08/23 20:20:35 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 20:20:37 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:20:37 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:20:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 20:20:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 20:20:37 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 20:20:37 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 20:20:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 20:20:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 20:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1209 s / img. ETA=0:00:02\n",
      "\u001b[32m[08/23 20:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1209 s / img. ETA=0:00:02\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.751568 (0.125052 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.751568 (0.125052 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.122405 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.122405 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.881\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.592\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.540\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.559\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.684\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 54.022 | 88.066 | 59.229 |  nan  |  nan  | 54.022 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 54.022 | 88.066 | 59.229 |  nan  |  nan  | 54.022 |\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 58.083 | Coffeemaker | 59.081 | Tree house | 44.901 |\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 58.083 | Coffeemaker | 59.081 | Tree house | 44.901 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.testing]: \u001b[0mcopypaste: 54.0217,88.0655,59.2289,nan,nan,54.0217\n",
      "\u001b[32m[08/23 20:20:42 d2.evaluation.testing]: \u001b[0mcopypaste: 54.0217,88.0655,59.2289,nan,nan,54.0217\n",
      "### Saving results to Weights & Biases...\n",
      ">>>>>>>>>>>>> Running experiment: 2\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-101.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-101.pkl\"\n",
      "  MASK_ON: False\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 20:20:42 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/gna49cnq\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/gna49cnq</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:20:45 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:20:45 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd3836c190>\n",
      "\u001b[32m[08/23 20:20:45 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "\u001b[32m[08/23 20:20:45 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "\u001b[32m[08/23 20:20:47 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:20:47 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:20:47 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:20:47 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:20:47 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "\u001b[32m[08/23 20:20:47 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{weight, bias}\u001b[0m\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[32m[08/23 20:20:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 20:20:47 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 20:20:47 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:20:47 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:20:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 20:20:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 20:20:47 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 20:20:47 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 20:20:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 20:20:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 20:20:47 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 20:20:47 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 20:20:55 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.532  loss_cls: 1.378  loss_box_reg: 0.094  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:20:55 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.532  loss_cls: 1.378  loss_box_reg: 0.094  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:03 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 40  total_loss: 1.464  loss_cls: 1.286  loss_box_reg: 0.083  loss_rpn_cls: 0.016  loss_rpn_loc: 0.008  lr: 0.000010  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:03 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 40  total_loss: 1.464  loss_cls: 1.286  loss_box_reg: 0.083  loss_rpn_cls: 0.016  loss_rpn_loc: 0.008  lr: 0.000010  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:10 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 60  total_loss: 1.226  loss_cls: 1.036  loss_box_reg: 0.110  loss_rpn_cls: 0.023  loss_rpn_loc: 0.007  lr: 0.000015  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:10 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 60  total_loss: 1.226  loss_cls: 1.036  loss_box_reg: 0.110  loss_rpn_cls: 0.023  loss_rpn_loc: 0.007  lr: 0.000015  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:18 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 80  total_loss: 0.961  loss_cls: 0.842  loss_box_reg: 0.088  loss_rpn_cls: 0.008  loss_rpn_loc: 0.006  lr: 0.000020  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:18 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 80  total_loss: 0.961  loss_cls: 0.842  loss_box_reg: 0.088  loss_rpn_cls: 0.008  loss_rpn_loc: 0.006  lr: 0.000020  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:25 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 100  total_loss: 0.676  loss_cls: 0.526  loss_box_reg: 0.101  loss_rpn_cls: 0.015  loss_rpn_loc: 0.004  lr: 0.000025  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:25 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 100  total_loss: 0.676  loss_cls: 0.526  loss_box_reg: 0.101  loss_rpn_cls: 0.015  loss_rpn_loc: 0.004  lr: 0.000025  max_mem: 2113M\n",
      "\u001b[32m[08/23 20:21:33 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 120  total_loss: 0.458  loss_cls: 0.324  loss_box_reg: 0.104  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  lr: 0.000030  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:33 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 120  total_loss: 0.458  loss_cls: 0.324  loss_box_reg: 0.104  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  lr: 0.000030  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:40 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 140  total_loss: 0.364  loss_cls: 0.255  loss_box_reg: 0.095  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  lr: 0.000035  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:40 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 140  total_loss: 0.364  loss_cls: 0.255  loss_box_reg: 0.095  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  lr: 0.000035  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:48 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 160  total_loss: 0.309  loss_cls: 0.183  loss_box_reg: 0.091  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  lr: 0.000040  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:48 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 160  total_loss: 0.309  loss_cls: 0.183  loss_box_reg: 0.091  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  lr: 0.000040  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:56 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 180  total_loss: 0.330  loss_cls: 0.173  loss_box_reg: 0.101  loss_rpn_cls: 0.008  loss_rpn_loc: 0.008  lr: 0.000045  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:21:56 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 180  total_loss: 0.330  loss_cls: 0.173  loss_box_reg: 0.101  loss_rpn_cls: 0.008  loss_rpn_loc: 0.008  lr: 0.000045  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:03 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 200  total_loss: 0.289  loss_cls: 0.134  loss_box_reg: 0.101  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000050  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:03 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 200  total_loss: 0.289  loss_cls: 0.134  loss_box_reg: 0.101  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000050  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:11 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 220  total_loss: 0.270  loss_cls: 0.118  loss_box_reg: 0.083  loss_rpn_cls: 0.007  loss_rpn_loc: 0.012  lr: 0.000055  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:11 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 220  total_loss: 0.270  loss_cls: 0.118  loss_box_reg: 0.083  loss_rpn_cls: 0.007  loss_rpn_loc: 0.012  lr: 0.000055  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:18 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 240  total_loss: 0.279  loss_cls: 0.124  loss_box_reg: 0.117  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000060  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:18 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 240  total_loss: 0.279  loss_cls: 0.124  loss_box_reg: 0.117  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000060  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:27 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 260  total_loss: 0.318  loss_cls: 0.154  loss_box_reg: 0.118  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000065  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:22:27 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 260  total_loss: 0.318  loss_cls: 0.154  loss_box_reg: 0.118  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000065  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:34 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 280  total_loss: 0.236  loss_cls: 0.110  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000070  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:34 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 280  total_loss: 0.236  loss_cls: 0.110  loss_box_reg: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000070  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:41 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 300  total_loss: 0.241  loss_cls: 0.111  loss_box_reg: 0.076  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:41 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 300  total_loss: 0.241  loss_cls: 0.111  loss_box_reg: 0.076  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:49 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 320  total_loss: 0.207  loss_cls: 0.106  loss_box_reg: 0.097  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000080  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:49 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 320  total_loss: 0.207  loss_cls: 0.106  loss_box_reg: 0.097  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000080  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:56 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 340  total_loss: 0.209  loss_cls: 0.093  loss_box_reg: 0.092  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  lr: 0.000085  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:22:56 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 340  total_loss: 0.209  loss_cls: 0.093  loss_box_reg: 0.092  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  lr: 0.000085  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:04 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 360  total_loss: 0.237  loss_cls: 0.111  loss_box_reg: 0.104  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000090  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:04 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 360  total_loss: 0.237  loss_cls: 0.111  loss_box_reg: 0.104  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000090  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:11 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 380  total_loss: 0.239  loss_cls: 0.104  loss_box_reg: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000095  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:11 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 380  total_loss: 0.239  loss_cls: 0.104  loss_box_reg: 0.100  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  lr: 0.000095  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:19 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 400  total_loss: 0.243  loss_cls: 0.099  loss_box_reg: 0.113  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  lr: 0.000100  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:19 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 400  total_loss: 0.243  loss_cls: 0.099  loss_box_reg: 0.113  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  lr: 0.000100  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:26 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 420  total_loss: 0.203  loss_cls: 0.081  loss_box_reg: 0.105  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000105  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:26 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 420  total_loss: 0.203  loss_cls: 0.081  loss_box_reg: 0.105  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000105  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:35 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 440  total_loss: 0.234  loss_cls: 0.090  loss_box_reg: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000110  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:35 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 440  total_loss: 0.234  loss_cls: 0.090  loss_box_reg: 0.103  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000110  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:42 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 460  total_loss: 0.259  loss_cls: 0.098  loss_box_reg: 0.110  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000115  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:42 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 460  total_loss: 0.259  loss_cls: 0.098  loss_box_reg: 0.110  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  lr: 0.000115  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:50 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 480  total_loss: 0.192  loss_cls: 0.073  loss_box_reg: 0.105  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000120  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:50 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 480  total_loss: 0.192  loss_cls: 0.073  loss_box_reg: 0.105  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000120  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:58 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 500  total_loss: 0.281  loss_cls: 0.125  loss_box_reg: 0.124  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  lr: 0.000125  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:23:58 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 500  total_loss: 0.281  loss_cls: 0.125  loss_box_reg: 0.124  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  lr: 0.000125  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:05 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 520  total_loss: 0.197  loss_cls: 0.074  loss_box_reg: 0.097  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000130  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:05 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 520  total_loss: 0.197  loss_cls: 0.074  loss_box_reg: 0.097  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000130  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:13 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 540  total_loss: 0.252  loss_cls: 0.108  loss_box_reg: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000135  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:13 d2.utils.events]: \u001b[0m eta: 0:15:46  iter: 540  total_loss: 0.252  loss_cls: 0.108  loss_box_reg: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000135  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:21 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 560  total_loss: 0.236  loss_cls: 0.082  loss_box_reg: 0.110  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000140  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:21 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 560  total_loss: 0.236  loss_cls: 0.082  loss_box_reg: 0.110  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000140  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:29 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 580  total_loss: 0.201  loss_cls: 0.075  loss_box_reg: 0.112  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000145  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:29 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 580  total_loss: 0.201  loss_cls: 0.075  loss_box_reg: 0.112  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000145  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:36 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 600  total_loss: 0.199  loss_cls: 0.063  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000150  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:36 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 600  total_loss: 0.199  loss_cls: 0.063  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000150  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:44 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 620  total_loss: 0.205  loss_cls: 0.065  loss_box_reg: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000155  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:44 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 620  total_loss: 0.205  loss_cls: 0.065  loss_box_reg: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000155  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:52 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 640  total_loss: 0.193  loss_cls: 0.070  loss_box_reg: 0.105  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000160  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:52 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 640  total_loss: 0.193  loss_cls: 0.070  loss_box_reg: 0.105  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000160  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:59 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 660  total_loss: 0.201  loss_cls: 0.083  loss_box_reg: 0.100  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000165  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:24:59 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 660  total_loss: 0.201  loss_cls: 0.083  loss_box_reg: 0.100  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000165  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:07 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 680  total_loss: 0.208  loss_cls: 0.089  loss_box_reg: 0.099  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  lr: 0.000170  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:25:07 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 680  total_loss: 0.208  loss_cls: 0.089  loss_box_reg: 0.099  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  lr: 0.000170  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:15 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 700  total_loss: 0.181  loss_cls: 0.061  loss_box_reg: 0.085  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000175  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:15 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 700  total_loss: 0.181  loss_cls: 0.061  loss_box_reg: 0.085  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000175  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:23 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 720  total_loss: 0.220  loss_cls: 0.084  loss_box_reg: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000180  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:23 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 720  total_loss: 0.220  loss_cls: 0.084  loss_box_reg: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000180  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:31 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 740  total_loss: 0.228  loss_cls: 0.075  loss_box_reg: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000185  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:31 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 740  total_loss: 0.228  loss_cls: 0.075  loss_box_reg: 0.101  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  lr: 0.000185  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:39 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 760  total_loss: 0.177  loss_cls: 0.066  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000190  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:39 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 760  total_loss: 0.177  loss_cls: 0.066  loss_box_reg: 0.085  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000190  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:47 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 780  total_loss: 0.189  loss_cls: 0.067  loss_box_reg: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000195  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:47 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 780  total_loss: 0.189  loss_cls: 0.067  loss_box_reg: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000195  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:54 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 800  total_loss: 0.204  loss_cls: 0.060  loss_box_reg: 0.102  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000200  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:25:54 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 800  total_loss: 0.204  loss_cls: 0.060  loss_box_reg: 0.102  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000200  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:01 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 820  total_loss: 0.199  loss_cls: 0.067  loss_box_reg: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000205  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:01 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 820  total_loss: 0.199  loss_cls: 0.067  loss_box_reg: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000205  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:09 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 840  total_loss: 0.214  loss_cls: 0.071  loss_box_reg: 0.100  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000210  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:09 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 840  total_loss: 0.214  loss_cls: 0.071  loss_box_reg: 0.100  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000210  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:17 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 860  total_loss: 0.188  loss_cls: 0.056  loss_box_reg: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000215  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:17 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 860  total_loss: 0.188  loss_cls: 0.056  loss_box_reg: 0.110  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000215  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:24 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 880  total_loss: 0.172  loss_cls: 0.060  loss_box_reg: 0.086  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000220  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:24 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 880  total_loss: 0.172  loss_cls: 0.060  loss_box_reg: 0.086  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  lr: 0.000220  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:32 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 900  total_loss: 0.179  loss_cls: 0.058  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000225  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:32 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 900  total_loss: 0.179  loss_cls: 0.058  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000225  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:41 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 920  total_loss: 0.179  loss_cls: 0.060  loss_box_reg: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000230  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:41 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 920  total_loss: 0.179  loss_cls: 0.060  loss_box_reg: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000230  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:48 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 940  total_loss: 0.206  loss_cls: 0.061  loss_box_reg: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000235  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:48 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 940  total_loss: 0.206  loss_cls: 0.061  loss_box_reg: 0.115  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000235  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:56 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 960  total_loss: 0.232  loss_cls: 0.085  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000240  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:26:56 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 960  total_loss: 0.232  loss_cls: 0.085  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000240  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:04 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 980  total_loss: 0.169  loss_cls: 0.057  loss_box_reg: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000245  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:04 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 980  total_loss: 0.169  loss_cls: 0.057  loss_box_reg: 0.093  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000245  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:11 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 1000  total_loss: 0.142  loss_cls: 0.038  loss_box_reg: 0.081  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:11 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 1000  total_loss: 0.142  loss_cls: 0.038  loss_box_reg: 0.081  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:20 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 1020  total_loss: 0.144  loss_cls: 0.045  loss_box_reg: 0.086  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:20 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 1020  total_loss: 0.144  loss_cls: 0.045  loss_box_reg: 0.086  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:27 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 1040  total_loss: 0.134  loss_cls: 0.033  loss_box_reg: 0.079  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:27 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 1040  total_loss: 0.134  loss_cls: 0.033  loss_box_reg: 0.079  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:35 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 1060  total_loss: 0.161  loss_cls: 0.046  loss_box_reg: 0.093  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:35 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 1060  total_loss: 0.161  loss_cls: 0.046  loss_box_reg: 0.093  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:43 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 1080  total_loss: 0.161  loss_cls: 0.056  loss_box_reg: 0.090  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:43 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 1080  total_loss: 0.161  loss_cls: 0.056  loss_box_reg: 0.090  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:50 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 1100  total_loss: 0.131  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:27:50 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 1100  total_loss: 0.131  loss_cls: 0.036  loss_box_reg: 0.065  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:59 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1120  total_loss: 0.155  loss_cls: 0.050  loss_box_reg: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:27:59 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1120  total_loss: 0.155  loss_cls: 0.050  loss_box_reg: 0.086  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:07 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 1140  total_loss: 0.162  loss_cls: 0.050  loss_box_reg: 0.094  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:07 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 1140  total_loss: 0.162  loss_cls: 0.050  loss_box_reg: 0.094  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:15 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 1160  total_loss: 0.167  loss_cls: 0.046  loss_box_reg: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:15 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 1160  total_loss: 0.167  loss_cls: 0.046  loss_box_reg: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:22 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1180  total_loss: 0.184  loss_cls: 0.051  loss_box_reg: 0.082  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:22 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1180  total_loss: 0.184  loss_cls: 0.051  loss_box_reg: 0.082  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:30 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 1200  total_loss: 0.153  loss_cls: 0.047  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:30 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 1200  total_loss: 0.153  loss_cls: 0.047  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:38 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 1220  total_loss: 0.160  loss_cls: 0.049  loss_box_reg: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:38 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 1220  total_loss: 0.160  loss_cls: 0.049  loss_box_reg: 0.069  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:45 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 1240  total_loss: 0.126  loss_cls: 0.040  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:45 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 1240  total_loss: 0.126  loss_cls: 0.040  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:53 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1260  total_loss: 0.140  loss_cls: 0.039  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:28:53 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1260  total_loss: 0.140  loss_cls: 0.039  loss_box_reg: 0.067  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:01 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 1280  total_loss: 0.166  loss_cls: 0.051  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:01 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 1280  total_loss: 0.166  loss_cls: 0.051  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:08 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 1300  total_loss: 0.135  loss_cls: 0.039  loss_box_reg: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:08 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 1300  total_loss: 0.135  loss_cls: 0.039  loss_box_reg: 0.068  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:16 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 1320  total_loss: 0.117  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:16 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 1320  total_loss: 0.117  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:24 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 1340  total_loss: 0.133  loss_cls: 0.050  loss_box_reg: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:24 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 1340  total_loss: 0.133  loss_cls: 0.050  loss_box_reg: 0.071  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:32 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 1360  total_loss: 0.124  loss_cls: 0.029  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:32 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 1360  total_loss: 0.124  loss_cls: 0.029  loss_box_reg: 0.050  loss_rpn_cls: 0.001  loss_rpn_loc: 0.016  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:40 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 1380  total_loss: 0.130  loss_cls: 0.049  loss_box_reg: 0.083  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:40 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 1380  total_loss: 0.130  loss_cls: 0.049  loss_box_reg: 0.083  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:48 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1400  total_loss: 0.136  loss_cls: 0.033  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:48 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 1400  total_loss: 0.136  loss_cls: 0.033  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:55 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 1420  total_loss: 0.098  loss_cls: 0.025  loss_box_reg: 0.043  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:29:55 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 1420  total_loss: 0.098  loss_cls: 0.025  loss_box_reg: 0.043  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:03 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 1440  total_loss: 0.108  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:03 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 1440  total_loss: 0.108  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:11 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 1460  total_loss: 0.095  loss_cls: 0.027  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:11 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 1460  total_loss: 0.095  loss_cls: 0.027  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:18 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 1480  total_loss: 0.078  loss_cls: 0.024  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.016  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:18 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 1480  total_loss: 0.078  loss_cls: 0.024  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.016  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:26 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 1500  total_loss: 0.103  loss_cls: 0.039  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:26 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 1500  total_loss: 0.103  loss_cls: 0.039  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:34 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1520  total_loss: 0.112  loss_cls: 0.036  loss_box_reg: 0.056  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:30:34 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1520  total_loss: 0.112  loss_cls: 0.036  loss_box_reg: 0.056  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:43 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 1540  total_loss: 0.107  loss_cls: 0.035  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:43 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 1540  total_loss: 0.107  loss_cls: 0.035  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:51 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 1560  total_loss: 0.128  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:51 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 1560  total_loss: 0.128  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:59 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 1580  total_loss: 0.130  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:30:59 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 1580  total_loss: 0.130  loss_cls: 0.035  loss_box_reg: 0.060  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:06 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 1600  total_loss: 0.145  loss_cls: 0.045  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:06 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 1600  total_loss: 0.145  loss_cls: 0.045  loss_box_reg: 0.066  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:15 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 1620  total_loss: 0.096  loss_cls: 0.027  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:15 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 1620  total_loss: 0.096  loss_cls: 0.027  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:22 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 1640  total_loss: 0.135  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:22 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 1640  total_loss: 0.135  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:30 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 1660  total_loss: 0.098  loss_cls: 0.029  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.014  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:30 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 1660  total_loss: 0.098  loss_cls: 0.029  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.014  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:38 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 1680  total_loss: 0.101  loss_cls: 0.037  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:38 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 1680  total_loss: 0.101  loss_cls: 0.037  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:46 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 1700  total_loss: 0.097  loss_cls: 0.032  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:46 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 1700  total_loss: 0.097  loss_cls: 0.032  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:54 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 1720  total_loss: 0.100  loss_cls: 0.025  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:31:54 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 1720  total_loss: 0.100  loss_cls: 0.025  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:02 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 1740  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:02 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 1740  total_loss: 0.116  loss_cls: 0.034  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:10 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1760  total_loss: 0.103  loss_cls: 0.026  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:10 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1760  total_loss: 0.103  loss_cls: 0.026  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:17 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 1780  total_loss: 0.087  loss_cls: 0.031  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:17 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 1780  total_loss: 0.087  loss_cls: 0.031  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:25 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 1800  total_loss: 0.093  loss_cls: 0.027  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:25 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 1800  total_loss: 0.093  loss_cls: 0.027  loss_box_reg: 0.046  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:32 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1820  total_loss: 0.089  loss_cls: 0.030  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:32 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1820  total_loss: 0.089  loss_cls: 0.030  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:40 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 1840  total_loss: 0.110  loss_cls: 0.026  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:40 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 1840  total_loss: 0.110  loss_cls: 0.026  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:48 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1860  total_loss: 0.082  loss_cls: 0.022  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:48 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1860  total_loss: 0.082  loss_cls: 0.022  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:55 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 1880  total_loss: 0.090  loss_cls: 0.028  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:32:55 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 1880  total_loss: 0.090  loss_cls: 0.028  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:03 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1900  total_loss: 0.094  loss_cls: 0.031  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:03 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1900  total_loss: 0.094  loss_cls: 0.031  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:10 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1920  total_loss: 0.092  loss_cls: 0.027  loss_box_reg: 0.053  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:10 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1920  total_loss: 0.092  loss_cls: 0.027  loss_box_reg: 0.053  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:18 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 1940  total_loss: 0.093  loss_cls: 0.036  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:33:18 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 1940  total_loss: 0.093  loss_cls: 0.036  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:25 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1960  total_loss: 0.098  loss_cls: 0.024  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:25 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1960  total_loss: 0.098  loss_cls: 0.024  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:33 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 1980  total_loss: 0.111  loss_cls: 0.039  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:33 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 1980  total_loss: 0.111  loss_cls: 0.039  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:40 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2000  total_loss: 0.088  loss_cls: 0.030  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:40 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2000  total_loss: 0.088  loss_cls: 0.030  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:48 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2020  total_loss: 0.088  loss_cls: 0.027  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:48 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2020  total_loss: 0.088  loss_cls: 0.027  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:56 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 2040  total_loss: 0.098  loss_cls: 0.027  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:33:56 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 2040  total_loss: 0.098  loss_cls: 0.027  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:03 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 2060  total_loss: 0.086  loss_cls: 0.029  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:03 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 2060  total_loss: 0.086  loss_cls: 0.029  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:11 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2080  total_loss: 0.087  loss_cls: 0.026  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:11 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2080  total_loss: 0.087  loss_cls: 0.026  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:19 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 2100  total_loss: 0.076  loss_cls: 0.026  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:19 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 2100  total_loss: 0.076  loss_cls: 0.026  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:27 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 2120  total_loss: 0.087  loss_cls: 0.027  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:27 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 2120  total_loss: 0.087  loss_cls: 0.027  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:35 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 2140  total_loss: 0.112  loss_cls: 0.036  loss_box_reg: 0.068  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:35 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 2140  total_loss: 0.112  loss_cls: 0.036  loss_box_reg: 0.068  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:43 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 2160  total_loss: 0.083  loss_cls: 0.022  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:43 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 2160  total_loss: 0.083  loss_cls: 0.022  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:50 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 2180  total_loss: 0.077  loss_cls: 0.029  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:50 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 2180  total_loss: 0.077  loss_cls: 0.029  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:58 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 2200  total_loss: 0.089  loss_cls: 0.025  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:34:58 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 2200  total_loss: 0.089  loss_cls: 0.025  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:06 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 2220  total_loss: 0.094  loss_cls: 0.027  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:06 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 2220  total_loss: 0.094  loss_cls: 0.027  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:13 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 2240  total_loss: 0.081  loss_cls: 0.023  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:13 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 2240  total_loss: 0.081  loss_cls: 0.023  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:20 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 2260  total_loss: 0.071  loss_cls: 0.022  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:20 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 2260  total_loss: 0.071  loss_cls: 0.022  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:28 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2280  total_loss: 0.081  loss_cls: 0.026  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:28 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2280  total_loss: 0.081  loss_cls: 0.026  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:36 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2300  total_loss: 0.079  loss_cls: 0.024  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:36 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2300  total_loss: 0.079  loss_cls: 0.024  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:44 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2320  total_loss: 0.076  loss_cls: 0.022  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:44 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2320  total_loss: 0.076  loss_cls: 0.022  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:52 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2340  total_loss: 0.075  loss_cls: 0.020  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:52 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2340  total_loss: 0.075  loss_cls: 0.020  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:35:59 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 2360  total_loss: 0.086  loss_cls: 0.025  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:35:59 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 2360  total_loss: 0.086  loss_cls: 0.025  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:07 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 2380  total_loss: 0.063  loss_cls: 0.019  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:07 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 2380  total_loss: 0.063  loss_cls: 0.019  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:14 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 2400  total_loss: 0.081  loss_cls: 0.023  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:14 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 2400  total_loss: 0.081  loss_cls: 0.023  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:22 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 2420  total_loss: 0.073  loss_cls: 0.020  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:22 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 2420  total_loss: 0.073  loss_cls: 0.020  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:29 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2440  total_loss: 0.077  loss_cls: 0.023  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:29 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2440  total_loss: 0.077  loss_cls: 0.023  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:37 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 2460  total_loss: 0.084  loss_cls: 0.021  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:37 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 2460  total_loss: 0.084  loss_cls: 0.021  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:45 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 2480  total_loss: 0.062  loss_cls: 0.020  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:45 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 2480  total_loss: 0.062  loss_cls: 0.020  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:53 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 2500  total_loss: 0.133  loss_cls: 0.030  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:36:53 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 2500  total_loss: 0.133  loss_cls: 0.030  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:00 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 2520  total_loss: 0.085  loss_cls: 0.029  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:00 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 2520  total_loss: 0.085  loss_cls: 0.029  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:08 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 2540  total_loss: 0.056  loss_cls: 0.022  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:08 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 2540  total_loss: 0.056  loss_cls: 0.022  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:15 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 2560  total_loss: 0.073  loss_cls: 0.019  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:15 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 2560  total_loss: 0.073  loss_cls: 0.019  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:24 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 2580  total_loss: 0.084  loss_cls: 0.031  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:24 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 2580  total_loss: 0.084  loss_cls: 0.031  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:32 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2600  total_loss: 0.072  loss_cls: 0.022  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:32 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2600  total_loss: 0.072  loss_cls: 0.022  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:40 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 2620  total_loss: 0.072  loss_cls: 0.025  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:40 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 2620  total_loss: 0.072  loss_cls: 0.025  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:47 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 2640  total_loss: 0.072  loss_cls: 0.016  loss_box_reg: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:47 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 2640  total_loss: 0.072  loss_cls: 0.016  loss_box_reg: 0.037  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:55 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2660  total_loss: 0.065  loss_cls: 0.014  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:37:55 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2660  total_loss: 0.065  loss_cls: 0.014  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:02 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 2680  total_loss: 0.094  loss_cls: 0.027  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:02 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 2680  total_loss: 0.094  loss_cls: 0.027  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:10 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 2700  total_loss: 0.060  loss_cls: 0.018  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:10 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 2700  total_loss: 0.060  loss_cls: 0.018  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:17 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 2720  total_loss: 0.078  loss_cls: 0.023  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:17 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 2720  total_loss: 0.078  loss_cls: 0.023  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:25 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2740  total_loss: 0.075  loss_cls: 0.024  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:25 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2740  total_loss: 0.075  loss_cls: 0.024  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:33 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 2760  total_loss: 0.072  loss_cls: 0.022  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:33 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 2760  total_loss: 0.072  loss_cls: 0.022  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:40 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2780  total_loss: 0.087  loss_cls: 0.022  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:38:40 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2780  total_loss: 0.087  loss_cls: 0.022  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:47 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 2800  total_loss: 0.063  loss_cls: 0.018  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:47 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 2800  total_loss: 0.063  loss_cls: 0.018  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:56 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 2820  total_loss: 0.070  loss_cls: 0.021  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:38:56 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 2820  total_loss: 0.070  loss_cls: 0.021  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:03 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 2840  total_loss: 0.072  loss_cls: 0.018  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:03 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 2840  total_loss: 0.072  loss_cls: 0.018  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:11 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2860  total_loss: 0.060  loss_cls: 0.023  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:11 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2860  total_loss: 0.060  loss_cls: 0.023  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:19 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2880  total_loss: 0.078  loss_cls: 0.025  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:19 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2880  total_loss: 0.078  loss_cls: 0.025  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:26 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 2900  total_loss: 0.089  loss_cls: 0.019  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:26 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 2900  total_loss: 0.089  loss_cls: 0.019  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:35 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 2920  total_loss: 0.074  loss_cls: 0.024  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:35 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 2920  total_loss: 0.074  loss_cls: 0.024  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:44 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2940  total_loss: 0.101  loss_cls: 0.025  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:44 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2940  total_loss: 0.101  loss_cls: 0.025  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:52 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2960  total_loss: 0.086  loss_cls: 0.023  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:52 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2960  total_loss: 0.086  loss_cls: 0.023  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 2980  total_loss: 0.071  loss_cls: 0.022  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:39:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 2980  total_loss: 0.071  loss_cls: 0.022  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:40:06 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 20:40:11 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.074  loss_cls: 0.027  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:40:11 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.074  loss_cls: 0.027  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 2265M\n",
      "\u001b[32m[08/23 20:40:11 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 20:40:14 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:40:14 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:40:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 20:40:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 20:40:14 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 20:40:14 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 20:40:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 20:40:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 20:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1612 s / img. ETA=0:00:03\n",
      "\u001b[32m[08/23 20:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1612 s / img. ETA=0:00:03\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.036446 (0.167882 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.036446 (0.167882 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.165140 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.165140 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.946\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.693\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.756\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 62.160 | 94.574 | 69.322 |  nan  |  nan  | 62.160 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 62.160 | 94.574 | 69.322 |  nan  |  nan  | 62.160 |\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 63.646 | Coffeemaker | 70.720 | Tree house | 52.112 |\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 63.646 | Coffeemaker | 70.720 | Tree house | 52.112 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 20:40:20 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 20:40:20 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.testing]: \u001b[0mcopypaste: 62.1595,94.5739,69.3217,nan,nan,62.1595\n",
      "\u001b[32m[08/23 20:40:20 d2.evaluation.testing]: \u001b[0mcopypaste: 62.1595,94.5739,69.3217,nan,nan,62.1595\n",
      "### Saving results to Weights & Biases...\n",
      ">>>>>>>>>>>>> Running experiment: 3\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  MASK_ON: False\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\"\n",
      "  PIXEL_STD: [57.375, 57.120, 58.395]\n",
      "  RESNETS:\n",
      "    STRIDE_IN_1X1: False  # this is a C2 model\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    DEPTH: 101\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  MASK_ON: False\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/FAIR/X-101-32x8d.pkl\"\n",
      "  PIXEL_STD: [57.375, 57.120, 58.395]\n",
      "  RESNETS:\n",
      "    STRIDE_IN_1X1: False  # this is a C2 model\n",
      "    NUM_GROUPS: 32\n",
      "    WIDTH_PER_GROUP: 8\n",
      "    DEPTH: 101\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [57.375, 57.12, 58.395]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 32\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [57.375, 57.12, 58.395]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 32\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: False\n",
      "    WIDTH_PER_GROUP: 8\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 20:40:21 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/3mru1vev\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/3mru1vev</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:40:25 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:40:25 detectron2]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd3803a670>\n",
      "\u001b[32m[08/23 20:40:25 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n",
      "\u001b[32m[08/23 20:40:25 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl\n",
      "\u001b[32m[08/23 20:40:28 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:40:28 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:40:28 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:40:28 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 20:40:28 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "\u001b[32m[08/23 20:40:28 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{weight, bias}\u001b[0m\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[32m[08/23 20:40:28 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 20:40:28 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 20:40:28 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:40:28 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 20:40:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 20:40:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 20:40:28 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 20:40:28 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 20:40:28 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 20:40:28 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 20:40:28 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 20:40:28 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 20:40:42 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.606  loss_cls: 1.462  loss_box_reg: 0.081  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:40:42 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.606  loss_cls: 1.462  loss_box_reg: 0.081  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  lr: 0.000005  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:40:57 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 40  total_loss: 1.461  loss_cls: 1.287  loss_box_reg: 0.083  loss_rpn_cls: 0.017  loss_rpn_loc: 0.008  lr: 0.000010  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:40:57 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 40  total_loss: 1.461  loss_cls: 1.287  loss_box_reg: 0.083  loss_rpn_cls: 0.017  loss_rpn_loc: 0.008  lr: 0.000010  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:11 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 60  total_loss: 1.252  loss_cls: 1.063  loss_box_reg: 0.107  loss_rpn_cls: 0.016  loss_rpn_loc: 0.007  lr: 0.000015  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:11 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 60  total_loss: 1.252  loss_cls: 1.063  loss_box_reg: 0.107  loss_rpn_cls: 0.016  loss_rpn_loc: 0.007  lr: 0.000015  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:25 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 80  total_loss: 0.920  loss_cls: 0.799  loss_box_reg: 0.087  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  lr: 0.000020  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:25 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 80  total_loss: 0.920  loss_cls: 0.799  loss_box_reg: 0.087  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  lr: 0.000020  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:38 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 100  total_loss: 0.634  loss_cls: 0.506  loss_box_reg: 0.094  loss_rpn_cls: 0.018  loss_rpn_loc: 0.005  lr: 0.000025  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:38 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 100  total_loss: 0.634  loss_cls: 0.506  loss_box_reg: 0.094  loss_rpn_cls: 0.018  loss_rpn_loc: 0.005  lr: 0.000025  max_mem: 3504M\n",
      "\u001b[32m[08/23 20:41:52 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 120  total_loss: 0.431  loss_cls: 0.325  loss_box_reg: 0.102  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:41:52 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 120  total_loss: 0.431  loss_cls: 0.325  loss_box_reg: 0.102  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:07 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 140  total_loss: 0.337  loss_cls: 0.224  loss_box_reg: 0.094  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:07 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 140  total_loss: 0.337  loss_cls: 0.224  loss_box_reg: 0.094  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:22 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 160  total_loss: 0.326  loss_cls: 0.195  loss_box_reg: 0.098  loss_rpn_cls: 0.007  loss_rpn_loc: 0.010  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:22 d2.utils.events]: \u001b[0m eta: 0:35:09  iter: 160  total_loss: 0.326  loss_cls: 0.195  loss_box_reg: 0.098  loss_rpn_cls: 0.007  loss_rpn_loc: 0.010  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:37 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 180  total_loss: 0.311  loss_cls: 0.171  loss_box_reg: 0.107  loss_rpn_cls: 0.006  loss_rpn_loc: 0.011  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:37 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 180  total_loss: 0.311  loss_cls: 0.171  loss_box_reg: 0.107  loss_rpn_cls: 0.006  loss_rpn_loc: 0.011  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:51 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 200  total_loss: 0.271  loss_cls: 0.143  loss_box_reg: 0.100  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:42:51 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 200  total_loss: 0.271  loss_cls: 0.143  loss_box_reg: 0.100  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:05 d2.utils.events]: \u001b[0m eta: 0:32:27  iter: 220  total_loss: 0.271  loss_cls: 0.135  loss_box_reg: 0.097  loss_rpn_cls: 0.009  loss_rpn_loc: 0.012  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:05 d2.utils.events]: \u001b[0m eta: 0:32:27  iter: 220  total_loss: 0.271  loss_cls: 0.135  loss_box_reg: 0.097  loss_rpn_cls: 0.009  loss_rpn_loc: 0.012  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:19 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 240  total_loss: 0.277  loss_cls: 0.127  loss_box_reg: 0.108  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:19 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 240  total_loss: 0.277  loss_cls: 0.127  loss_box_reg: 0.108  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:33 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 260  total_loss: 0.285  loss_cls: 0.151  loss_box_reg: 0.120  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000065  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:43:33 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 260  total_loss: 0.285  loss_cls: 0.151  loss_box_reg: 0.120  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:46 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 280  total_loss: 0.225  loss_cls: 0.111  loss_box_reg: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:43:46 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 280  total_loss: 0.225  loss_cls: 0.111  loss_box_reg: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:00 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 300  total_loss: 0.271  loss_cls: 0.125  loss_box_reg: 0.101  loss_rpn_cls: 0.008  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:00 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 300  total_loss: 0.271  loss_cls: 0.125  loss_box_reg: 0.101  loss_rpn_cls: 0.008  loss_rpn_loc: 0.007  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:14 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 320  total_loss: 0.232  loss_cls: 0.107  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:14 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 320  total_loss: 0.232  loss_cls: 0.107  loss_box_reg: 0.103  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:29 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 340  total_loss: 0.217  loss_cls: 0.095  loss_box_reg: 0.093  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:29 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 340  total_loss: 0.217  loss_cls: 0.095  loss_box_reg: 0.093  loss_rpn_cls: 0.001  loss_rpn_loc: 0.014  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:44 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 360  total_loss: 0.253  loss_cls: 0.120  loss_box_reg: 0.118  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:44 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 360  total_loss: 0.253  loss_cls: 0.120  loss_box_reg: 0.118  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:58 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 380  total_loss: 0.251  loss_cls: 0.106  loss_box_reg: 0.114  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:44:58 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 380  total_loss: 0.251  loss_cls: 0.106  loss_box_reg: 0.114  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:12 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 400  total_loss: 0.225  loss_cls: 0.090  loss_box_reg: 0.097  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:12 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 400  total_loss: 0.225  loss_cls: 0.090  loss_box_reg: 0.097  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:26 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 420  total_loss: 0.225  loss_cls: 0.092  loss_box_reg: 0.096  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000105  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:26 d2.utils.events]: \u001b[0m eta: 0:30:51  iter: 420  total_loss: 0.225  loss_cls: 0.092  loss_box_reg: 0.096  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000105  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:41 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 440  total_loss: 0.218  loss_cls: 0.099  loss_box_reg: 0.104  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:41 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 440  total_loss: 0.218  loss_cls: 0.099  loss_box_reg: 0.104  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:56 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 460  total_loss: 0.236  loss_cls: 0.087  loss_box_reg: 0.097  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:45:56 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 460  total_loss: 0.236  loss_cls: 0.087  loss_box_reg: 0.097  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:09 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 480  total_loss: 0.219  loss_cls: 0.086  loss_box_reg: 0.102  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:09 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 480  total_loss: 0.219  loss_cls: 0.086  loss_box_reg: 0.102  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:24 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 500  total_loss: 0.283  loss_cls: 0.122  loss_box_reg: 0.122  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:24 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 500  total_loss: 0.283  loss_cls: 0.122  loss_box_reg: 0.122  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:38 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 520  total_loss: 0.209  loss_cls: 0.079  loss_box_reg: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:38 d2.utils.events]: \u001b[0m eta: 0:28:57  iter: 520  total_loss: 0.209  loss_cls: 0.079  loss_box_reg: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:53 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 540  total_loss: 0.223  loss_cls: 0.102  loss_box_reg: 0.111  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:46:53 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 540  total_loss: 0.223  loss_cls: 0.102  loss_box_reg: 0.111  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:08 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 560  total_loss: 0.242  loss_cls: 0.091  loss_box_reg: 0.119  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:08 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 560  total_loss: 0.242  loss_cls: 0.091  loss_box_reg: 0.119  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:23 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 580  total_loss: 0.199  loss_cls: 0.077  loss_box_reg: 0.106  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:23 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 580  total_loss: 0.199  loss_cls: 0.077  loss_box_reg: 0.106  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:37 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 600  total_loss: 0.176  loss_cls: 0.069  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:37 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 600  total_loss: 0.176  loss_cls: 0.069  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:52 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 620  total_loss: 0.179  loss_cls: 0.060  loss_box_reg: 0.096  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:47:52 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 620  total_loss: 0.179  loss_cls: 0.060  loss_box_reg: 0.096  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:06 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 640  total_loss: 0.196  loss_cls: 0.071  loss_box_reg: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:06 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 640  total_loss: 0.196  loss_cls: 0.071  loss_box_reg: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:20 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 660  total_loss: 0.227  loss_cls: 0.091  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:20 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 660  total_loss: 0.227  loss_cls: 0.091  loss_box_reg: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:35 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 680  total_loss: 0.217  loss_cls: 0.094  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000170  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:48:35 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 680  total_loss: 0.217  loss_cls: 0.094  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:50 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 700  total_loss: 0.179  loss_cls: 0.061  loss_box_reg: 0.083  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:48:50 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 700  total_loss: 0.179  loss_cls: 0.061  loss_box_reg: 0.083  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:05 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 720  total_loss: 0.208  loss_cls: 0.080  loss_box_reg: 0.089  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:05 d2.utils.events]: \u001b[0m eta: 0:29:02  iter: 720  total_loss: 0.208  loss_cls: 0.080  loss_box_reg: 0.089  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:21 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 740  total_loss: 0.212  loss_cls: 0.075  loss_box_reg: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:21 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 740  total_loss: 0.212  loss_cls: 0.075  loss_box_reg: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:35 d2.utils.events]: \u001b[0m eta: 0:26:54  iter: 760  total_loss: 0.179  loss_cls: 0.059  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:35 d2.utils.events]: \u001b[0m eta: 0:26:54  iter: 760  total_loss: 0.179  loss_cls: 0.059  loss_box_reg: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:51 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 780  total_loss: 0.181  loss_cls: 0.069  loss_box_reg: 0.102  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:49:51 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 780  total_loss: 0.181  loss_cls: 0.069  loss_box_reg: 0.102  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:04 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 800  total_loss: 0.198  loss_cls: 0.068  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:04 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 800  total_loss: 0.198  loss_cls: 0.068  loss_box_reg: 0.104  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:19 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 820  total_loss: 0.190  loss_cls: 0.058  loss_box_reg: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:19 d2.utils.events]: \u001b[0m eta: 0:26:04  iter: 820  total_loss: 0.190  loss_cls: 0.058  loss_box_reg: 0.119  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:34 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 840  total_loss: 0.209  loss_cls: 0.064  loss_box_reg: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:34 d2.utils.events]: \u001b[0m eta: 0:27:18  iter: 840  total_loss: 0.209  loss_cls: 0.064  loss_box_reg: 0.111  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:49 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 860  total_loss: 0.178  loss_cls: 0.045  loss_box_reg: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:50:49 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 860  total_loss: 0.178  loss_cls: 0.045  loss_box_reg: 0.104  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:03 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 880  total_loss: 0.187  loss_cls: 0.057  loss_box_reg: 0.089  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:03 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 880  total_loss: 0.187  loss_cls: 0.057  loss_box_reg: 0.089  loss_rpn_cls: 0.001  loss_rpn_loc: 0.012  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:18 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 900  total_loss: 0.192  loss_cls: 0.052  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:18 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 900  total_loss: 0.192  loss_cls: 0.052  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:31 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 920  total_loss: 0.167  loss_cls: 0.053  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:31 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 920  total_loss: 0.167  loss_cls: 0.053  loss_box_reg: 0.092  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:46 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 940  total_loss: 0.206  loss_cls: 0.059  loss_box_reg: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000235  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:51:46 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 940  total_loss: 0.206  loss_cls: 0.059  loss_box_reg: 0.118  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000235  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:00 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 960  total_loss: 0.234  loss_cls: 0.093  loss_box_reg: 0.117  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:00 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 960  total_loss: 0.234  loss_cls: 0.093  loss_box_reg: 0.117  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:15 d2.utils.events]: \u001b[0m eta: 0:25:04  iter: 980  total_loss: 0.169  loss_cls: 0.053  loss_box_reg: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:15 d2.utils.events]: \u001b[0m eta: 0:25:04  iter: 980  total_loss: 0.169  loss_cls: 0.053  loss_box_reg: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:29 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 1000  total_loss: 0.135  loss_cls: 0.036  loss_box_reg: 0.078  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:29 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 1000  total_loss: 0.135  loss_cls: 0.036  loss_box_reg: 0.078  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:43 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 1020  total_loss: 0.161  loss_cls: 0.044  loss_box_reg: 0.088  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:43 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 1020  total_loss: 0.161  loss_cls: 0.044  loss_box_reg: 0.088  loss_rpn_cls: 0.000  loss_rpn_loc: 0.011  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:58 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 1040  total_loss: 0.141  loss_cls: 0.038  loss_box_reg: 0.079  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:52:58 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 1040  total_loss: 0.141  loss_cls: 0.038  loss_box_reg: 0.079  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:12 d2.utils.events]: \u001b[0m eta: 0:23:10  iter: 1060  total_loss: 0.169  loss_cls: 0.041  loss_box_reg: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:12 d2.utils.events]: \u001b[0m eta: 0:23:10  iter: 1060  total_loss: 0.169  loss_cls: 0.041  loss_box_reg: 0.102  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:27 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 1080  total_loss: 0.150  loss_cls: 0.051  loss_box_reg: 0.090  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:27 d2.utils.events]: \u001b[0m eta: 0:23:01  iter: 1080  total_loss: 0.150  loss_cls: 0.051  loss_box_reg: 0.090  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:42 d2.utils.events]: \u001b[0m eta: 0:23:19  iter: 1100  total_loss: 0.129  loss_cls: 0.029  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:53:42 d2.utils.events]: \u001b[0m eta: 0:23:19  iter: 1100  total_loss: 0.129  loss_cls: 0.029  loss_box_reg: 0.072  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:56 d2.utils.events]: \u001b[0m eta: 0:23:02  iter: 1120  total_loss: 0.149  loss_cls: 0.042  loss_box_reg: 0.090  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:53:56 d2.utils.events]: \u001b[0m eta: 0:23:02  iter: 1120  total_loss: 0.149  loss_cls: 0.042  loss_box_reg: 0.090  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:10 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 1140  total_loss: 0.151  loss_cls: 0.046  loss_box_reg: 0.086  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:10 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 1140  total_loss: 0.151  loss_cls: 0.046  loss_box_reg: 0.086  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:25 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 1160  total_loss: 0.135  loss_cls: 0.032  loss_box_reg: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:25 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 1160  total_loss: 0.135  loss_cls: 0.032  loss_box_reg: 0.063  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:40 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 1180  total_loss: 0.163  loss_cls: 0.044  loss_box_reg: 0.079  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:40 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 1180  total_loss: 0.163  loss_cls: 0.044  loss_box_reg: 0.079  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:55 d2.utils.events]: \u001b[0m eta: 0:22:23  iter: 1200  total_loss: 0.137  loss_cls: 0.042  loss_box_reg: 0.077  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:54:55 d2.utils.events]: \u001b[0m eta: 0:22:23  iter: 1200  total_loss: 0.137  loss_cls: 0.042  loss_box_reg: 0.077  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:09 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 1220  total_loss: 0.133  loss_cls: 0.033  loss_box_reg: 0.070  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:09 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 1220  total_loss: 0.133  loss_cls: 0.033  loss_box_reg: 0.070  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:24 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 1240  total_loss: 0.115  loss_cls: 0.036  loss_box_reg: 0.073  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:24 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 1240  total_loss: 0.115  loss_cls: 0.036  loss_box_reg: 0.073  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:38 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 1260  total_loss: 0.123  loss_cls: 0.041  loss_box_reg: 0.068  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:38 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 1260  total_loss: 0.123  loss_cls: 0.041  loss_box_reg: 0.068  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:52 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 1280  total_loss: 0.142  loss_cls: 0.054  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:55:52 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 1280  total_loss: 0.142  loss_cls: 0.054  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:06 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 1300  total_loss: 0.107  loss_cls: 0.033  loss_box_reg: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:06 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 1300  total_loss: 0.107  loss_cls: 0.033  loss_box_reg: 0.065  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:20 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 1320  total_loss: 0.106  loss_cls: 0.028  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:20 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 1320  total_loss: 0.106  loss_cls: 0.028  loss_box_reg: 0.051  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:35 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 1340  total_loss: 0.133  loss_cls: 0.044  loss_box_reg: 0.075  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:35 d2.utils.events]: \u001b[0m eta: 0:21:10  iter: 1340  total_loss: 0.133  loss_cls: 0.044  loss_box_reg: 0.075  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:49 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 1360  total_loss: 0.118  loss_cls: 0.023  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.015  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:56:49 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 1360  total_loss: 0.118  loss_cls: 0.023  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.015  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:03 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 1380  total_loss: 0.112  loss_cls: 0.032  loss_box_reg: 0.069  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:03 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 1380  total_loss: 0.112  loss_cls: 0.032  loss_box_reg: 0.069  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:18 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 1400  total_loss: 0.116  loss_cls: 0.031  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:18 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 1400  total_loss: 0.116  loss_cls: 0.031  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:33 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 1420  total_loss: 0.107  loss_cls: 0.026  loss_box_reg: 0.043  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:33 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 1420  total_loss: 0.107  loss_cls: 0.026  loss_box_reg: 0.043  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:48 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 1440  total_loss: 0.102  loss_cls: 0.028  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:57:48 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 1440  total_loss: 0.102  loss_cls: 0.028  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:03 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 1460  total_loss: 0.107  loss_cls: 0.032  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:03 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 1460  total_loss: 0.107  loss_cls: 0.032  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:17 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 1480  total_loss: 0.090  loss_cls: 0.021  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:17 d2.utils.events]: \u001b[0m eta: 0:18:24  iter: 1480  total_loss: 0.090  loss_cls: 0.021  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:32 d2.utils.events]: \u001b[0m eta: 0:17:55  iter: 1500  total_loss: 0.112  loss_cls: 0.038  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:32 d2.utils.events]: \u001b[0m eta: 0:17:55  iter: 1500  total_loss: 0.112  loss_cls: 0.038  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:58:47 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 1520  total_loss: 0.108  loss_cls: 0.029  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 20:58:47 d2.utils.events]: \u001b[0m eta: 0:18:43  iter: 1520  total_loss: 0.108  loss_cls: 0.029  loss_box_reg: 0.058  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:01 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 1540  total_loss: 0.111  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:01 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 1540  total_loss: 0.111  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:15 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 1560  total_loss: 0.129  loss_cls: 0.028  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:15 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 1560  total_loss: 0.129  loss_cls: 0.028  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:30 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 1580  total_loss: 0.109  loss_cls: 0.031  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:30 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 1580  total_loss: 0.109  loss_cls: 0.031  loss_box_reg: 0.047  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:45 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 1600  total_loss: 0.111  loss_cls: 0.030  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 20:59:45 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 1600  total_loss: 0.111  loss_cls: 0.030  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:00 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 1620  total_loss: 0.106  loss_cls: 0.023  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:00 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 1620  total_loss: 0.106  loss_cls: 0.023  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:14 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 1640  total_loss: 0.119  loss_cls: 0.030  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:14 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 1640  total_loss: 0.119  loss_cls: 0.030  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:28 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 1660  total_loss: 0.101  loss_cls: 0.028  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:28 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 1660  total_loss: 0.101  loss_cls: 0.028  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.012  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:43 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 1680  total_loss: 0.084  loss_cls: 0.029  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:43 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 1680  total_loss: 0.084  loss_cls: 0.029  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:58 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 1700  total_loss: 0.100  loss_cls: 0.027  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:00:58 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 1700  total_loss: 0.100  loss_cls: 0.027  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:12 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 1720  total_loss: 0.105  loss_cls: 0.027  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:12 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 1720  total_loss: 0.105  loss_cls: 0.027  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:27 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 1740  total_loss: 0.114  loss_cls: 0.033  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:27 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 1740  total_loss: 0.114  loss_cls: 0.033  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:42 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 1760  total_loss: 0.098  loss_cls: 0.024  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:42 d2.utils.events]: \u001b[0m eta: 0:15:27  iter: 1760  total_loss: 0.098  loss_cls: 0.024  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:56 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 1780  total_loss: 0.086  loss_cls: 0.026  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:01:56 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 1780  total_loss: 0.086  loss_cls: 0.026  loss_box_reg: 0.042  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:10 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 1800  total_loss: 0.079  loss_cls: 0.022  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:10 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 1800  total_loss: 0.079  loss_cls: 0.022  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:24 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 1820  total_loss: 0.084  loss_cls: 0.023  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:24 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 1820  total_loss: 0.084  loss_cls: 0.023  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:39 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 1840  total_loss: 0.073  loss_cls: 0.023  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:39 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 1840  total_loss: 0.073  loss_cls: 0.023  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:54 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 1860  total_loss: 0.067  loss_cls: 0.017  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:02:54 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 1860  total_loss: 0.067  loss_cls: 0.017  loss_box_reg: 0.038  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:08 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1880  total_loss: 0.088  loss_cls: 0.023  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:08 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1880  total_loss: 0.088  loss_cls: 0.023  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:23 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 1900  total_loss: 0.080  loss_cls: 0.029  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:23 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 1900  total_loss: 0.080  loss_cls: 0.029  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:37 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 1920  total_loss: 0.087  loss_cls: 0.021  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:37 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 1920  total_loss: 0.087  loss_cls: 0.021  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:03:51 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 1940  total_loss: 0.082  loss_cls: 0.025  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:03:51 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 1940  total_loss: 0.082  loss_cls: 0.025  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:05 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1960  total_loss: 0.076  loss_cls: 0.019  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:05 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1960  total_loss: 0.076  loss_cls: 0.019  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:19 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 1980  total_loss: 0.094  loss_cls: 0.022  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:19 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 1980  total_loss: 0.094  loss_cls: 0.022  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:33 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 2000  total_loss: 0.099  loss_cls: 0.024  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:33 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 2000  total_loss: 0.099  loss_cls: 0.024  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:48 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 2020  total_loss: 0.089  loss_cls: 0.021  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:04:48 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 2020  total_loss: 0.089  loss_cls: 0.021  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:03 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 2040  total_loss: 0.089  loss_cls: 0.024  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:03 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 2040  total_loss: 0.089  loss_cls: 0.024  loss_box_reg: 0.040  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:17 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 2060  total_loss: 0.074  loss_cls: 0.029  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:17 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 2060  total_loss: 0.074  loss_cls: 0.029  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:31 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 2080  total_loss: 0.078  loss_cls: 0.019  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:31 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 2080  total_loss: 0.078  loss_cls: 0.019  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:46 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 2100  total_loss: 0.073  loss_cls: 0.021  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:05:46 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 2100  total_loss: 0.073  loss_cls: 0.021  loss_box_reg: 0.041  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:02 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 2120  total_loss: 0.084  loss_cls: 0.025  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:02 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 2120  total_loss: 0.084  loss_cls: 0.025  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:16 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 2140  total_loss: 0.091  loss_cls: 0.025  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:16 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 2140  total_loss: 0.091  loss_cls: 0.025  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:31 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 2160  total_loss: 0.065  loss_cls: 0.020  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:31 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 2160  total_loss: 0.065  loss_cls: 0.020  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:45 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 2180  total_loss: 0.062  loss_cls: 0.018  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:06:45 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 2180  total_loss: 0.062  loss_cls: 0.018  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:00 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 2200  total_loss: 0.079  loss_cls: 0.024  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:00 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 2200  total_loss: 0.079  loss_cls: 0.024  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:14 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 2220  total_loss: 0.083  loss_cls: 0.026  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:14 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 2220  total_loss: 0.083  loss_cls: 0.026  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:28 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 2240  total_loss: 0.064  loss_cls: 0.019  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:28 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 2240  total_loss: 0.064  loss_cls: 0.019  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:42 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 2260  total_loss: 0.053  loss_cls: 0.017  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:42 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 2260  total_loss: 0.053  loss_cls: 0.017  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:57 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 2280  total_loss: 0.062  loss_cls: 0.018  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:07:57 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 2280  total_loss: 0.062  loss_cls: 0.018  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:12 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 2300  total_loss: 0.064  loss_cls: 0.019  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:12 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 2300  total_loss: 0.064  loss_cls: 0.019  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:27 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 2320  total_loss: 0.060  loss_cls: 0.019  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:27 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 2320  total_loss: 0.060  loss_cls: 0.019  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:41 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 2340  total_loss: 0.064  loss_cls: 0.018  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:41 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 2340  total_loss: 0.064  loss_cls: 0.018  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:08:56 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 2360  total_loss: 0.087  loss_cls: 0.022  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:08:56 d2.utils.events]: \u001b[0m eta: 0:07:36  iter: 2360  total_loss: 0.087  loss_cls: 0.022  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:10 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 2380  total_loss: 0.064  loss_cls: 0.016  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:10 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 2380  total_loss: 0.064  loss_cls: 0.016  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:24 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 2400  total_loss: 0.079  loss_cls: 0.026  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:24 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 2400  total_loss: 0.079  loss_cls: 0.026  loss_box_reg: 0.044  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:38 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 2420  total_loss: 0.080  loss_cls: 0.016  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:38 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 2420  total_loss: 0.080  loss_cls: 0.016  loss_box_reg: 0.039  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:53 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 2440  total_loss: 0.063  loss_cls: 0.017  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:09:53 d2.utils.events]: \u001b[0m eta: 0:06:50  iter: 2440  total_loss: 0.063  loss_cls: 0.017  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:08 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 2460  total_loss: 0.068  loss_cls: 0.021  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:08 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 2460  total_loss: 0.068  loss_cls: 0.021  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:22 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2480  total_loss: 0.053  loss_cls: 0.018  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:22 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 2480  total_loss: 0.053  loss_cls: 0.018  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:38 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 2500  total_loss: 0.096  loss_cls: 0.023  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:38 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 2500  total_loss: 0.096  loss_cls: 0.023  loss_box_reg: 0.043  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:53 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 2520  total_loss: 0.071  loss_cls: 0.024  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:10:53 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 2520  total_loss: 0.071  loss_cls: 0.024  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:07 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 2540  total_loss: 0.054  loss_cls: 0.019  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:07 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 2540  total_loss: 0.054  loss_cls: 0.019  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:21 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 2560  total_loss: 0.064  loss_cls: 0.013  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:21 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 2560  total_loss: 0.064  loss_cls: 0.013  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:36 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 2580  total_loss: 0.066  loss_cls: 0.023  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:36 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 2580  total_loss: 0.066  loss_cls: 0.023  loss_box_reg: 0.036  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:51 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 2600  total_loss: 0.066  loss_cls: 0.020  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:11:51 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 2600  total_loss: 0.066  loss_cls: 0.020  loss_box_reg: 0.031  loss_rpn_cls: 0.000  loss_rpn_loc: 0.008  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:06 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 2620  total_loss: 0.061  loss_cls: 0.017  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:06 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 2620  total_loss: 0.061  loss_cls: 0.017  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:21 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 2640  total_loss: 0.064  loss_cls: 0.015  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:21 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 2640  total_loss: 0.064  loss_cls: 0.015  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:35 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 2660  total_loss: 0.061  loss_cls: 0.014  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:35 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 2660  total_loss: 0.061  loss_cls: 0.014  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.009  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:50 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 2680  total_loss: 0.076  loss_cls: 0.020  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:12:50 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 2680  total_loss: 0.076  loss_cls: 0.020  loss_box_reg: 0.037  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:04 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 2700  total_loss: 0.056  loss_cls: 0.015  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:04 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 2700  total_loss: 0.056  loss_cls: 0.015  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:19 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2720  total_loss: 0.060  loss_cls: 0.017  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:19 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2720  total_loss: 0.060  loss_cls: 0.017  loss_box_reg: 0.029  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:33 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 2740  total_loss: 0.066  loss_cls: 0.020  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:33 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 2740  total_loss: 0.066  loss_cls: 0.020  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:49 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 2760  total_loss: 0.062  loss_cls: 0.018  loss_box_reg: 0.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:13:49 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 2760  total_loss: 0.062  loss_cls: 0.018  loss_box_reg: 0.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:02 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 2780  total_loss: 0.065  loss_cls: 0.020  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:14:02 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 2780  total_loss: 0.065  loss_cls: 0.020  loss_box_reg: 0.034  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:16 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 2800  total_loss: 0.058  loss_cls: 0.016  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:16 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 2800  total_loss: 0.058  loss_cls: 0.016  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:32 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2820  total_loss: 0.054  loss_cls: 0.016  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:32 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2820  total_loss: 0.054  loss_cls: 0.016  loss_box_reg: 0.026  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:47 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2840  total_loss: 0.077  loss_cls: 0.019  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:14:47 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 2840  total_loss: 0.077  loss_cls: 0.019  loss_box_reg: 0.033  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:02 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 2860  total_loss: 0.055  loss_cls: 0.018  loss_box_reg: 0.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:02 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 2860  total_loss: 0.055  loss_cls: 0.018  loss_box_reg: 0.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:17 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2880  total_loss: 0.058  loss_cls: 0.018  loss_box_reg: 0.024  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:17 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 2880  total_loss: 0.058  loss_cls: 0.018  loss_box_reg: 0.024  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:31 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2900  total_loss: 0.061  loss_cls: 0.020  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:31 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 2900  total_loss: 0.061  loss_cls: 0.020  loss_box_reg: 0.030  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:46 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 2920  total_loss: 0.066  loss_cls: 0.016  loss_box_reg: 0.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:15:46 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 2920  total_loss: 0.066  loss_cls: 0.016  loss_box_reg: 0.028  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:02 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 2940  total_loss: 0.065  loss_cls: 0.017  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:02 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 2940  total_loss: 0.065  loss_cls: 0.017  loss_box_reg: 0.027  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:16 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2960  total_loss: 0.079  loss_cls: 0.020  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:16 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2960  total_loss: 0.079  loss_cls: 0.020  loss_box_reg: 0.035  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:30 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 2980  total_loss: 0.050  loss_cls: 0.020  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:30 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 2980  total_loss: 0.050  loss_cls: 0.020  loss_box_reg: 0.025  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:44 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 21:16:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.058  loss_cls: 0.017  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.058  loss_cls: 0.017  loss_box_reg: 0.032  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:16:53 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 21:17:02 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:17:02 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:17:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 21:17:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 21:17:02 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 21:17:02 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 21:17:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 21:17:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 21:17:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.2747 s / img. ETA=0:00:06\n",
      "\u001b[32m[08/23 21:17:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.2747 s / img. ETA=0:00:06\n",
      "\u001b[32m[08/23 21:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 29/35. 0.2797 s / img. ETA=0:00:01\n",
      "\u001b[32m[08/23 21:17:10 d2.evaluation.evaluator]: \u001b[0mInference done 29/35. 0.2797 s / img. ETA=0:00:01\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.492669 (0.283089 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:08.492669 (0.283089 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.280232 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:08 (0.280232 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.561\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.906\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.561\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.649\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.739\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.739\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 56.058 | 90.646 | 60.362 |  nan  |  nan  | 56.075 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 56.058 | 90.646 | 60.362 |  nan  |  nan  | 56.075 |\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 63.888 | Coffeemaker | 52.255 | Tree house | 52.030 |\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 63.888 | Coffeemaker | 52.255 | Tree house | 52.030 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: 56.0576,90.6462,60.3618,nan,nan,56.0754\n",
      "\u001b[32m[08/23 21:17:12 d2.evaluation.testing]: \u001b[0mcopypaste: 56.0576,90.6462,60.3618,nan,nan,56.0754\n",
      "### Saving results to Weights & Biases...\n",
      ">>>>>>>>>>>>> Running experiment: 4\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 21:17:12 fvcore.common.config]: \u001b[0mLoading config /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml:\n",
      "_BASE_: \"../Base-RetinaNet.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_1x.yaml:\n",
      "_BASE_: \"../Base-RetinaNet.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: RetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: RetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 21:17:12 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2jxomuol\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/2jxomuol</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:17:15 detectron2]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:17:15 detectron2]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd2048edf0>\n",
      "\u001b[32m[08/23 21:17:15 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "\u001b[32m[08/23 21:17:15 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "\u001b[32m[08/23 21:17:16 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[32m[08/23 21:17:16 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 21:17:16 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 21:17:16 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:17:16 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:17:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 21:17:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 21:17:16 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 21:17:16 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 21:17:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 21:17:16 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 21:17:16 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 21:17:16 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 21:17:22 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.005  loss_cls: 0.830  loss_box_reg: 0.149  lr: 0.000005  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:22 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.005  loss_cls: 0.830  loss_box_reg: 0.149  lr: 0.000005  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:28 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 40  total_loss: 1.748  loss_cls: 1.608  loss_box_reg: 0.214  lr: 0.000010  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:28 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 40  total_loss: 1.748  loss_cls: 1.608  loss_box_reg: 0.214  lr: 0.000010  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:34 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 60  total_loss: 1.227  loss_cls: 0.796  loss_box_reg: 0.270  lr: 0.000015  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:34 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 60  total_loss: 1.227  loss_cls: 0.796  loss_box_reg: 0.270  lr: 0.000015  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:40 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 80  total_loss: 1.064  loss_cls: 0.863  loss_box_reg: 0.234  lr: 0.000020  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:40 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 80  total_loss: 1.064  loss_cls: 0.863  loss_box_reg: 0.234  lr: 0.000020  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:45 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 100  total_loss: 1.030  loss_cls: 0.879  loss_box_reg: 0.183  lr: 0.000025  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:45 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 100  total_loss: 1.030  loss_cls: 0.879  loss_box_reg: 0.183  lr: 0.000025  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:51 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 120  total_loss: 0.798  loss_cls: 0.492  loss_box_reg: 0.307  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:51 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 120  total_loss: 0.798  loss_cls: 0.492  loss_box_reg: 0.307  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:58 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 140  total_loss: 0.865  loss_cls: 0.501  loss_box_reg: 0.277  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:17:58 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 140  total_loss: 0.865  loss_cls: 0.501  loss_box_reg: 0.277  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:04 d2.utils.events]: \u001b[0m eta: 0:14:15  iter: 160  total_loss: 0.556  loss_cls: 0.326  loss_box_reg: 0.252  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:04 d2.utils.events]: \u001b[0m eta: 0:14:15  iter: 160  total_loss: 0.556  loss_cls: 0.326  loss_box_reg: 0.252  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:10 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 180  total_loss: 0.722  loss_cls: 0.432  loss_box_reg: 0.301  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:10 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 180  total_loss: 0.722  loss_cls: 0.432  loss_box_reg: 0.301  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:15 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 200  total_loss: 0.653  loss_cls: 0.376  loss_box_reg: 0.289  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:15 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 200  total_loss: 0.653  loss_cls: 0.376  loss_box_reg: 0.289  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:21 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 220  total_loss: 0.492  loss_cls: 0.259  loss_box_reg: 0.177  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:21 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 220  total_loss: 0.492  loss_cls: 0.259  loss_box_reg: 0.177  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:27 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 240  total_loss: 0.533  loss_cls: 0.232  loss_box_reg: 0.232  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:27 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 240  total_loss: 0.533  loss_cls: 0.232  loss_box_reg: 0.232  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:32 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 260  total_loss: 0.528  loss_cls: 0.258  loss_box_reg: 0.227  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:32 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 260  total_loss: 0.528  loss_cls: 0.258  loss_box_reg: 0.227  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:37 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 280  total_loss: 0.487  loss_cls: 0.244  loss_box_reg: 0.231  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:37 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 280  total_loss: 0.487  loss_cls: 0.244  loss_box_reg: 0.231  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:43 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 300  total_loss: 0.501  loss_cls: 0.241  loss_box_reg: 0.242  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:43 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 300  total_loss: 0.501  loss_cls: 0.241  loss_box_reg: 0.242  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:49 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 320  total_loss: 0.398  loss_cls: 0.177  loss_box_reg: 0.172  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:49 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 320  total_loss: 0.398  loss_cls: 0.177  loss_box_reg: 0.172  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:55 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 340  total_loss: 0.356  loss_cls: 0.167  loss_box_reg: 0.167  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:18:55 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 340  total_loss: 0.356  loss_cls: 0.167  loss_box_reg: 0.167  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:00 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 360  total_loss: 0.453  loss_cls: 0.254  loss_box_reg: 0.160  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:00 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 360  total_loss: 0.453  loss_cls: 0.254  loss_box_reg: 0.160  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:06 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 380  total_loss: 0.421  loss_cls: 0.150  loss_box_reg: 0.180  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:06 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 380  total_loss: 0.421  loss_cls: 0.150  loss_box_reg: 0.180  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:12 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 400  total_loss: 0.349  loss_cls: 0.124  loss_box_reg: 0.155  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:12 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 400  total_loss: 0.349  loss_cls: 0.124  loss_box_reg: 0.155  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:17 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 420  total_loss: 0.256  loss_cls: 0.094  loss_box_reg: 0.160  lr: 0.000105  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:19:17 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 420  total_loss: 0.256  loss_cls: 0.094  loss_box_reg: 0.160  lr: 0.000105  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:23 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 440  total_loss: 0.454  loss_cls: 0.209  loss_box_reg: 0.217  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:23 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 440  total_loss: 0.454  loss_cls: 0.209  loss_box_reg: 0.217  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:30 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 460  total_loss: 0.403  loss_cls: 0.160  loss_box_reg: 0.249  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:30 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 460  total_loss: 0.403  loss_cls: 0.160  loss_box_reg: 0.249  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:36 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 480  total_loss: 0.349  loss_cls: 0.175  loss_box_reg: 0.169  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:36 d2.utils.events]: \u001b[0m eta: 0:11:49  iter: 480  total_loss: 0.349  loss_cls: 0.175  loss_box_reg: 0.169  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:42 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 500  total_loss: 0.423  loss_cls: 0.259  loss_box_reg: 0.181  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:42 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 500  total_loss: 0.423  loss_cls: 0.259  loss_box_reg: 0.181  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:47 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 520  total_loss: 0.208  loss_cls: 0.090  loss_box_reg: 0.087  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:47 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 520  total_loss: 0.208  loss_cls: 0.090  loss_box_reg: 0.087  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:53 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 540  total_loss: 0.423  loss_cls: 0.192  loss_box_reg: 0.212  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:53 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 540  total_loss: 0.423  loss_cls: 0.192  loss_box_reg: 0.212  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:59 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 560  total_loss: 0.236  loss_cls: 0.102  loss_box_reg: 0.093  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:19:59 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 560  total_loss: 0.236  loss_cls: 0.102  loss_box_reg: 0.093  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:05 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 580  total_loss: 0.375  loss_cls: 0.141  loss_box_reg: 0.177  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:05 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 580  total_loss: 0.375  loss_cls: 0.141  loss_box_reg: 0.177  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:11 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 600  total_loss: 0.237  loss_cls: 0.079  loss_box_reg: 0.154  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:11 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 600  total_loss: 0.237  loss_cls: 0.079  loss_box_reg: 0.154  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:17 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 620  total_loss: 0.221  loss_cls: 0.105  loss_box_reg: 0.116  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:17 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 620  total_loss: 0.221  loss_cls: 0.105  loss_box_reg: 0.116  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:23 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 640  total_loss: 0.321  loss_cls: 0.122  loss_box_reg: 0.145  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:23 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 640  total_loss: 0.321  loss_cls: 0.122  loss_box_reg: 0.145  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:29 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 660  total_loss: 0.399  loss_cls: 0.142  loss_box_reg: 0.226  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:29 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 660  total_loss: 0.399  loss_cls: 0.142  loss_box_reg: 0.226  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:35 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 680  total_loss: 0.337  loss_cls: 0.172  loss_box_reg: 0.172  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:35 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 680  total_loss: 0.337  loss_cls: 0.172  loss_box_reg: 0.172  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:42 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 700  total_loss: 0.307  loss_cls: 0.142  loss_box_reg: 0.148  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:42 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 700  total_loss: 0.307  loss_cls: 0.142  loss_box_reg: 0.148  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:48 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 720  total_loss: 0.294  loss_cls: 0.133  loss_box_reg: 0.167  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:48 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 720  total_loss: 0.294  loss_cls: 0.133  loss_box_reg: 0.167  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:54 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 740  total_loss: 0.331  loss_cls: 0.150  loss_box_reg: 0.205  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:20:54 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 740  total_loss: 0.331  loss_cls: 0.150  loss_box_reg: 0.205  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:00 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 760  total_loss: 0.249  loss_cls: 0.115  loss_box_reg: 0.126  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:00 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 760  total_loss: 0.249  loss_cls: 0.115  loss_box_reg: 0.126  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:06 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 780  total_loss: 0.318  loss_cls: 0.102  loss_box_reg: 0.123  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:06 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 780  total_loss: 0.318  loss_cls: 0.102  loss_box_reg: 0.123  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:12 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 800  total_loss: 0.190  loss_cls: 0.071  loss_box_reg: 0.098  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:12 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 800  total_loss: 0.190  loss_cls: 0.071  loss_box_reg: 0.098  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:17 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 820  total_loss: 0.220  loss_cls: 0.073  loss_box_reg: 0.128  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:17 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 820  total_loss: 0.220  loss_cls: 0.073  loss_box_reg: 0.128  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:23 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 840  total_loss: 0.309  loss_cls: 0.101  loss_box_reg: 0.164  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:23 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 840  total_loss: 0.309  loss_cls: 0.101  loss_box_reg: 0.164  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:29 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 860  total_loss: 0.326  loss_cls: 0.107  loss_box_reg: 0.163  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:29 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 860  total_loss: 0.326  loss_cls: 0.107  loss_box_reg: 0.163  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:35 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 880  total_loss: 0.212  loss_cls: 0.098  loss_box_reg: 0.114  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:35 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 880  total_loss: 0.212  loss_cls: 0.098  loss_box_reg: 0.114  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:42 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 900  total_loss: 0.259  loss_cls: 0.113  loss_box_reg: 0.119  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:42 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 900  total_loss: 0.259  loss_cls: 0.113  loss_box_reg: 0.119  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:47 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 920  total_loss: 0.358  loss_cls: 0.151  loss_box_reg: 0.193  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:47 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 920  total_loss: 0.358  loss_cls: 0.151  loss_box_reg: 0.193  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:53 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 940  total_loss: 0.229  loss_cls: 0.109  loss_box_reg: 0.121  lr: 0.000235  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:53 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 940  total_loss: 0.229  loss_cls: 0.109  loss_box_reg: 0.121  lr: 0.000235  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:21:59 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 960  total_loss: 0.259  loss_cls: 0.128  loss_box_reg: 0.116  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:21:59 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 960  total_loss: 0.259  loss_cls: 0.128  loss_box_reg: 0.116  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:05 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 980  total_loss: 0.224  loss_cls: 0.109  loss_box_reg: 0.103  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:05 d2.utils.events]: \u001b[0m eta: 0:09:56  iter: 980  total_loss: 0.224  loss_cls: 0.109  loss_box_reg: 0.103  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:10 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 1000  total_loss: 0.379  loss_cls: 0.118  loss_box_reg: 0.256  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:10 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 1000  total_loss: 0.379  loss_cls: 0.118  loss_box_reg: 0.256  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:16 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 1020  total_loss: 0.253  loss_cls: 0.098  loss_box_reg: 0.131  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:16 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 1020  total_loss: 0.253  loss_cls: 0.098  loss_box_reg: 0.131  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:22 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 1040  total_loss: 0.236  loss_cls: 0.085  loss_box_reg: 0.134  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:22 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 1040  total_loss: 0.236  loss_cls: 0.085  loss_box_reg: 0.134  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:28 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 1060  total_loss: 0.215  loss_cls: 0.070  loss_box_reg: 0.110  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:28 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 1060  total_loss: 0.215  loss_cls: 0.070  loss_box_reg: 0.110  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:33 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1080  total_loss: 0.223  loss_cls: 0.100  loss_box_reg: 0.130  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:33 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1080  total_loss: 0.223  loss_cls: 0.100  loss_box_reg: 0.130  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:40 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 1100  total_loss: 0.174  loss_cls: 0.063  loss_box_reg: 0.108  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:40 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 1100  total_loss: 0.174  loss_cls: 0.063  loss_box_reg: 0.108  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:46 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1120  total_loss: 0.226  loss_cls: 0.082  loss_box_reg: 0.126  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:46 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1120  total_loss: 0.226  loss_cls: 0.082  loss_box_reg: 0.126  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:51 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1140  total_loss: 0.139  loss_cls: 0.065  loss_box_reg: 0.098  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:51 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1140  total_loss: 0.139  loss_cls: 0.065  loss_box_reg: 0.098  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:57 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1160  total_loss: 0.258  loss_cls: 0.080  loss_box_reg: 0.111  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:22:57 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1160  total_loss: 0.258  loss_cls: 0.080  loss_box_reg: 0.111  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:03 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1180  total_loss: 0.272  loss_cls: 0.100  loss_box_reg: 0.124  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:03 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1180  total_loss: 0.272  loss_cls: 0.100  loss_box_reg: 0.124  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:09 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 1200  total_loss: 0.223  loss_cls: 0.101  loss_box_reg: 0.092  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:09 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 1200  total_loss: 0.223  loss_cls: 0.101  loss_box_reg: 0.092  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:14 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1220  total_loss: 0.198  loss_cls: 0.089  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:14 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1220  total_loss: 0.198  loss_cls: 0.089  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:21 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 1240  total_loss: 0.157  loss_cls: 0.048  loss_box_reg: 0.106  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:21 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 1240  total_loss: 0.157  loss_cls: 0.048  loss_box_reg: 0.106  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:27 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 1260  total_loss: 0.152  loss_cls: 0.073  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:27 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 1260  total_loss: 0.152  loss_cls: 0.073  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:33 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 1280  total_loss: 0.168  loss_cls: 0.085  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:33 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 1280  total_loss: 0.168  loss_cls: 0.085  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:38 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 1300  total_loss: 0.193  loss_cls: 0.071  loss_box_reg: 0.103  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:38 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 1300  total_loss: 0.193  loss_cls: 0.071  loss_box_reg: 0.103  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:44 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 1320  total_loss: 0.127  loss_cls: 0.054  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:44 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 1320  total_loss: 0.127  loss_cls: 0.054  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:50 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 1340  total_loss: 0.222  loss_cls: 0.077  loss_box_reg: 0.123  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:50 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 1340  total_loss: 0.222  loss_cls: 0.077  loss_box_reg: 0.123  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:56 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1360  total_loss: 0.172  loss_cls: 0.067  loss_box_reg: 0.115  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:23:56 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1360  total_loss: 0.172  loss_cls: 0.067  loss_box_reg: 0.115  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:02 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1380  total_loss: 0.239  loss_cls: 0.081  loss_box_reg: 0.154  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:02 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1380  total_loss: 0.239  loss_cls: 0.081  loss_box_reg: 0.154  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:08 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1400  total_loss: 0.215  loss_cls: 0.081  loss_box_reg: 0.101  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:08 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1400  total_loss: 0.215  loss_cls: 0.081  loss_box_reg: 0.101  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:14 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 1420  total_loss: 0.146  loss_cls: 0.040  loss_box_reg: 0.099  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:14 d2.utils.events]: \u001b[0m eta: 0:07:42  iter: 1420  total_loss: 0.146  loss_cls: 0.040  loss_box_reg: 0.099  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:20 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 1440  total_loss: 0.163  loss_cls: 0.054  loss_box_reg: 0.099  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:20 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 1440  total_loss: 0.163  loss_cls: 0.054  loss_box_reg: 0.099  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:26 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1460  total_loss: 0.172  loss_cls: 0.047  loss_box_reg: 0.113  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:26 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1460  total_loss: 0.172  loss_cls: 0.047  loss_box_reg: 0.113  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:31 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1480  total_loss: 0.162  loss_cls: 0.069  loss_box_reg: 0.112  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:24:31 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1480  total_loss: 0.162  loss_cls: 0.069  loss_box_reg: 0.112  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:37 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1500  total_loss: 0.197  loss_cls: 0.070  loss_box_reg: 0.117  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:37 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1500  total_loss: 0.197  loss_cls: 0.070  loss_box_reg: 0.117  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:43 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 1520  total_loss: 0.123  loss_cls: 0.046  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:43 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 1520  total_loss: 0.123  loss_cls: 0.046  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:49 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1540  total_loss: 0.138  loss_cls: 0.057  loss_box_reg: 0.085  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:49 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1540  total_loss: 0.138  loss_cls: 0.057  loss_box_reg: 0.085  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:55 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 1560  total_loss: 0.147  loss_cls: 0.043  loss_box_reg: 0.108  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:24:55 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 1560  total_loss: 0.147  loss_cls: 0.043  loss_box_reg: 0.108  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:01 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1580  total_loss: 0.159  loss_cls: 0.051  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:01 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1580  total_loss: 0.159  loss_cls: 0.051  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:07 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 1600  total_loss: 0.162  loss_cls: 0.047  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:07 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 1600  total_loss: 0.162  loss_cls: 0.047  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:13 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1620  total_loss: 0.128  loss_cls: 0.027  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:13 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1620  total_loss: 0.128  loss_cls: 0.027  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:19 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1640  total_loss: 0.188  loss_cls: 0.052  loss_box_reg: 0.102  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:19 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 1640  total_loss: 0.188  loss_cls: 0.052  loss_box_reg: 0.102  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:25 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 1660  total_loss: 0.113  loss_cls: 0.035  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:25 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 1660  total_loss: 0.113  loss_cls: 0.035  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:31 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 1680  total_loss: 0.139  loss_cls: 0.044  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:31 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 1680  total_loss: 0.139  loss_cls: 0.044  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:37 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1700  total_loss: 0.197  loss_cls: 0.047  loss_box_reg: 0.113  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:37 d2.utils.events]: \u001b[0m eta: 0:06:26  iter: 1700  total_loss: 0.197  loss_cls: 0.047  loss_box_reg: 0.113  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:43 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1720  total_loss: 0.133  loss_cls: 0.051  loss_box_reg: 0.088  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:43 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 1720  total_loss: 0.133  loss_cls: 0.051  loss_box_reg: 0.088  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:48 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 1740  total_loss: 0.200  loss_cls: 0.050  loss_box_reg: 0.114  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:48 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 1740  total_loss: 0.200  loss_cls: 0.050  loss_box_reg: 0.114  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:54 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1760  total_loss: 0.148  loss_cls: 0.041  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:25:54 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 1760  total_loss: 0.148  loss_cls: 0.041  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:00 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1780  total_loss: 0.147  loss_cls: 0.043  loss_box_reg: 0.079  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:00 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 1780  total_loss: 0.147  loss_cls: 0.043  loss_box_reg: 0.079  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:06 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1800  total_loss: 0.099  loss_cls: 0.049  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:06 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 1800  total_loss: 0.099  loss_cls: 0.049  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:11 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1820  total_loss: 0.124  loss_cls: 0.035  loss_box_reg: 0.089  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:11 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1820  total_loss: 0.124  loss_cls: 0.035  loss_box_reg: 0.089  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:18 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1840  total_loss: 0.133  loss_cls: 0.032  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:18 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 1840  total_loss: 0.133  loss_cls: 0.032  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:24 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 1860  total_loss: 0.105  loss_cls: 0.032  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:24 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 1860  total_loss: 0.105  loss_cls: 0.032  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:29 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 1880  total_loss: 0.142  loss_cls: 0.039  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:29 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 1880  total_loss: 0.142  loss_cls: 0.039  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:36 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1900  total_loss: 0.136  loss_cls: 0.037  loss_box_reg: 0.099  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:36 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 1900  total_loss: 0.136  loss_cls: 0.037  loss_box_reg: 0.099  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:41 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1920  total_loss: 0.158  loss_cls: 0.038  loss_box_reg: 0.112  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:41 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 1920  total_loss: 0.158  loss_cls: 0.038  loss_box_reg: 0.112  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:47 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 1940  total_loss: 0.119  loss_cls: 0.031  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:47 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 1940  total_loss: 0.119  loss_cls: 0.031  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:52 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1960  total_loss: 0.125  loss_cls: 0.034  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:52 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1960  total_loss: 0.125  loss_cls: 0.034  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:58 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 1980  total_loss: 0.150  loss_cls: 0.041  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:26:58 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 1980  total_loss: 0.150  loss_cls: 0.041  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:04 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 2000  total_loss: 0.126  loss_cls: 0.036  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:04 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 2000  total_loss: 0.126  loss_cls: 0.036  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:27:10 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 2020  total_loss: 0.106  loss_cls: 0.040  loss_box_reg: 0.061  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:10 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 2020  total_loss: 0.106  loss_cls: 0.040  loss_box_reg: 0.061  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:16 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 2040  total_loss: 0.109  loss_cls: 0.040  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:16 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 2040  total_loss: 0.109  loss_cls: 0.040  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:21 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 2060  total_loss: 0.089  loss_cls: 0.021  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:21 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 2060  total_loss: 0.089  loss_cls: 0.021  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:27 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 2080  total_loss: 0.086  loss_cls: 0.019  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:27 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 2080  total_loss: 0.086  loss_cls: 0.019  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:32 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 2100  total_loss: 0.099  loss_cls: 0.026  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:32 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 2100  total_loss: 0.099  loss_cls: 0.026  loss_box_reg: 0.080  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:39 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 2120  total_loss: 0.134  loss_cls: 0.035  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:39 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 2120  total_loss: 0.134  loss_cls: 0.035  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:44 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2140  total_loss: 0.124  loss_cls: 0.029  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:44 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 2140  total_loss: 0.124  loss_cls: 0.029  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:50 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 2160  total_loss: 0.112  loss_cls: 0.021  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:50 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 2160  total_loss: 0.112  loss_cls: 0.021  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:56 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 2180  total_loss: 0.095  loss_cls: 0.023  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:27:56 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 2180  total_loss: 0.095  loss_cls: 0.023  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:02 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 2200  total_loss: 0.124  loss_cls: 0.025  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:02 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 2200  total_loss: 0.124  loss_cls: 0.025  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:08 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 2220  total_loss: 0.123  loss_cls: 0.047  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:08 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 2220  total_loss: 0.123  loss_cls: 0.047  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:13 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 2240  total_loss: 0.099  loss_cls: 0.021  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:13 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 2240  total_loss: 0.099  loss_cls: 0.021  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:19 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 2260  total_loss: 0.095  loss_cls: 0.016  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:19 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 2260  total_loss: 0.095  loss_cls: 0.016  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:25 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 2280  total_loss: 0.093  loss_cls: 0.018  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:25 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 2280  total_loss: 0.093  loss_cls: 0.018  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:31 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2300  total_loss: 0.127  loss_cls: 0.025  loss_box_reg: 0.089  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:31 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 2300  total_loss: 0.127  loss_cls: 0.025  loss_box_reg: 0.089  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:37 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 2320  total_loss: 0.133  loss_cls: 0.030  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:37 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 2320  total_loss: 0.133  loss_cls: 0.030  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:43 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 2340  total_loss: 0.077  loss_cls: 0.017  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:43 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 2340  total_loss: 0.077  loss_cls: 0.017  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:49 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 2360  total_loss: 0.084  loss_cls: 0.012  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:49 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 2360  total_loss: 0.084  loss_cls: 0.012  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:55 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2380  total_loss: 0.053  loss_cls: 0.011  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:28:55 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2380  total_loss: 0.053  loss_cls: 0.011  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:01 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 2400  total_loss: 0.085  loss_cls: 0.022  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:01 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 2400  total_loss: 0.085  loss_cls: 0.022  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:07 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 2420  total_loss: 0.084  loss_cls: 0.022  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:07 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 2420  total_loss: 0.084  loss_cls: 0.022  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:13 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 2440  total_loss: 0.083  loss_cls: 0.013  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:13 d2.utils.events]: \u001b[0m eta: 0:02:47  iter: 2440  total_loss: 0.083  loss_cls: 0.013  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:19 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 2460  total_loss: 0.088  loss_cls: 0.020  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:19 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 2460  total_loss: 0.088  loss_cls: 0.020  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:25 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 2480  total_loss: 0.085  loss_cls: 0.016  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:25 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 2480  total_loss: 0.085  loss_cls: 0.016  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:31 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 2500  total_loss: 0.131  loss_cls: 0.017  loss_box_reg: 0.092  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:31 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 2500  total_loss: 0.131  loss_cls: 0.017  loss_box_reg: 0.092  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:37 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2520  total_loss: 0.099  loss_cls: 0.025  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:37 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2520  total_loss: 0.099  loss_cls: 0.025  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:43 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2540  total_loss: 0.076  loss_cls: 0.013  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:29:43 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2540  total_loss: 0.076  loss_cls: 0.013  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:50 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 2560  total_loss: 0.081  loss_cls: 0.010  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:50 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 2560  total_loss: 0.081  loss_cls: 0.010  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:56 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2580  total_loss: 0.105  loss_cls: 0.014  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:29:56 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2580  total_loss: 0.105  loss_cls: 0.014  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:02 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 2600  total_loss: 0.072  loss_cls: 0.011  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:02 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 2600  total_loss: 0.072  loss_cls: 0.011  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:08 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 2620  total_loss: 0.092  loss_cls: 0.017  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:08 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 2620  total_loss: 0.092  loss_cls: 0.017  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:14 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 2640  total_loss: 0.100  loss_cls: 0.020  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:14 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 2640  total_loss: 0.100  loss_cls: 0.020  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:20 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 2660  total_loss: 0.079  loss_cls: 0.015  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:20 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 2660  total_loss: 0.079  loss_cls: 0.015  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:26 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2680  total_loss: 0.108  loss_cls: 0.025  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:26 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2680  total_loss: 0.108  loss_cls: 0.025  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:32 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2700  total_loss: 0.088  loss_cls: 0.021  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:32 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2700  total_loss: 0.088  loss_cls: 0.021  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:38 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 2720  total_loss: 0.106  loss_cls: 0.026  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:38 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 2720  total_loss: 0.106  loss_cls: 0.026  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:44 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2740  total_loss: 0.083  loss_cls: 0.016  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:44 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2740  total_loss: 0.083  loss_cls: 0.016  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:50 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 2760  total_loss: 0.105  loss_cls: 0.027  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:50 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 2760  total_loss: 0.105  loss_cls: 0.027  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:56 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 2780  total_loss: 0.116  loss_cls: 0.020  loss_box_reg: 0.087  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:30:56 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 2780  total_loss: 0.116  loss_cls: 0.020  loss_box_reg: 0.087  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:02 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 2800  total_loss: 0.074  loss_cls: 0.013  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:02 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 2800  total_loss: 0.074  loss_cls: 0.013  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:08 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2820  total_loss: 0.073  loss_cls: 0.014  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:08 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2820  total_loss: 0.073  loss_cls: 0.014  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:14 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 2840  total_loss: 0.075  loss_cls: 0.012  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:14 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 2840  total_loss: 0.075  loss_cls: 0.012  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:20 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 2860  total_loss: 0.083  loss_cls: 0.018  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:20 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 2860  total_loss: 0.083  loss_cls: 0.018  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:26 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 2880  total_loss: 0.072  loss_cls: 0.011  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:26 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 2880  total_loss: 0.072  loss_cls: 0.011  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:32 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2900  total_loss: 0.080  loss_cls: 0.017  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:32 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2900  total_loss: 0.080  loss_cls: 0.017  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:38 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2920  total_loss: 0.094  loss_cls: 0.015  loss_box_reg: 0.077  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:38 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 2920  total_loss: 0.094  loss_cls: 0.015  loss_box_reg: 0.077  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:45 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 2940  total_loss: 0.093  loss_cls: 0.023  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:45 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 2940  total_loss: 0.093  loss_cls: 0.023  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:51 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.088  loss_cls: 0.027  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:51 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.088  loss_cls: 0.027  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:56 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2980  total_loss: 0.115  loss_cls: 0.018  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:31:56 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2980  total_loss: 0.115  loss_cls: 0.018  loss_box_reg: 0.072  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:02 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 21:32:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.095  loss_cls: 0.019  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.095  loss_cls: 0.019  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:05 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 21:32:08 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:32:08 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:32:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 21:32:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 21:32:08 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 21:32:08 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:32:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 21:32:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 21:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1792 s / img. ETA=0:00:04\n",
      "\u001b[32m[08/23 21:32:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1792 s / img. ETA=0:00:04\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.650321 (0.188344 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.650321 (0.188344 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.185847 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.185847 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.911\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.613\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.571\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.613\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.713\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.713\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 57.076 | 91.093 | 61.335 |  nan  |  nan  | 57.076 |\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 57.076 | 91.093 | 61.335 |  nan  |  nan  | 57.076 |\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 76.122 | Coffeemaker | 51.478 | Tree house | 43.627 |\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 76.122 | Coffeemaker | 51.478 | Tree house | 43.627 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: 57.0757,91.0926,61.3348,nan,nan,57.0757\n",
      "\u001b[32m[08/23 21:32:15 d2.evaluation.testing]: \u001b[0mcopypaste: 57.0757,91.0926,61.3348,nan,nan,57.0757\n",
      "### Saving results to Weights & Biases...\n",
      ">>>>>>>>>>>>> Running experiment: 5\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 21:32:15 fvcore.common.config]: \u001b[0mLoading config /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RetinaNet.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RetinaNet.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: RetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: RetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 21:32:15 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/1nkw42ht\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/1nkw42ht</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:32:18 detectron2]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:32:18 detectron2]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd3841d160>\n",
      "\u001b[32m[08/23 21:32:18 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl\n",
      "\u001b[32m[08/23 21:32:18 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl\n",
      "\u001b[32m[08/23 21:32:19 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[32m[08/23 21:32:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 21:32:19 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 21:32:19 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:32:19 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:32:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 21:32:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 21:32:19 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 21:32:19 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 21:32:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 21:32:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 21:32:19 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 21:32:19 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 21:32:25 d2.utils.events]: \u001b[0m iter: 20  total_loss: 0.998  loss_cls: 0.855  loss_box_reg: 0.149  lr: 0.000005  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:25 d2.utils.events]: \u001b[0m iter: 20  total_loss: 0.998  loss_cls: 0.855  loss_box_reg: 0.149  lr: 0.000005  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:31 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 40  total_loss: 1.884  loss_cls: 1.716  loss_box_reg: 0.278  lr: 0.000010  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:31 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 40  total_loss: 1.884  loss_cls: 1.716  loss_box_reg: 0.278  lr: 0.000010  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:36 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 60  total_loss: 1.153  loss_cls: 0.845  loss_box_reg: 0.301  lr: 0.000015  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:36 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 60  total_loss: 1.153  loss_cls: 0.845  loss_box_reg: 0.301  lr: 0.000015  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:42 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 80  total_loss: 0.899  loss_cls: 0.715  loss_box_reg: 0.232  lr: 0.000020  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:42 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 80  total_loss: 0.899  loss_cls: 0.715  loss_box_reg: 0.232  lr: 0.000020  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:48 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 100  total_loss: 1.004  loss_cls: 0.787  loss_box_reg: 0.195  lr: 0.000025  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:48 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 100  total_loss: 1.004  loss_cls: 0.787  loss_box_reg: 0.195  lr: 0.000025  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:54 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 120  total_loss: 0.707  loss_cls: 0.415  loss_box_reg: 0.308  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:32:54 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 120  total_loss: 0.707  loss_cls: 0.415  loss_box_reg: 0.308  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:00 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 140  total_loss: 0.643  loss_cls: 0.400  loss_box_reg: 0.213  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:00 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 140  total_loss: 0.643  loss_cls: 0.400  loss_box_reg: 0.213  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:06 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 160  total_loss: 0.488  loss_cls: 0.241  loss_box_reg: 0.259  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:06 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 160  total_loss: 0.488  loss_cls: 0.241  loss_box_reg: 0.259  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:12 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 180  total_loss: 0.682  loss_cls: 0.381  loss_box_reg: 0.286  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:12 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 180  total_loss: 0.682  loss_cls: 0.381  loss_box_reg: 0.286  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:18 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 200  total_loss: 0.594  loss_cls: 0.246  loss_box_reg: 0.222  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:18 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 200  total_loss: 0.594  loss_cls: 0.246  loss_box_reg: 0.222  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:25 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 220  total_loss: 0.504  loss_cls: 0.271  loss_box_reg: 0.187  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:25 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 220  total_loss: 0.504  loss_cls: 0.271  loss_box_reg: 0.187  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:31 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 240  total_loss: 0.421  loss_cls: 0.165  loss_box_reg: 0.216  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:31 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 240  total_loss: 0.421  loss_cls: 0.165  loss_box_reg: 0.216  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:37 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 260  total_loss: 0.475  loss_cls: 0.223  loss_box_reg: 0.206  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:37 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 260  total_loss: 0.475  loss_cls: 0.223  loss_box_reg: 0.206  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:42 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 280  total_loss: 0.429  loss_cls: 0.192  loss_box_reg: 0.211  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:42 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 280  total_loss: 0.429  loss_cls: 0.192  loss_box_reg: 0.211  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:48 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 300  total_loss: 0.528  loss_cls: 0.195  loss_box_reg: 0.185  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:48 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 300  total_loss: 0.528  loss_cls: 0.195  loss_box_reg: 0.185  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:54 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 320  total_loss: 0.324  loss_cls: 0.154  loss_box_reg: 0.153  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:54 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 320  total_loss: 0.324  loss_cls: 0.154  loss_box_reg: 0.153  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:59 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 340  total_loss: 0.290  loss_cls: 0.107  loss_box_reg: 0.154  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:33:59 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 340  total_loss: 0.290  loss_cls: 0.107  loss_box_reg: 0.154  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:06 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 360  total_loss: 0.310  loss_cls: 0.167  loss_box_reg: 0.123  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:06 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 360  total_loss: 0.310  loss_cls: 0.167  loss_box_reg: 0.123  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:12 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 380  total_loss: 0.279  loss_cls: 0.133  loss_box_reg: 0.169  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:12 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 380  total_loss: 0.279  loss_cls: 0.133  loss_box_reg: 0.169  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:18 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 400  total_loss: 0.202  loss_cls: 0.099  loss_box_reg: 0.094  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:18 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 400  total_loss: 0.202  loss_cls: 0.099  loss_box_reg: 0.094  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:24 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 420  total_loss: 0.214  loss_cls: 0.081  loss_box_reg: 0.127  lr: 0.000105  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:34:24 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 420  total_loss: 0.214  loss_cls: 0.081  loss_box_reg: 0.127  lr: 0.000105  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:30 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 440  total_loss: 0.339  loss_cls: 0.151  loss_box_reg: 0.239  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:30 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 440  total_loss: 0.339  loss_cls: 0.151  loss_box_reg: 0.239  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:35 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 460  total_loss: 0.367  loss_cls: 0.123  loss_box_reg: 0.215  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:35 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 460  total_loss: 0.367  loss_cls: 0.123  loss_box_reg: 0.215  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:41 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 480  total_loss: 0.283  loss_cls: 0.127  loss_box_reg: 0.165  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:41 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 480  total_loss: 0.283  loss_cls: 0.127  loss_box_reg: 0.165  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:47 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 500  total_loss: 0.384  loss_cls: 0.180  loss_box_reg: 0.196  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:47 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 500  total_loss: 0.384  loss_cls: 0.180  loss_box_reg: 0.196  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:52 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 520  total_loss: 0.188  loss_cls: 0.082  loss_box_reg: 0.074  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:52 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 520  total_loss: 0.188  loss_cls: 0.082  loss_box_reg: 0.074  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:58 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 540  total_loss: 0.386  loss_cls: 0.161  loss_box_reg: 0.233  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:34:58 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 540  total_loss: 0.386  loss_cls: 0.161  loss_box_reg: 0.233  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:04 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 560  total_loss: 0.184  loss_cls: 0.064  loss_box_reg: 0.115  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:04 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 560  total_loss: 0.184  loss_cls: 0.064  loss_box_reg: 0.115  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:10 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 580  total_loss: 0.257  loss_cls: 0.098  loss_box_reg: 0.164  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:10 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 580  total_loss: 0.257  loss_cls: 0.098  loss_box_reg: 0.164  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:16 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 600  total_loss: 0.160  loss_cls: 0.052  loss_box_reg: 0.108  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:16 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 600  total_loss: 0.160  loss_cls: 0.052  loss_box_reg: 0.108  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:22 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 620  total_loss: 0.195  loss_cls: 0.071  loss_box_reg: 0.111  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:22 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 620  total_loss: 0.195  loss_cls: 0.071  loss_box_reg: 0.111  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:28 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 640  total_loss: 0.244  loss_cls: 0.102  loss_box_reg: 0.126  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:28 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 640  total_loss: 0.244  loss_cls: 0.102  loss_box_reg: 0.126  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:33 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 660  total_loss: 0.300  loss_cls: 0.117  loss_box_reg: 0.174  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:33 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 660  total_loss: 0.300  loss_cls: 0.117  loss_box_reg: 0.174  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:39 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 680  total_loss: 0.210  loss_cls: 0.092  loss_box_reg: 0.114  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:39 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 680  total_loss: 0.210  loss_cls: 0.092  loss_box_reg: 0.114  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:46 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 700  total_loss: 0.249  loss_cls: 0.072  loss_box_reg: 0.111  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:46 d2.utils.events]: \u001b[0m eta: 0:12:17  iter: 700  total_loss: 0.249  loss_cls: 0.072  loss_box_reg: 0.111  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:52 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 720  total_loss: 0.243  loss_cls: 0.117  loss_box_reg: 0.130  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:52 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 720  total_loss: 0.243  loss_cls: 0.117  loss_box_reg: 0.130  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:58 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 740  total_loss: 0.214  loss_cls: 0.078  loss_box_reg: 0.131  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:35:58 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 740  total_loss: 0.214  loss_cls: 0.078  loss_box_reg: 0.131  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:04 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 760  total_loss: 0.217  loss_cls: 0.077  loss_box_reg: 0.103  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:04 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 760  total_loss: 0.217  loss_cls: 0.077  loss_box_reg: 0.103  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:10 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 780  total_loss: 0.159  loss_cls: 0.055  loss_box_reg: 0.100  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:10 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 780  total_loss: 0.159  loss_cls: 0.055  loss_box_reg: 0.100  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:15 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 800  total_loss: 0.176  loss_cls: 0.052  loss_box_reg: 0.080  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:15 d2.utils.events]: \u001b[0m eta: 0:10:15  iter: 800  total_loss: 0.176  loss_cls: 0.052  loss_box_reg: 0.080  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:21 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 820  total_loss: 0.171  loss_cls: 0.053  loss_box_reg: 0.100  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:21 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 820  total_loss: 0.171  loss_cls: 0.053  loss_box_reg: 0.100  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:27 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 840  total_loss: 0.195  loss_cls: 0.049  loss_box_reg: 0.100  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:27 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 840  total_loss: 0.195  loss_cls: 0.049  loss_box_reg: 0.100  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:33 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 860  total_loss: 0.295  loss_cls: 0.106  loss_box_reg: 0.154  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:33 d2.utils.events]: \u001b[0m eta: 0:10:26  iter: 860  total_loss: 0.295  loss_cls: 0.106  loss_box_reg: 0.154  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:39 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 880  total_loss: 0.137  loss_cls: 0.031  loss_box_reg: 0.095  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:39 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 880  total_loss: 0.137  loss_cls: 0.031  loss_box_reg: 0.095  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:44 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 900  total_loss: 0.154  loss_cls: 0.068  loss_box_reg: 0.092  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:44 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 900  total_loss: 0.154  loss_cls: 0.068  loss_box_reg: 0.092  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:50 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 920  total_loss: 0.241  loss_cls: 0.046  loss_box_reg: 0.123  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:50 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 920  total_loss: 0.241  loss_cls: 0.046  loss_box_reg: 0.123  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:56 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 940  total_loss: 0.155  loss_cls: 0.057  loss_box_reg: 0.116  lr: 0.000235  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:36:56 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 940  total_loss: 0.155  loss_cls: 0.057  loss_box_reg: 0.116  lr: 0.000235  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:37:02 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 960  total_loss: 0.166  loss_cls: 0.078  loss_box_reg: 0.086  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:02 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 960  total_loss: 0.166  loss_cls: 0.078  loss_box_reg: 0.086  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:08 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 980  total_loss: 0.127  loss_cls: 0.044  loss_box_reg: 0.076  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:08 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 980  total_loss: 0.127  loss_cls: 0.044  loss_box_reg: 0.076  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:14 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 1000  total_loss: 0.283  loss_cls: 0.059  loss_box_reg: 0.175  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:14 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 1000  total_loss: 0.283  loss_cls: 0.059  loss_box_reg: 0.175  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:21 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1020  total_loss: 0.200  loss_cls: 0.047  loss_box_reg: 0.138  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:21 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 1020  total_loss: 0.200  loss_cls: 0.047  loss_box_reg: 0.138  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:29 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 1040  total_loss: 0.118  loss_cls: 0.030  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:29 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 1040  total_loss: 0.118  loss_cls: 0.030  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:35 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 1060  total_loss: 0.121  loss_cls: 0.033  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:35 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 1060  total_loss: 0.121  loss_cls: 0.033  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:40 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1080  total_loss: 0.179  loss_cls: 0.055  loss_box_reg: 0.102  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:40 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1080  total_loss: 0.179  loss_cls: 0.055  loss_box_reg: 0.102  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:46 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 1100  total_loss: 0.131  loss_cls: 0.041  loss_box_reg: 0.100  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:46 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 1100  total_loss: 0.131  loss_cls: 0.041  loss_box_reg: 0.100  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:52 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1120  total_loss: 0.162  loss_cls: 0.042  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:37:52 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1120  total_loss: 0.162  loss_cls: 0.042  loss_box_reg: 0.104  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:03 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 1140  total_loss: 0.120  loss_cls: 0.031  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:03 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 1140  total_loss: 0.120  loss_cls: 0.031  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:09 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 1160  total_loss: 0.173  loss_cls: 0.053  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:09 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 1160  total_loss: 0.173  loss_cls: 0.053  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:15 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 1180  total_loss: 0.157  loss_cls: 0.066  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:15 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 1180  total_loss: 0.157  loss_cls: 0.066  loss_box_reg: 0.109  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:21 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 1200  total_loss: 0.143  loss_cls: 0.050  loss_box_reg: 0.100  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:21 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 1200  total_loss: 0.143  loss_cls: 0.050  loss_box_reg: 0.100  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:26 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 1220  total_loss: 0.155  loss_cls: 0.041  loss_box_reg: 0.112  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:26 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 1220  total_loss: 0.155  loss_cls: 0.041  loss_box_reg: 0.112  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:32 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 1240  total_loss: 0.146  loss_cls: 0.035  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:32 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 1240  total_loss: 0.146  loss_cls: 0.035  loss_box_reg: 0.083  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:37 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 1260  total_loss: 0.152  loss_cls: 0.071  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:37 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 1260  total_loss: 0.152  loss_cls: 0.071  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:43 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1280  total_loss: 0.135  loss_cls: 0.040  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:43 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1280  total_loss: 0.135  loss_cls: 0.040  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:50 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 1300  total_loss: 0.129  loss_cls: 0.035  loss_box_reg: 0.092  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:50 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 1300  total_loss: 0.129  loss_cls: 0.035  loss_box_reg: 0.092  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:56 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1320  total_loss: 0.093  loss_cls: 0.022  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:38:56 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 1320  total_loss: 0.093  loss_cls: 0.022  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:02 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 1340  total_loss: 0.120  loss_cls: 0.034  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:02 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 1340  total_loss: 0.120  loss_cls: 0.034  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:08 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1360  total_loss: 0.105  loss_cls: 0.022  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:08 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 1360  total_loss: 0.105  loss_cls: 0.022  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:13 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1380  total_loss: 0.129  loss_cls: 0.053  loss_box_reg: 0.095  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:13 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 1380  total_loss: 0.129  loss_cls: 0.053  loss_box_reg: 0.095  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:20 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 1400  total_loss: 0.137  loss_cls: 0.031  loss_box_reg: 0.094  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:20 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 1400  total_loss: 0.137  loss_cls: 0.031  loss_box_reg: 0.094  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:26 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1420  total_loss: 0.087  loss_cls: 0.017  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:26 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 1420  total_loss: 0.087  loss_cls: 0.017  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:32 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 1440  total_loss: 0.105  loss_cls: 0.022  loss_box_reg: 0.088  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:32 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 1440  total_loss: 0.105  loss_cls: 0.022  loss_box_reg: 0.088  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:38 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 1460  total_loss: 0.138  loss_cls: 0.027  loss_box_reg: 0.098  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:38 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 1460  total_loss: 0.138  loss_cls: 0.027  loss_box_reg: 0.098  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:43 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 1480  total_loss: 0.097  loss_cls: 0.024  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:39:43 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 1480  total_loss: 0.097  loss_cls: 0.024  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:49 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 1500  total_loss: 0.129  loss_cls: 0.037  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:49 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 1500  total_loss: 0.129  loss_cls: 0.037  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:56 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 1520  total_loss: 0.092  loss_cls: 0.023  loss_box_reg: 0.077  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:39:56 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 1520  total_loss: 0.092  loss_cls: 0.023  loss_box_reg: 0.077  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:02 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1540  total_loss: 0.078  loss_cls: 0.018  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:02 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1540  total_loss: 0.078  loss_cls: 0.018  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:07 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1560  total_loss: 0.071  loss_cls: 0.019  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:07 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1560  total_loss: 0.071  loss_cls: 0.019  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:14 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1580  total_loss: 0.101  loss_cls: 0.024  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:14 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1580  total_loss: 0.101  loss_cls: 0.024  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:19 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1600  total_loss: 0.109  loss_cls: 0.022  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:19 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 1600  total_loss: 0.109  loss_cls: 0.022  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:26 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1620  total_loss: 0.081  loss_cls: 0.013  loss_box_reg: 0.070  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:26 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1620  total_loss: 0.081  loss_cls: 0.013  loss_box_reg: 0.070  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:31 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1640  total_loss: 0.146  loss_cls: 0.033  loss_box_reg: 0.111  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:31 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1640  total_loss: 0.146  loss_cls: 0.033  loss_box_reg: 0.111  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:37 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 1660  total_loss: 0.096  loss_cls: 0.018  loss_box_reg: 0.077  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:37 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 1660  total_loss: 0.096  loss_cls: 0.018  loss_box_reg: 0.077  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:43 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1680  total_loss: 0.097  loss_cls: 0.018  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:43 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1680  total_loss: 0.097  loss_cls: 0.018  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:49 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1700  total_loss: 0.097  loss_cls: 0.018  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:49 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1700  total_loss: 0.097  loss_cls: 0.018  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:55 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 1720  total_loss: 0.101  loss_cls: 0.018  loss_box_reg: 0.085  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:40:55 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 1720  total_loss: 0.101  loss_cls: 0.018  loss_box_reg: 0.085  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:02 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 1740  total_loss: 0.093  loss_cls: 0.015  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:02 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 1740  total_loss: 0.093  loss_cls: 0.015  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:08 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1760  total_loss: 0.123  loss_cls: 0.032  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:08 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1760  total_loss: 0.123  loss_cls: 0.032  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:15 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1780  total_loss: 0.066  loss_cls: 0.012  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:15 d2.utils.events]: \u001b[0m eta: 0:07:44  iter: 1780  total_loss: 0.066  loss_cls: 0.012  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:25 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1800  total_loss: 0.062  loss_cls: 0.008  loss_box_reg: 0.043  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:25 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1800  total_loss: 0.062  loss_cls: 0.008  loss_box_reg: 0.043  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:31 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1820  total_loss: 0.096  loss_cls: 0.010  loss_box_reg: 0.070  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:31 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 1820  total_loss: 0.096  loss_cls: 0.010  loss_box_reg: 0.070  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:37 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1840  total_loss: 0.090  loss_cls: 0.012  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:37 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1840  total_loss: 0.090  loss_cls: 0.012  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:43 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 1860  total_loss: 0.058  loss_cls: 0.012  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:43 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 1860  total_loss: 0.058  loss_cls: 0.012  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:48 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 1880  total_loss: 0.087  loss_cls: 0.010  loss_box_reg: 0.074  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:48 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 1880  total_loss: 0.087  loss_cls: 0.010  loss_box_reg: 0.074  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:55 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 1900  total_loss: 0.085  loss_cls: 0.010  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:41:55 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 1900  total_loss: 0.085  loss_cls: 0.010  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:00 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 1920  total_loss: 0.100  loss_cls: 0.014  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:00 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 1920  total_loss: 0.100  loss_cls: 0.014  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:06 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1940  total_loss: 0.088  loss_cls: 0.012  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:06 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 1940  total_loss: 0.088  loss_cls: 0.012  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:12 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 1960  total_loss: 0.094  loss_cls: 0.007  loss_box_reg: 0.079  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:12 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 1960  total_loss: 0.094  loss_cls: 0.007  loss_box_reg: 0.079  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:17 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 1980  total_loss: 0.061  loss_cls: 0.012  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:17 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 1980  total_loss: 0.061  loss_cls: 0.012  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:23 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 2000  total_loss: 0.064  loss_cls: 0.006  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:23 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 2000  total_loss: 0.064  loss_cls: 0.006  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:42:29 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 2020  total_loss: 0.072  loss_cls: 0.013  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:29 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 2020  total_loss: 0.072  loss_cls: 0.013  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:35 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 2040  total_loss: 0.062  loss_cls: 0.012  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:35 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 2040  total_loss: 0.062  loss_cls: 0.012  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:42 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 2060  total_loss: 0.078  loss_cls: 0.017  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:42 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 2060  total_loss: 0.078  loss_cls: 0.017  loss_box_reg: 0.066  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:47 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 2080  total_loss: 0.046  loss_cls: 0.010  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:47 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 2080  total_loss: 0.046  loss_cls: 0.010  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:53 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 2100  total_loss: 0.058  loss_cls: 0.008  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:53 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 2100  total_loss: 0.058  loss_cls: 0.008  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:59 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 2120  total_loss: 0.084  loss_cls: 0.015  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:42:59 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 2120  total_loss: 0.084  loss_cls: 0.015  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:05 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 2140  total_loss: 0.080  loss_cls: 0.009  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:05 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 2140  total_loss: 0.080  loss_cls: 0.009  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:11 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 2160  total_loss: 0.080  loss_cls: 0.007  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:11 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 2160  total_loss: 0.080  loss_cls: 0.007  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:17 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2180  total_loss: 0.069  loss_cls: 0.006  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:17 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2180  total_loss: 0.069  loss_cls: 0.006  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:23 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 2200  total_loss: 0.075  loss_cls: 0.012  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:23 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 2200  total_loss: 0.075  loss_cls: 0.012  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:29 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 2220  total_loss: 0.104  loss_cls: 0.014  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:29 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 2220  total_loss: 0.104  loss_cls: 0.014  loss_box_reg: 0.084  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:34 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 2240  total_loss: 0.074  loss_cls: 0.007  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:34 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 2240  total_loss: 0.074  loss_cls: 0.007  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:40 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 2260  total_loss: 0.067  loss_cls: 0.007  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:40 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 2260  total_loss: 0.067  loss_cls: 0.007  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:46 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 2280  total_loss: 0.078  loss_cls: 0.005  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:46 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 2280  total_loss: 0.078  loss_cls: 0.005  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:52 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 2300  total_loss: 0.073  loss_cls: 0.009  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:52 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 2300  total_loss: 0.073  loss_cls: 0.009  loss_box_reg: 0.067  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:58 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 2320  total_loss: 0.085  loss_cls: 0.006  loss_box_reg: 0.075  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:43:58 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 2320  total_loss: 0.085  loss_cls: 0.006  loss_box_reg: 0.075  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:04 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2340  total_loss: 0.056  loss_cls: 0.007  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:04 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2340  total_loss: 0.056  loss_cls: 0.007  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:10 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2360  total_loss: 0.056  loss_cls: 0.004  loss_box_reg: 0.053  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:10 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2360  total_loss: 0.056  loss_cls: 0.004  loss_box_reg: 0.053  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:16 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 2380  total_loss: 0.045  loss_cls: 0.004  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:16 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 2380  total_loss: 0.045  loss_cls: 0.004  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:21 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2400  total_loss: 0.073  loss_cls: 0.009  loss_box_reg: 0.061  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:21 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2400  total_loss: 0.073  loss_cls: 0.009  loss_box_reg: 0.061  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:27 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2420  total_loss: 0.079  loss_cls: 0.010  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:27 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2420  total_loss: 0.079  loss_cls: 0.010  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:33 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 2440  total_loss: 0.069  loss_cls: 0.007  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:33 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 2440  total_loss: 0.069  loss_cls: 0.007  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:39 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 2460  total_loss: 0.071  loss_cls: 0.012  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:39 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 2460  total_loss: 0.071  loss_cls: 0.012  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:45 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 2480  total_loss: 0.070  loss_cls: 0.007  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:45 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 2480  total_loss: 0.070  loss_cls: 0.007  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:51 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2500  total_loss: 0.081  loss_cls: 0.012  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:51 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 2500  total_loss: 0.081  loss_cls: 0.012  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:57 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2520  total_loss: 0.060  loss_cls: 0.008  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:44:57 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 2520  total_loss: 0.060  loss_cls: 0.008  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:03 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 2540  total_loss: 0.055  loss_cls: 0.005  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:45:03 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 2540  total_loss: 0.055  loss_cls: 0.005  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:08 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2560  total_loss: 0.044  loss_cls: 0.003  loss_box_reg: 0.039  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:08 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2560  total_loss: 0.044  loss_cls: 0.003  loss_box_reg: 0.039  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:14 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2580  total_loss: 0.080  loss_cls: 0.008  loss_box_reg: 0.074  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:14 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 2580  total_loss: 0.080  loss_cls: 0.008  loss_box_reg: 0.074  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:20 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2600  total_loss: 0.047  loss_cls: 0.004  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:20 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2600  total_loss: 0.047  loss_cls: 0.004  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:26 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 2620  total_loss: 0.059  loss_cls: 0.006  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:26 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 2620  total_loss: 0.059  loss_cls: 0.006  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:32 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 2640  total_loss: 0.063  loss_cls: 0.007  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:32 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 2640  total_loss: 0.063  loss_cls: 0.007  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:38 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2660  total_loss: 0.048  loss_cls: 0.007  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:38 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 2660  total_loss: 0.048  loss_cls: 0.007  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:43 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2680  total_loss: 0.065  loss_cls: 0.007  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:43 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 2680  total_loss: 0.065  loss_cls: 0.007  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:49 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2700  total_loss: 0.051  loss_cls: 0.004  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:49 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 2700  total_loss: 0.051  loss_cls: 0.004  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:55 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 2720  total_loss: 0.084  loss_cls: 0.010  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:45:55 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 2720  total_loss: 0.084  loss_cls: 0.010  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:01 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 2740  total_loss: 0.074  loss_cls: 0.011  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:01 d2.utils.events]: \u001b[0m eta: 0:01:12  iter: 2740  total_loss: 0.074  loss_cls: 0.011  loss_box_reg: 0.064  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:07 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 2760  total_loss: 0.055  loss_cls: 0.005  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:07 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 2760  total_loss: 0.055  loss_cls: 0.005  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:12 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 2780  total_loss: 0.061  loss_cls: 0.009  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:12 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 2780  total_loss: 0.061  loss_cls: 0.009  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:18 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2800  total_loss: 0.054  loss_cls: 0.004  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:18 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2800  total_loss: 0.054  loss_cls: 0.004  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:25 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2820  total_loss: 0.044  loss_cls: 0.004  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:25 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 2820  total_loss: 0.044  loss_cls: 0.004  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:31 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 2840  total_loss: 0.063  loss_cls: 0.004  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:31 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 2840  total_loss: 0.063  loss_cls: 0.004  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:37 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 2860  total_loss: 0.065  loss_cls: 0.006  loss_box_reg: 0.059  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:37 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 2860  total_loss: 0.065  loss_cls: 0.006  loss_box_reg: 0.059  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:43 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 2880  total_loss: 0.041  loss_cls: 0.003  loss_box_reg: 0.038  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:43 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 2880  total_loss: 0.041  loss_cls: 0.003  loss_box_reg: 0.038  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:49 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2900  total_loss: 0.056  loss_cls: 0.004  loss_box_reg: 0.043  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:49 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 2900  total_loss: 0.056  loss_cls: 0.004  loss_box_reg: 0.043  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:55 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 2920  total_loss: 0.066  loss_cls: 0.006  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:46:55 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 2920  total_loss: 0.066  loss_cls: 0.006  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:01 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 2940  total_loss: 0.060  loss_cls: 0.008  loss_box_reg: 0.048  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:01 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 2940  total_loss: 0.060  loss_cls: 0.008  loss_box_reg: 0.048  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:07 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.064  loss_cls: 0.006  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:07 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2960  total_loss: 0.064  loss_cls: 0.006  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:12 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2980  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:12 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 2980  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:18 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 21:47:21 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.064  loss_cls: 0.004  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:21 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.064  loss_cls: 0.004  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:21 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 21:47:24 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:47:24 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:47:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 21:47:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 21:47:24 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 21:47:24 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:47:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 21:47:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 21:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1794 s / img. ETA=0:00:04\n",
      "\u001b[32m[08/23 21:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.1794 s / img. ETA=0:00:04\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.669983 (0.188999 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.669983 (0.188999 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.186307 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.186307 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.956\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.670\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.622\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.695\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.744\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.744\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 62.170 | 95.607 | 67.018 |  nan  |  nan  | 62.170 |\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 62.170 | 95.607 | 67.018 |  nan  |  nan  | 62.170 |\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 75.276 | Coffeemaker | 60.542 | Tree house | 50.693 |\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 75.276 | Coffeemaker | 60.542 | Tree house | 50.693 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 21:47:30 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 21:47:30 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: 62.1702,95.6073,67.0176,nan,nan,62.1702\n",
      "\u001b[32m[08/23 21:47:30 d2.evaluation.testing]: \u001b[0mcopypaste: 62.1702,95.6073,67.0176,nan,nan,62.1702\n",
      "### Saving results to Weights & Biases...\n",
      ">>>>>>>>>>>>> Running experiment: 6\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[08/23 21:47:31 fvcore.common.config]: \u001b[0mLoading config /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.8.3 | packaged by conda-forge | (default, Jun  1 2020, 17:43:00) [GCC 7.5.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.0\n",
      "detectron2 arch flags   /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.4.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   GeForce GTX 1660\n",
      "CUDA_HOME               None\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.5.0+cu100 @/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision\n",
      "torchvision arch flags  /home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/torchvision/_C.so\n",
      "fvcore                  0.1.1.post20200716\n",
      "cv2                     4.4.0\n",
      "----------------------  -------------------------------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl', 'DATASETS.TRAIN', \"('train/cmaker-bathtub-treehouse-train',)\", 'DATASETS.TEST', \"('validation/cmaker-bathtub-treehouse-validation',)\", 'DATALOADER.NUM_WORKERS', '2', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.BASE_LR', '0.00025', 'SOLVER.MAX_ITER', '3000', 'SEED', '33', 'MODEL.ROI_HEADS.NUM_CLASSES', '3'], resume=False)\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RetinaNet.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-101.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mContents of args.config_file=/home/santhosh/miniconda3/envs/airnb/lib/python3.8/site-packages/detectron2/model_zoo/configs/COCO-Detection/retinanet_R_101_FPN_3x.yaml:\n",
      "_BASE_: \"../Base-RetinaNet.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-101.pkl\"\n",
      "  RESNETS:\n",
      "    DEPTH: 101\n",
      "SOLVER:\n",
      "  STEPS: (210000, 250000)\n",
      "  MAX_ITER: 270000\n",
      "\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: RetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('validation/cmaker-bathtub-treehouse-validation',)\n",
      "  TRAIN: ('train/cmaker-bathtub-treehouse-train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_retinanet_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: RetinaNet\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.0\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: \n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: Res5ROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 3\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['res4']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 2000\n",
      "    PRE_NMS_TOPK_TEST: 6000\n",
      "    PRE_NMS_TOPK_TRAIN: 12000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 33\n",
      "SOLVER:\n",
      "  BASE_LR: 0.00025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 1\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 3000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (210000, 250000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
      "\u001b[32m[08/23 21:47:31 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/20b2r8ad\" target=\"_blank\">https://app.wandb.ai/skumarr53/airbnb-object-detection/runs/20b2r8ad</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:47:34 detectron2]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:47:34 detectron2]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: <detectron2.solver.lr_scheduler.WarmupMultiStepLR object at 0x7fbd38349d90>\n",
      "\u001b[32m[08/23 21:47:34 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl\n",
      "\u001b[32m[08/23 21:47:34 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl cached in /home/santhosh/.torch/fvcore_cache/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl\n",
      "\u001b[32m[08/23 21:47:34 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[32m[08/23 21:47:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 21:47:34 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 252 images left.\n",
      "\u001b[32m[08/23 21:47:34 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:47:34 d2.data.common]: \u001b[0mSerializing 252 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 21:47:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 21:47:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[08/23 21:47:34 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 21:47:34 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[08/23 21:47:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 21:47:34 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[08/23 21:47:34 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 21:47:34 detectron2]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[08/23 21:47:43 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.121  loss_cls: 0.891  loss_box_reg: 0.158  lr: 0.000005  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:43 d2.utils.events]: \u001b[0m iter: 20  total_loss: 1.121  loss_cls: 0.891  loss_box_reg: 0.158  lr: 0.000005  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:51 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 40  total_loss: 2.021  loss_cls: 1.849  loss_box_reg: 0.253  lr: 0.000010  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:51 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 40  total_loss: 2.021  loss_cls: 1.849  loss_box_reg: 0.253  lr: 0.000010  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:59 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 60  total_loss: 1.230  loss_cls: 1.026  loss_box_reg: 0.304  lr: 0.000015  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:47:59 d2.utils.events]: \u001b[0m eta: 0:19:39  iter: 60  total_loss: 1.230  loss_cls: 1.026  loss_box_reg: 0.304  lr: 0.000015  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:07 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 80  total_loss: 0.920  loss_cls: 0.681  loss_box_reg: 0.237  lr: 0.000020  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:07 d2.utils.events]: \u001b[0m eta: 0:19:37  iter: 80  total_loss: 0.920  loss_cls: 0.681  loss_box_reg: 0.237  lr: 0.000020  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:14 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 100  total_loss: 1.021  loss_cls: 0.870  loss_box_reg: 0.157  lr: 0.000025  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:14 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 100  total_loss: 1.021  loss_cls: 0.870  loss_box_reg: 0.157  lr: 0.000025  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:22 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 120  total_loss: 0.693  loss_cls: 0.517  loss_box_reg: 0.246  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:22 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 120  total_loss: 0.693  loss_cls: 0.517  loss_box_reg: 0.246  lr: 0.000030  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:31 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 140  total_loss: 0.652  loss_cls: 0.360  loss_box_reg: 0.322  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:31 d2.utils.events]: \u001b[0m eta: 0:20:01  iter: 140  total_loss: 0.652  loss_cls: 0.360  loss_box_reg: 0.322  lr: 0.000035  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:39 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 160  total_loss: 0.424  loss_cls: 0.229  loss_box_reg: 0.187  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:39 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 160  total_loss: 0.424  loss_cls: 0.229  loss_box_reg: 0.187  lr: 0.000040  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:47 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 180  total_loss: 0.624  loss_cls: 0.346  loss_box_reg: 0.275  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:47 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 180  total_loss: 0.624  loss_cls: 0.346  loss_box_reg: 0.275  lr: 0.000045  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:55 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 200  total_loss: 0.509  loss_cls: 0.260  loss_box_reg: 0.252  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:48:55 d2.utils.events]: \u001b[0m eta: 0:18:11  iter: 200  total_loss: 0.509  loss_cls: 0.260  loss_box_reg: 0.252  lr: 0.000050  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:03 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 220  total_loss: 0.390  loss_cls: 0.248  loss_box_reg: 0.166  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:03 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 220  total_loss: 0.390  loss_cls: 0.248  loss_box_reg: 0.166  lr: 0.000055  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:10 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 240  total_loss: 0.383  loss_cls: 0.176  loss_box_reg: 0.188  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:10 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 240  total_loss: 0.383  loss_cls: 0.176  loss_box_reg: 0.188  lr: 0.000060  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:18 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 260  total_loss: 0.395  loss_cls: 0.189  loss_box_reg: 0.193  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:18 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 260  total_loss: 0.395  loss_cls: 0.189  loss_box_reg: 0.193  lr: 0.000065  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:27 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 280  total_loss: 0.453  loss_cls: 0.197  loss_box_reg: 0.237  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:27 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 280  total_loss: 0.453  loss_cls: 0.197  loss_box_reg: 0.237  lr: 0.000070  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:34 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 300  total_loss: 0.493  loss_cls: 0.207  loss_box_reg: 0.272  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:34 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 300  total_loss: 0.493  loss_cls: 0.207  loss_box_reg: 0.272  lr: 0.000075  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:42 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 320  total_loss: 0.347  loss_cls: 0.157  loss_box_reg: 0.161  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:42 d2.utils.events]: \u001b[0m eta: 0:18:10  iter: 320  total_loss: 0.347  loss_cls: 0.157  loss_box_reg: 0.161  lr: 0.000080  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:50 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 340  total_loss: 0.264  loss_cls: 0.108  loss_box_reg: 0.134  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:50 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 340  total_loss: 0.264  loss_cls: 0.108  loss_box_reg: 0.134  lr: 0.000085  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:59 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 360  total_loss: 0.305  loss_cls: 0.185  loss_box_reg: 0.126  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:49:59 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 360  total_loss: 0.305  loss_cls: 0.185  loss_box_reg: 0.126  lr: 0.000090  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:06 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 380  total_loss: 0.239  loss_cls: 0.121  loss_box_reg: 0.116  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:06 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 380  total_loss: 0.239  loss_cls: 0.121  loss_box_reg: 0.116  lr: 0.000095  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:14 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 400  total_loss: 0.263  loss_cls: 0.130  loss_box_reg: 0.114  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:14 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 400  total_loss: 0.263  loss_cls: 0.130  loss_box_reg: 0.114  lr: 0.000100  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:24 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 420  total_loss: 0.238  loss_cls: 0.090  loss_box_reg: 0.145  lr: 0.000105  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:50:24 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 420  total_loss: 0.238  loss_cls: 0.090  loss_box_reg: 0.145  lr: 0.000105  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:32 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 440  total_loss: 0.386  loss_cls: 0.174  loss_box_reg: 0.209  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:32 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 440  total_loss: 0.386  loss_cls: 0.174  loss_box_reg: 0.209  lr: 0.000110  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:41 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 460  total_loss: 0.383  loss_cls: 0.107  loss_box_reg: 0.245  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:41 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 460  total_loss: 0.383  loss_cls: 0.107  loss_box_reg: 0.245  lr: 0.000115  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:48 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 480  total_loss: 0.319  loss_cls: 0.114  loss_box_reg: 0.154  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:48 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 480  total_loss: 0.319  loss_cls: 0.114  loss_box_reg: 0.154  lr: 0.000120  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:56 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 500  total_loss: 0.314  loss_cls: 0.170  loss_box_reg: 0.176  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:50:56 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 500  total_loss: 0.314  loss_cls: 0.170  loss_box_reg: 0.176  lr: 0.000125  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:04 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 520  total_loss: 0.123  loss_cls: 0.065  loss_box_reg: 0.060  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:04 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 520  total_loss: 0.123  loss_cls: 0.065  loss_box_reg: 0.060  lr: 0.000130  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:12 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 540  total_loss: 0.346  loss_cls: 0.101  loss_box_reg: 0.223  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:12 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 540  total_loss: 0.346  loss_cls: 0.101  loss_box_reg: 0.223  lr: 0.000135  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:21 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 560  total_loss: 0.159  loss_cls: 0.061  loss_box_reg: 0.080  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:21 d2.utils.events]: \u001b[0m eta: 0:17:24  iter: 560  total_loss: 0.159  loss_cls: 0.061  loss_box_reg: 0.080  lr: 0.000140  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:29 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 580  total_loss: 0.279  loss_cls: 0.096  loss_box_reg: 0.176  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:29 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 580  total_loss: 0.279  loss_cls: 0.096  loss_box_reg: 0.176  lr: 0.000145  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:37 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 600  total_loss: 0.143  loss_cls: 0.050  loss_box_reg: 0.099  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:37 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 600  total_loss: 0.143  loss_cls: 0.050  loss_box_reg: 0.099  lr: 0.000150  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:46 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 620  total_loss: 0.157  loss_cls: 0.052  loss_box_reg: 0.102  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:46 d2.utils.events]: \u001b[0m eta: 0:16:34  iter: 620  total_loss: 0.157  loss_cls: 0.052  loss_box_reg: 0.102  lr: 0.000155  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:55 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 640  total_loss: 0.201  loss_cls: 0.063  loss_box_reg: 0.129  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:51:55 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 640  total_loss: 0.201  loss_cls: 0.063  loss_box_reg: 0.129  lr: 0.000160  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:03 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 660  total_loss: 0.297  loss_cls: 0.115  loss_box_reg: 0.200  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:03 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 660  total_loss: 0.297  loss_cls: 0.115  loss_box_reg: 0.200  lr: 0.000165  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:11 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 680  total_loss: 0.290  loss_cls: 0.127  loss_box_reg: 0.157  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:11 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 680  total_loss: 0.290  loss_cls: 0.127  loss_box_reg: 0.157  lr: 0.000170  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:20 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 700  total_loss: 0.226  loss_cls: 0.085  loss_box_reg: 0.107  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:20 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 700  total_loss: 0.226  loss_cls: 0.085  loss_box_reg: 0.107  lr: 0.000175  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:29 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 720  total_loss: 0.284  loss_cls: 0.129  loss_box_reg: 0.134  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:29 d2.utils.events]: \u001b[0m eta: 0:16:13  iter: 720  total_loss: 0.284  loss_cls: 0.129  loss_box_reg: 0.134  lr: 0.000180  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:38 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 740  total_loss: 0.236  loss_cls: 0.112  loss_box_reg: 0.139  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:38 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 740  total_loss: 0.236  loss_cls: 0.112  loss_box_reg: 0.139  lr: 0.000185  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:46 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 760  total_loss: 0.150  loss_cls: 0.061  loss_box_reg: 0.075  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:46 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 760  total_loss: 0.150  loss_cls: 0.061  loss_box_reg: 0.075  lr: 0.000190  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:56 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 780  total_loss: 0.197  loss_cls: 0.061  loss_box_reg: 0.129  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:52:56 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 780  total_loss: 0.197  loss_cls: 0.061  loss_box_reg: 0.129  lr: 0.000195  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:04 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 800  total_loss: 0.161  loss_cls: 0.050  loss_box_reg: 0.091  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:04 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 800  total_loss: 0.161  loss_cls: 0.050  loss_box_reg: 0.091  lr: 0.000200  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:11 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 820  total_loss: 0.157  loss_cls: 0.045  loss_box_reg: 0.081  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:11 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 820  total_loss: 0.157  loss_cls: 0.045  loss_box_reg: 0.081  lr: 0.000205  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:19 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 840  total_loss: 0.178  loss_cls: 0.046  loss_box_reg: 0.129  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:19 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 840  total_loss: 0.178  loss_cls: 0.046  loss_box_reg: 0.129  lr: 0.000210  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:27 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 860  total_loss: 0.211  loss_cls: 0.085  loss_box_reg: 0.133  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:27 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 860  total_loss: 0.211  loss_cls: 0.085  loss_box_reg: 0.133  lr: 0.000215  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:35 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 880  total_loss: 0.099  loss_cls: 0.037  loss_box_reg: 0.063  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:35 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 880  total_loss: 0.099  loss_cls: 0.037  loss_box_reg: 0.063  lr: 0.000220  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:43 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 900  total_loss: 0.186  loss_cls: 0.063  loss_box_reg: 0.083  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:43 d2.utils.events]: \u001b[0m eta: 0:13:55  iter: 900  total_loss: 0.186  loss_cls: 0.063  loss_box_reg: 0.083  lr: 0.000225  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:51 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 920  total_loss: 0.176  loss_cls: 0.066  loss_box_reg: 0.122  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:51 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 920  total_loss: 0.176  loss_cls: 0.066  loss_box_reg: 0.122  lr: 0.000230  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:59 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 940  total_loss: 0.147  loss_cls: 0.031  loss_box_reg: 0.094  lr: 0.000235  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:53:59 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 940  total_loss: 0.147  loss_cls: 0.031  loss_box_reg: 0.094  lr: 0.000235  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:54:07 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 960  total_loss: 0.151  loss_cls: 0.070  loss_box_reg: 0.060  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:07 d2.utils.events]: \u001b[0m eta: 0:13:43  iter: 960  total_loss: 0.151  loss_cls: 0.070  loss_box_reg: 0.060  lr: 0.000240  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:15 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 980  total_loss: 0.159  loss_cls: 0.056  loss_box_reg: 0.094  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:15 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 980  total_loss: 0.159  loss_cls: 0.056  loss_box_reg: 0.094  lr: 0.000245  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:23 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 1000  total_loss: 0.260  loss_cls: 0.082  loss_box_reg: 0.136  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:23 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 1000  total_loss: 0.260  loss_cls: 0.082  loss_box_reg: 0.136  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:31 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 1020  total_loss: 0.167  loss_cls: 0.040  loss_box_reg: 0.123  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:31 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 1020  total_loss: 0.167  loss_cls: 0.040  loss_box_reg: 0.123  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:40 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 1040  total_loss: 0.128  loss_cls: 0.027  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:40 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 1040  total_loss: 0.128  loss_cls: 0.027  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:48 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1060  total_loss: 0.130  loss_cls: 0.033  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:48 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 1060  total_loss: 0.130  loss_cls: 0.033  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:56 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 1080  total_loss: 0.175  loss_cls: 0.050  loss_box_reg: 0.101  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:54:56 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 1080  total_loss: 0.175  loss_cls: 0.050  loss_box_reg: 0.101  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:04 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 1100  total_loss: 0.114  loss_cls: 0.035  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:04 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 1100  total_loss: 0.114  loss_cls: 0.035  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:13 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 1120  total_loss: 0.135  loss_cls: 0.045  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:13 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 1120  total_loss: 0.135  loss_cls: 0.045  loss_box_reg: 0.097  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:21 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 1140  total_loss: 0.117  loss_cls: 0.040  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:21 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 1140  total_loss: 0.117  loss_cls: 0.040  loss_box_reg: 0.076  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:29 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 1160  total_loss: 0.173  loss_cls: 0.044  loss_box_reg: 0.107  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:29 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 1160  total_loss: 0.173  loss_cls: 0.044  loss_box_reg: 0.107  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:37 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1180  total_loss: 0.106  loss_cls: 0.030  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:37 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1180  total_loss: 0.106  loss_cls: 0.030  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:45 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 1200  total_loss: 0.117  loss_cls: 0.028  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:45 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 1200  total_loss: 0.117  loss_cls: 0.028  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:53 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 1220  total_loss: 0.150  loss_cls: 0.035  loss_box_reg: 0.096  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:55:53 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 1220  total_loss: 0.150  loss_cls: 0.035  loss_box_reg: 0.096  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:02 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 1240  total_loss: 0.103  loss_cls: 0.020  loss_box_reg: 0.075  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:02 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 1240  total_loss: 0.103  loss_cls: 0.020  loss_box_reg: 0.075  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:10 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 1260  total_loss: 0.111  loss_cls: 0.037  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:10 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 1260  total_loss: 0.111  loss_cls: 0.037  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:18 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1280  total_loss: 0.093  loss_cls: 0.013  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:18 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 1280  total_loss: 0.093  loss_cls: 0.013  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:26 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1300  total_loss: 0.109  loss_cls: 0.026  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:26 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1300  total_loss: 0.109  loss_cls: 0.026  loss_box_reg: 0.090  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:34 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 1320  total_loss: 0.063  loss_cls: 0.013  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:34 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 1320  total_loss: 0.063  loss_cls: 0.013  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:42 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 1340  total_loss: 0.115  loss_cls: 0.034  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:42 d2.utils.events]: \u001b[0m eta: 0:11:44  iter: 1340  total_loss: 0.115  loss_cls: 0.034  loss_box_reg: 0.086  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:50 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 1360  total_loss: 0.107  loss_cls: 0.027  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:50 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 1360  total_loss: 0.107  loss_cls: 0.027  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:57 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 1380  total_loss: 0.140  loss_cls: 0.036  loss_box_reg: 0.093  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:56:57 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 1380  total_loss: 0.140  loss_cls: 0.036  loss_box_reg: 0.093  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:06 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 1400  total_loss: 0.120  loss_cls: 0.040  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:06 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 1400  total_loss: 0.120  loss_cls: 0.040  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:14 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 1420  total_loss: 0.101  loss_cls: 0.021  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:14 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 1420  total_loss: 0.101  loss_cls: 0.021  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:23 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1440  total_loss: 0.086  loss_cls: 0.020  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:23 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1440  total_loss: 0.086  loss_cls: 0.020  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:30 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 1460  total_loss: 0.110  loss_cls: 0.020  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:30 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 1460  total_loss: 0.110  loss_cls: 0.020  loss_box_reg: 0.091  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:39 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 1480  total_loss: 0.075  loss_cls: 0.016  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 21:57:39 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 1480  total_loss: 0.075  loss_cls: 0.016  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:47 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 1500  total_loss: 0.111  loss_cls: 0.024  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:47 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 1500  total_loss: 0.111  loss_cls: 0.024  loss_box_reg: 0.078  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:56 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 1520  total_loss: 0.099  loss_cls: 0.018  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:57:56 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 1520  total_loss: 0.099  loss_cls: 0.018  loss_box_reg: 0.073  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:04 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1540  total_loss: 0.079  loss_cls: 0.019  loss_box_reg: 0.053  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:04 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 1540  total_loss: 0.079  loss_cls: 0.019  loss_box_reg: 0.053  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:11 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1560  total_loss: 0.070  loss_cls: 0.015  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:11 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1560  total_loss: 0.070  loss_cls: 0.015  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:20 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 1580  total_loss: 0.066  loss_cls: 0.010  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:20 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 1580  total_loss: 0.066  loss_cls: 0.010  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:27 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 1600  total_loss: 0.077  loss_cls: 0.019  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:27 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 1600  total_loss: 0.077  loss_cls: 0.019  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:36 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 1620  total_loss: 0.067  loss_cls: 0.010  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:36 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 1620  total_loss: 0.067  loss_cls: 0.010  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:43 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1640  total_loss: 0.122  loss_cls: 0.018  loss_box_reg: 0.093  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:43 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 1640  total_loss: 0.122  loss_cls: 0.018  loss_box_reg: 0.093  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:52 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 1660  total_loss: 0.090  loss_cls: 0.011  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:58:52 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 1660  total_loss: 0.090  loss_cls: 0.011  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:00 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1680  total_loss: 0.110  loss_cls: 0.014  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:00 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 1680  total_loss: 0.110  loss_cls: 0.014  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:08 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1700  total_loss: 0.090  loss_cls: 0.010  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:08 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 1700  total_loss: 0.090  loss_cls: 0.010  loss_box_reg: 0.081  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:16 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 1720  total_loss: 0.091  loss_cls: 0.013  loss_box_reg: 0.074  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:16 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 1720  total_loss: 0.091  loss_cls: 0.013  loss_box_reg: 0.074  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:24 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1740  total_loss: 0.093  loss_cls: 0.015  loss_box_reg: 0.075  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:24 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1740  total_loss: 0.093  loss_cls: 0.015  loss_box_reg: 0.075  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:32 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 1760  total_loss: 0.117  loss_cls: 0.027  loss_box_reg: 0.085  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:32 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 1760  total_loss: 0.117  loss_cls: 0.027  loss_box_reg: 0.085  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:40 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 1780  total_loss: 0.058  loss_cls: 0.013  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:40 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 1780  total_loss: 0.058  loss_cls: 0.013  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:49 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 1800  total_loss: 0.050  loss_cls: 0.010  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:49 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 1800  total_loss: 0.050  loss_cls: 0.010  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:56 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 1820  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.059  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 21:59:56 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 1820  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.059  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:05 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 1840  total_loss: 0.076  loss_cls: 0.012  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:05 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 1840  total_loss: 0.076  loss_cls: 0.012  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:13 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1860  total_loss: 0.071  loss_cls: 0.009  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:13 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1860  total_loss: 0.071  loss_cls: 0.009  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:22 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 1880  total_loss: 0.073  loss_cls: 0.010  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:22 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 1880  total_loss: 0.073  loss_cls: 0.010  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:31 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 1900  total_loss: 0.081  loss_cls: 0.010  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:31 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 1900  total_loss: 0.081  loss_cls: 0.010  loss_box_reg: 0.071  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:39 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 1920  total_loss: 0.105  loss_cls: 0.012  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:39 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 1920  total_loss: 0.105  loss_cls: 0.012  loss_box_reg: 0.082  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:47 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 1940  total_loss: 0.086  loss_cls: 0.008  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:47 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 1940  total_loss: 0.086  loss_cls: 0.008  loss_box_reg: 0.069  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:55 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 1960  total_loss: 0.067  loss_cls: 0.005  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:00:55 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 1960  total_loss: 0.067  loss_cls: 0.005  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:03 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1980  total_loss: 0.063  loss_cls: 0.008  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:03 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 1980  total_loss: 0.063  loss_cls: 0.008  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:11 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2000  total_loss: 0.061  loss_cls: 0.007  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:11 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2000  total_loss: 0.061  loss_cls: 0.007  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 22:01:20 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 2020  total_loss: 0.051  loss_cls: 0.012  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:20 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 2020  total_loss: 0.051  loss_cls: 0.012  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:27 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 2040  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:27 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 2040  total_loss: 0.067  loss_cls: 0.006  loss_box_reg: 0.056  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:36 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2060  total_loss: 0.053  loss_cls: 0.009  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:36 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2060  total_loss: 0.053  loss_cls: 0.009  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:44 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 2080  total_loss: 0.063  loss_cls: 0.010  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:44 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 2080  total_loss: 0.063  loss_cls: 0.010  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:52 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 2100  total_loss: 0.062  loss_cls: 0.005  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:01:52 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 2100  total_loss: 0.062  loss_cls: 0.005  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:00 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 2120  total_loss: 0.082  loss_cls: 0.012  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:00 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 2120  total_loss: 0.082  loss_cls: 0.012  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:09 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 2140  total_loss: 0.065  loss_cls: 0.007  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:09 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 2140  total_loss: 0.065  loss_cls: 0.007  loss_box_reg: 0.060  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:17 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 2160  total_loss: 0.077  loss_cls: 0.006  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:17 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 2160  total_loss: 0.077  loss_cls: 0.006  loss_box_reg: 0.057  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:25 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 2180  total_loss: 0.060  loss_cls: 0.006  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:25 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 2180  total_loss: 0.060  loss_cls: 0.006  loss_box_reg: 0.052  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:34 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 2200  total_loss: 0.077  loss_cls: 0.008  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:34 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 2200  total_loss: 0.077  loss_cls: 0.008  loss_box_reg: 0.068  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:42 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 2220  total_loss: 0.077  loss_cls: 0.014  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:42 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 2220  total_loss: 0.077  loss_cls: 0.014  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:49 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 2240  total_loss: 0.061  loss_cls: 0.006  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:49 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 2240  total_loss: 0.061  loss_cls: 0.006  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:57 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2260  total_loss: 0.054  loss_cls: 0.002  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:02:57 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2260  total_loss: 0.054  loss_cls: 0.002  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:05 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 2280  total_loss: 0.055  loss_cls: 0.006  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:05 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 2280  total_loss: 0.055  loss_cls: 0.006  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:14 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 2300  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.044  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:14 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 2300  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.044  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:23 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 2320  total_loss: 0.065  loss_cls: 0.007  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:23 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 2320  total_loss: 0.065  loss_cls: 0.007  loss_box_reg: 0.058  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:31 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2340  total_loss: 0.054  loss_cls: 0.005  loss_box_reg: 0.044  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:31 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 2340  total_loss: 0.054  loss_cls: 0.005  loss_box_reg: 0.044  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:39 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 2360  total_loss: 0.059  loss_cls: 0.004  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:39 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 2360  total_loss: 0.059  loss_cls: 0.004  loss_box_reg: 0.050  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:49 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 2380  total_loss: 0.046  loss_cls: 0.003  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:49 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 2380  total_loss: 0.046  loss_cls: 0.003  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:57 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 2400  total_loss: 0.047  loss_cls: 0.005  loss_box_reg: 0.044  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:03:57 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 2400  total_loss: 0.047  loss_cls: 0.005  loss_box_reg: 0.044  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:04 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 2420  total_loss: 0.065  loss_cls: 0.004  loss_box_reg: 0.059  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:04 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 2420  total_loss: 0.065  loss_cls: 0.004  loss_box_reg: 0.059  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:12 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2440  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:12 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2440  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:21 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 2460  total_loss: 0.063  loss_cls: 0.008  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:21 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 2460  total_loss: 0.063  loss_cls: 0.008  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:29 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 2480  total_loss: 0.065  loss_cls: 0.004  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:29 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 2480  total_loss: 0.065  loss_cls: 0.004  loss_box_reg: 0.063  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:37 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 2500  total_loss: 0.071  loss_cls: 0.008  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:37 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 2500  total_loss: 0.071  loss_cls: 0.008  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:46 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2520  total_loss: 0.067  loss_cls: 0.010  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:46 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 2520  total_loss: 0.067  loss_cls: 0.010  loss_box_reg: 0.051  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:04:54 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 2540  total_loss: 0.064  loss_cls: 0.006  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 22:04:54 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 2540  total_loss: 0.064  loss_cls: 0.006  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:02 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 2560  total_loss: 0.050  loss_cls: 0.002  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:02 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 2560  total_loss: 0.050  loss_cls: 0.002  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:10 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 2580  total_loss: 0.073  loss_cls: 0.007  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:10 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 2580  total_loss: 0.073  loss_cls: 0.007  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:18 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2600  total_loss: 0.053  loss_cls: 0.003  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:18 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 2600  total_loss: 0.053  loss_cls: 0.003  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:27 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 2620  total_loss: 0.045  loss_cls: 0.004  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:27 d2.utils.events]: \u001b[0m eta: 0:02:34  iter: 2620  total_loss: 0.045  loss_cls: 0.004  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:35 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 2640  total_loss: 0.049  loss_cls: 0.004  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:35 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 2640  total_loss: 0.049  loss_cls: 0.004  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:43 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 2660  total_loss: 0.052  loss_cls: 0.002  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:43 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 2660  total_loss: 0.052  loss_cls: 0.002  loss_box_reg: 0.045  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:51 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 2680  total_loss: 0.063  loss_cls: 0.006  loss_box_reg: 0.061  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:51 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 2680  total_loss: 0.063  loss_cls: 0.006  loss_box_reg: 0.061  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:59 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 2700  total_loss: 0.047  loss_cls: 0.003  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:05:59 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 2700  total_loss: 0.047  loss_cls: 0.003  loss_box_reg: 0.041  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:07 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2720  total_loss: 0.067  loss_cls: 0.008  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:07 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 2720  total_loss: 0.067  loss_cls: 0.008  loss_box_reg: 0.055  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:15 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 2740  total_loss: 0.052  loss_cls: 0.005  loss_box_reg: 0.043  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:15 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 2740  total_loss: 0.052  loss_cls: 0.005  loss_box_reg: 0.043  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:24 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2760  total_loss: 0.059  loss_cls: 0.005  loss_box_reg: 0.048  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:24 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2760  total_loss: 0.059  loss_cls: 0.005  loss_box_reg: 0.048  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:31 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 2780  total_loss: 0.058  loss_cls: 0.006  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:31 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 2780  total_loss: 0.058  loss_cls: 0.006  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:39 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2800  total_loss: 0.041  loss_cls: 0.003  loss_box_reg: 0.038  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:39 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 2800  total_loss: 0.041  loss_cls: 0.003  loss_box_reg: 0.038  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:48 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 2820  total_loss: 0.047  loss_cls: 0.002  loss_box_reg: 0.040  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:48 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 2820  total_loss: 0.047  loss_cls: 0.002  loss_box_reg: 0.040  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:55 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 2840  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:06:55 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 2840  total_loss: 0.051  loss_cls: 0.005  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:04 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 2860  total_loss: 0.051  loss_cls: 0.003  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:04 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 2860  total_loss: 0.051  loss_cls: 0.003  loss_box_reg: 0.049  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:12 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 2880  total_loss: 0.048  loss_cls: 0.003  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:12 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 2880  total_loss: 0.048  loss_cls: 0.003  loss_box_reg: 0.042  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:20 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 2900  total_loss: 0.052  loss_cls: 0.004  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:20 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 2900  total_loss: 0.052  loss_cls: 0.004  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:29 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 2920  total_loss: 0.051  loss_cls: 0.004  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:29 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 2920  total_loss: 0.051  loss_cls: 0.004  loss_box_reg: 0.047  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:38 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 2940  total_loss: 0.058  loss_cls: 0.006  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:38 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 2940  total_loss: 0.058  loss_cls: 0.006  loss_box_reg: 0.046  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:46 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2960  total_loss: 0.077  loss_cls: 0.006  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:46 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2960  total_loss: 0.077  loss_cls: 0.006  loss_box_reg: 0.062  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:54 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 2980  total_loss: 0.062  loss_cls: 0.003  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:07:54 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 2980  total_loss: 0.062  loss_cls: 0.003  loss_box_reg: 0.054  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:08:02 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 22:08:11 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.072  loss_cls: 0.004  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:08:11 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 3000  total_loss: 0.072  loss_cls: 0.004  loss_box_reg: 0.065  lr: 0.000250  max_mem: 3743M\n",
      "\u001b[32m[08/23 22:08:12 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[08/23 22:08:20 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 22:08:20 d2.data.common]: \u001b[0mSerializing 35 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[08/23 22:08:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 22:08:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[08/23 22:08:20 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[08/23 22:08:20 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[08/23 22:08:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 22:08:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 35 images\n",
      "\u001b[32m[08/23 22:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.2259 s / img. ETA=0:00:05\n",
      "\u001b[32m[08/23 22:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/35. 0.2259 s / img. ETA=0:00:05\n",
      "\u001b[32m[08/23 22:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 33/35. 0.2315 s / img. ETA=0:00:00\n",
      "\u001b[32m[08/23 22:08:28 d2.evaluation.evaluator]: \u001b[0mInference done 33/35. 0.2315 s / img. ETA=0:00:00\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.110831 (0.237028 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:07.110831 (0.237028 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.234351 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.234351 s / img per device, on 1 devices)\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/validation/cmaker-bathtub-treehouse-validation/coco_instances_results.json\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "COCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "Accumulating evaluation results...\n",
      "COCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.703\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.716\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.768\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.768\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.768\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 64.962 | 97.836 | 70.277 |  nan  |  nan  | 64.962 |\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 64.962 | 97.836 | 70.277 |  nan  |  nan  | 64.962 |\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 67.899 | Coffeemaker | 69.958 | Tree house | 57.030 |\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category    | AP     | category   | AP     |\n",
      "|:-----------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| Bathtub    | 67.899 | Coffeemaker | 69.958 | Tree house | 57.030 |\n",
      "### Returning results_i...\n",
      "\u001b[32m[08/23 22:08:29 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 22:08:29 detectron2]: \u001b[0mEvaluation results for validation/cmaker-bathtub-treehouse-validation in csv format:\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.testing]: \u001b[0mcopypaste: 64.9624,97.8365,70.2773,nan,nan,64.9624\n",
      "\u001b[32m[08/23 22:08:29 d2.evaluation.testing]: \u001b[0mcopypaste: 64.9624,97.8365,70.2773,nan,nan,64.9624\n",
      "### Saving results to Weights & Biases...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for i,arg in enumerate(arg_list):\n",
    "        print(f\">>>>>>>>>>>>> Running experiment: {i}\")\n",
    "        main(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T17:53:51.043586Z",
     "start_time": "2020-08-23T17:53:51.025175Z"
    }
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-23T17:54:38.820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train-annotations-bbox.csv for annotations...\n",
      "On dataset: train\n",
      "Classes we're using:\n",
      " Stairs          5981\n",
      "Couch           4256\n",
      "Porch           3854\n",
      "Television      3789\n",
      "Fountain        3690\n",
      "Bed             3563\n",
      "Pillow          3508\n",
      "Countertop      3112\n",
      "Sink            1648\n",
      "Mirror          1571\n",
      "Oven             637\n",
      "Refrigerator     592\n",
      "Toilet           465\n",
      "Towel            338\n",
      "Bathtub          251\n",
      "Shower           235\n",
      "Fireplace        221\n",
      "Jacuzzi          103\n",
      "Dishwasher        92\n",
      "Coffeemaker       73\n",
      "Name: ClassName, dtype: int64\n",
      "Total number of images: 33409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5334fb58024f1fb5c691f9611c21fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## \n",
    "## Generate JSON label file\n",
    "\n",
    "_ = get_image_dicts('images',\n",
    "                     'train-annotations-bbox.csv',target_classes)\n",
    "\n",
    "_ = get_image_dicts('valid_images',\n",
    "                    'validation-annotations-bbox.csv',target_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-23T17:56:59.858Z"
    }
   },
   "outputs": [],
   "source": [
    "shutdown -h 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "airnb",
   "language": "python",
   "name": "airnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
